{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "589deee9-da2e-4e74-b193-42ace8d58f69",
   "metadata": {},
   "source": [
    "# RAG System evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6de6f3",
   "metadata": {},
   "source": [
    "## Evaluation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "689dfb3b-a599-450a-b3f2-7d882da9633a",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "267bab21-796f-4fe7-bfc1-faf82bde91fd",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/evaluation_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c9455a8d-badf-4b70-a90a-6443c58d9fad",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "      <th>article_url</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What can you tell me about a new Deepseek model?</td>\n",
       "      <td>DeepSeek released DeepSeek-R1, a large languag...</td>\n",
       "      <td>https://www.deeplearning.ai/the-batch/issue-285/</td>\n",
       "      <td>DeepSeek released DeepSeek-R1, a mixture-of-ex...</td>\n",
       "      <td>A new open model rivals OpenAI’s o1, and it’s ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Is Sony Music Group working with Generative AI?</td>\n",
       "      <td>Yes, Sony Music Group is working with AI and h...</td>\n",
       "      <td>https://www.deeplearning.ai/the-batch/sony-mus...</td>\n",
       "      <td>Sony Music Group has prohibited the use of its...</td>\n",
       "      <td>\\nThe world’s second-largest music publisher a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Which AI companies are working with U.S. gover...</td>\n",
       "      <td>Meta and Anthropic are working with the U.S. g...</td>\n",
       "      <td>https://www.deeplearning.ai/the-batch/meta-and...</td>\n",
       "      <td>Meta and Anthropic</td>\n",
       "      <td>Two top AI companies changed their stances on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what are the models used in biochemistry?</td>\n",
       "      <td>AlphaFold 3 is a model that predicts the struc...</td>\n",
       "      <td>https://www.deeplearning.ai/the-batch/deepmind...</td>\n",
       "      <td>AlphaFold 3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Are neural networks assisting brain surgeons, ...</td>\n",
       "      <td>Yes, the article indicates that neural network...</td>\n",
       "      <td>https://www.deeplearning.ai/the-batch/research...</td>\n",
       "      <td>The article describes a deep learning-based te...</td>\n",
       "      <td>The latest update of DeepMind’s AlphaFold mode...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0   What can you tell me about a new Deepseek model?   \n",
       "1    Is Sony Music Group working with Generative AI?   \n",
       "2  Which AI companies are working with U.S. gover...   \n",
       "3          what are the models used in biochemistry?   \n",
       "4  Are neural networks assisting brain surgeons, ...   \n",
       "\n",
       "                                            response  \\\n",
       "0  DeepSeek released DeepSeek-R1, a large languag...   \n",
       "1  Yes, Sony Music Group is working with AI and h...   \n",
       "2  Meta and Anthropic are working with the U.S. g...   \n",
       "3  AlphaFold 3 is a model that predicts the struc...   \n",
       "4  Yes, the article indicates that neural network...   \n",
       "\n",
       "                                         article_url  \\\n",
       "0   https://www.deeplearning.ai/the-batch/issue-285/   \n",
       "1  https://www.deeplearning.ai/the-batch/sony-mus...   \n",
       "2  https://www.deeplearning.ai/the-batch/meta-and...   \n",
       "3  https://www.deeplearning.ai/the-batch/deepmind...   \n",
       "4  https://www.deeplearning.ai/the-batch/research...   \n",
       "\n",
       "                                        ground_truth  \\\n",
       "0  DeepSeek released DeepSeek-R1, a mixture-of-ex...   \n",
       "1  Sony Music Group has prohibited the use of its...   \n",
       "2                                Meta and Anthropic    \n",
       "3                                        AlphaFold 3   \n",
       "4  The article describes a deep learning-based te...   \n",
       "\n",
       "                                             context  \n",
       "0  A new open model rivals OpenAI’s o1, and it’s ...  \n",
       "1  \\nThe world’s second-largest music publisher a...  \n",
       "2  Two top AI companies changed their stances on ...  \n",
       "3                                                NaN  \n",
       "4  The latest update of DeepMind’s AlphaFold mode...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bf4a03",
   "metadata": {},
   "source": [
    "## Evaluation using Langkit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8b0808-1f09-49dc-b5ef-34a63626ba7b",
   "metadata": {},
   "source": [
    "### Setup Langkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccc1cd0b-d77f-42fc-aeae-917397df6f91",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annacielas/Documents/projects/softserve_genai/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/annacielas/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from langkit import llm_metrics\n",
    "from langkit_bounty_helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03260f49-ea45-48a9-b90c-3019503f4a4d",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "schema = llm_metrics.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef256947-b3c4-4a99-96b1-fa354f6533c5",
   "metadata": {},
   "source": [
    "### Prompt-response relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a068589b-d0c9-4e00-8d8d-0b3dee42d056",
   "metadata": {
    "height": 81
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div></div><iframe srcdoc=\"&lt;!DOCTYPE html&gt;\n",
       "&lt;html lang=&quot;en&quot;&gt;\n",
       "  &lt;head&gt;\n",
       "    &lt;meta charset=&quot;UTF-8&quot; /&gt;\n",
       "    &lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;IE=edge&quot; /&gt;\n",
       "    &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot; /&gt;\n",
       "    &lt;meta name=&quot;description&quot; content=&quot;&quot; /&gt;\n",
       "    &lt;meta name=&quot;author&quot; content=&quot;&quot; /&gt;\n",
       "\n",
       "    &lt;title&gt;Profile Visualizer | whylogs&lt;/title&gt;\n",
       "\n",
       "    &lt;link rel=&quot;icon&quot; href=&quot;images/whylabs-favicon.png&quot; type=&quot;image/png&quot; sizes=&quot;16x16&quot; /&gt;\n",
       "    &lt;link rel=&quot;preconnect&quot; href=&quot;https://fonts.googleapis.com&quot; /&gt;\n",
       "    &lt;link rel=&quot;preconnect&quot; href=&quot;https://fonts.gstatic.com&quot; crossorigin /&gt;\n",
       "    &lt;link href=&quot;https://fonts.googleapis.com/css2?family=Asap:wght@400;500;600;700&amp;display=swap&quot; rel=&quot;stylesheet&quot; /&gt;\n",
       "    &lt;link rel=&quot;preconnect&quot; href=&quot;https://fonts.gstatic.com&quot; /&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.1.0/dist/css/bootstrap.min.css&quot; /&gt;\n",
       "\n",
       "    &lt;script\n",
       "      src=&quot;https://cdnjs.cloudflare.com/ajax/libs/handlebars.js/4.7.7/handlebars.min.js&quot;\n",
       "      integrity=&quot;sha512-RNLkV3d+aLtfcpEyFG8jRbnWHxUqVZozacROI4J2F1sTaDqo1dPQYs01OMi1t1w9Y2FdbSCDSQ2ZVdAC8bzgAg==&quot;\n",
       "      crossorigin=&quot;anonymous&quot;\n",
       "      referrerpolicy=&quot;no-referrer&quot;\n",
       "    &gt;&lt;/script&gt;\n",
       "\n",
       "    &lt;style type=&quot;text/css&quot;&gt;\n",
       "\n",
       "      :root {\n",
       "        /** Branded colors */\n",
       "        --brandSecondary900: #4f595b;\n",
       "        --secondaryLight1000: #313b3d;\n",
       "        /** Purpose colors */\n",
       "        --tealBackground: #eaf2f3;\n",
       "      }\n",
       "\n",
       "      /* RESET STYLE */\n",
       "      *,\n",
       "      *::after,\n",
       "      *::before {\n",
       "        margin: 0;\n",
       "        padding: 0;\n",
       "        box-sizing: border-box;\n",
       "        overflow-y: hidden;\n",
       "      }\n",
       "\n",
       "      /* Screen on smaller screens */\n",
       "      .no-responsive {\n",
       "        display: none;\n",
       "        position: fixed;\n",
       "        top: 0;\n",
       "        left: 0;\n",
       "        z-index: 1031;\n",
       "        width: 100vw;\n",
       "        height: 100vh;\n",
       "        background-color: var(--tealBackground);\n",
       "        display: flex;\n",
       "        align-items: center;\n",
       "        justify-content: center;\n",
       "      }\n",
       "\n",
       "      .desktop-content {\n",
       "        display: flex;\n",
       "        flex-direction: column;\n",
       "      }\n",
       "\n",
       "      .no-responsive__content {\n",
       "        max-width: 600px;\n",
       "        width: 100%;\n",
       "        padding: 0 24px;\n",
       "      }\n",
       "\n",
       "      .no-responsive__title {\n",
       "        font-size: 96px;\n",
       "        font-weight: 300;\n",
       "        color: var(--brandSecondary900);\n",
       "        line-height: 1.167;\n",
       "      }\n",
       "\n",
       "      .no-responsive__text {\n",
       "        margin: 0;\n",
       "        font-size: 16px;\n",
       "        font-weight: 400;\n",
       "        color: var(--brandSecondary900);\n",
       "        line-height: 1.5;\n",
       "      }\n",
       "\n",
       "      .svg-container {\n",
       "        display: inline-block;\n",
       "        position: relative;\n",
       "        width: 100%;\n",
       "        vertical-align: top;\n",
       "        overflow: hidden;\n",
       "      }\n",
       "\n",
       "      .svg-content-responsive {\n",
       "        display: inline-block;\n",
       "        position: absolute;\n",
       "        left: 0;\n",
       "      }\n",
       "\n",
       "      .circle-color {\n",
       "       display: inline-block;\n",
       "       padding: 5px;\n",
       "       border-radius: 50px;\n",
       "     }\n",
       "\n",
       "     .colors-for-distingushing-charts {\n",
       "       padding-right: 10px;\n",
       "     }\n",
       "\n",
       "     .display-flex{\n",
       "       display: flex;\n",
       "     }\n",
       "\n",
       "     .align-items-flex-end {\n",
       "       align-items: flex-end;\n",
       "     }\n",
       "\n",
       "     .chart-box-title {\n",
       "       width: 88%;\n",
       "       justify-content: space-between;\n",
       "       margin: 10px;\n",
       "       margin-top: 15px;\n",
       "       bottom: 0;\n",
       "     }\n",
       "\n",
       "     .chart-box-title p{\n",
       "       margin-bottom: 0;\n",
       "       font-family: Asap;\n",
       "       font-weight: bold;\n",
       "       font-size: 18px;\n",
       "       line-height: 16px;\n",
       "       color: #4F595B;\n",
       "     }\n",
       "\n",
       "    .bar {\n",
       "      font: 10px sans-serif;\n",
       "    }\n",
       "\n",
       "    .bar path,\n",
       "    .bar line {\n",
       "      fill: none;\n",
       "      stroke: #000;\n",
       "      shape-rendering: crispEdges;\n",
       "    }\n",
       "\n",
       "    .error-message {\n",
       "      display: flex;\n",
       "      justify-content: center;\n",
       "      align-items: center;\n",
       "      color: rgb(255, 114, 71);\n",
       "      font-size: 30px;\n",
       "      font-weight: 900;\n",
       "    }\n",
       "\n",
       "     @media screen and (min-width: 500px) {\n",
       "       .desktop-content {\n",
       "         display: block;\n",
       "       }\n",
       "       .no-responsive {\n",
       "         display: none;\n",
       "       }\n",
       "     }\n",
       "    &lt;/style&gt;\n",
       "  &lt;/head&gt;\n",
       "\n",
       "  &lt;body id=&quot;generated-html&quot;&gt;&lt;/body&gt;\n",
       "  &lt;script id=&quot;entry-template&quot; type=&quot;text/x-handlebars-template&quot;&gt;\n",
       "    \n",
       "      &lt;div class=&quot;desktop-content&quot;&gt;\n",
       "{{#each this}}              &lt;div class=&quot;chart-box&quot; id=&quot;chart-box&quot;&gt;\n",
       "                &lt;div class=&quot;chart-box-title display-flex&quot;&gt;\n",
       "                  &lt;p&gt;{{@key}}&lt;/p&gt;\n",
       "                  &lt;div class=&quot;display-flex&quot;&gt;\n",
       "                    &lt;div class=&quot;colors-for-distingushing-charts&quot;&gt;\n",
       "                      &lt;div class=&quot;circle-color&quot; style=&quot;background: #44C0E7;&quot;&gt;&lt;/div&gt;\n",
       "                      &lt;text alignment-baseline=&quot;middle&quot; style=&quot;font-size: 15px;&quot;&gt;Target&lt;/text&gt;\n",
       "                    &lt;/div&gt;\n",
       "                    &lt;div class=&quot;colors-for-distingushing-charts&quot;&gt;\n",
       "                      &lt;div class=&quot;circle-color&quot; style=&quot;background: #F5843C&quot;&gt;&lt;/div&gt;\n",
       "                      &lt;text alignment-baseline=&quot;middle&quot; style=&quot;font-size: 15px;&quot;&gt;Reference&lt;/text&gt;\n",
       "                    &lt;/div&gt;\n",
       "                  &lt;/div&gt;&lt;/div&gt;\n",
       "                &lt;div class=&quot;svg-container&quot;&gt;{{{getDoubleHistogramChart this}}}&lt;/div&gt;\n",
       "              &lt;/div&gt;\n",
       "{{/each}}      &lt;/div&gt;\n",
       "      &lt;div class=&quot;no-responsive&quot;&gt;\n",
       "        &lt;div class=&quot;no-responsive__content&quot;&gt;\n",
       "          &lt;h1 class=&quot;no-responsive__title&quot;&gt;Hold on! :)&lt;/h1&gt;\n",
       "          &lt;p class=&quot;no-responsive__text&quot;&gt;\n",
       "            It looks like your current screen size or device is not yet supported by the WhyLabs Sandbox. The Sandbox is\n",
       "            best experienced on a desktop computer. Please try maximizing this window or switching to another device. We\n",
       "            are working on adding support for a larger variety of devices.\n",
       "          &lt;/p&gt;\n",
       "        &lt;/div&gt;\n",
       "      &lt;/div&gt;\n",
       "    \n",
       "  &lt;/script&gt;\n",
       "\n",
       "  &lt;script src=&quot;https://code.jquery.com/jquery-3.6.0.min.js&quot; integrity=&quot;sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=&quot; crossorigin=&quot;anonymous&quot;&gt;&lt;/script&gt;\n",
       "\n",
       "  &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/d3/6.7.0/d3.min.js&quot; integrity=&quot;sha512-cd6CHE+XWDQ33ElJqsi0MdNte3S+bQY819f7p3NUHgwQQLXSKjE4cPZTeGNI+vaxZynk1wVU3hoHmow3m089wA==&quot; crossorigin=&quot;anonymous&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/script&gt;\n",
       "\n",
       "  &lt;script&gt;\n",
       "    function registerHandlebarHelperFunctions() {\n",
       "      //helper fun\n",
       "\n",
       "      class GenerateChartParams {\n",
       "        constructor(height, width, targetData, referenceData, bottomMargin=30, topMargin=5) {\n",
       "          this.MARGIN = {\n",
       "            TOP: topMargin,\n",
       "            RIGHT: 5,\n",
       "            BOTTOM: bottomMargin,\n",
       "            LEFT: 55,\n",
       "          };\n",
       "          this.SVG_WIDTH = width;\n",
       "          this.SVG_HEIGHT = height;\n",
       "          this.CHART_WIDTH = this.SVG_WIDTH - this.MARGIN.LEFT - this.MARGIN.RIGHT;\n",
       "          this.CHART_HEIGHT = this.SVG_HEIGHT - this.MARGIN.TOP - this.MARGIN.BOTTOM;\n",
       "          this.svgEl = d3.create(&quot;svg&quot;)\n",
       "             .attr(&quot;preserveAspectRatio&quot;, &quot;xMinYMin meet&quot;)\n",
       "             .attr(&quot;viewBox&quot;, `0 0 ${$(window).width()+100} ${$(window).height()-30}`)\n",
       "             .classed(&quot;svg-content-responsive&quot;, true)\n",
       "          this.maxYValue = d3.max(targetData, (d) =&gt; Math.abs(d.axisY));\n",
       "          this.minYValue = d3.min(targetData, (d) =&gt; Math.abs(d.axisY));\n",
       "          const mergedReferenceData = referenceData.map(({axisX, axisY}) =&gt; {\n",
       "            return {axisX, axisY}\n",
       "          })\n",
       "          const mergedTargetedData = targetData.map(({axisX, axisY}) =&gt; {\n",
       "            return {axisX, axisY}\n",
       "          })\n",
       "\n",
       "          this.charts2 = mergedReferenceData.concat(mergedTargetedData)\n",
       "          this.charts2 = this.charts2.sort(function(a, b) { return a - b; });\n",
       "\n",
       "          this.targetBinWidth = targetData[1]?.axisX - targetData[0]?.axisX\n",
       "          this.referenceBinWidth = referenceData[1]?.axisX - referenceData[0]?.axisX\n",
       "          this.maxTargetXValue = d3.max(targetData, (d) =&gt; d.axisX);\n",
       "\n",
       "          this.maxReferenceXValue = d3.max(referenceData, (d) =&gt; d.axisX);\n",
       "\n",
       "          this.xScale = d3\n",
       "              .scaleLinear()\n",
       "         .domain([d3.min(this.charts2, function(d) { return parseFloat(d.axisX); }),(this.maxTargetXValue+this.targetBinWidth &gt;= this.maxReferenceXValue+this.referenceBinWidth) ? this.maxTargetXValue+this.targetBinWidth:this.maxReferenceXValue+this.referenceBinWidth])\n",
       "         .range([0, this.CHART_WIDTH ]);\n",
       "\n",
       "         this.svgEl.append(&quot;g&quot;)\n",
       "             .attr(&quot;transform&quot;, &quot;translate(&quot;+ this.MARGIN.LEFT +&quot;,&quot; + this.SVG_HEIGHT + &quot;)&quot;)\n",
       "             .call(d3.axisBottom(this.xScale));\n",
       "          this.yScale = d3.scaleLinear()\n",
       "              .range([this.CHART_HEIGHT , 0])\n",
       "              .domain([d3.min(this.charts2, function(d) { return parseFloat(d.axisY); }), d3.max(this.charts2, function(d) { return parseFloat(d.axisY); })*1.2])\n",
       "              .nice();\n",
       "        }\n",
       "      }\n",
       "\n",
       "      function chartData(column) {\n",
       "        const data = [];\n",
       "        if (column?.histogram) {\n",
       "          for (let i = 0; i&lt;column.histogram.bins.length; i++) {\n",
       "            data.push({\n",
       "              axisY: column.histogram.counts[i] || 0,\n",
       "              axisX: column.histogram.bins[i] || 0,\n",
       "            });\n",
       "          }\n",
       "        } else {\n",
       "            $(document).ready(() =&gt;\n",
       "              $(&quot;.desktop-content&quot;).html(`\n",
       "                &lt;p style=&quot;height: ${$(window).height()}px&quot; class=&quot;error-message&quot;&gt;\n",
       "                  Something went wrong. Please try again.\n",
       "                &lt;/p&gt;\n",
       "              `)\n",
       "            )\n",
       "          }\n",
       "\n",
       "        return data\n",
       "      }\n",
       "\n",
       "      function verticalLine(column) {\n",
       "        const line_data = [];\n",
       "        if (column?.vertical_line) {\n",
       "            line_data.push({\n",
       "              axisX: column?.vertical_line || 0,\n",
       "            });\n",
       "\n",
       "        }\n",
       "\n",
       "        return line_data\n",
       "      }\n",
       "\n",
       "      function generateDoubleHistogramChart(targetData, referenceData) {\n",
       "        let histogramData = [],\n",
       "            overlappedHistogramData = [];\n",
       "        let yFormat;\n",
       "\n",
       "        histogramData = chartData(targetData)\n",
       "        overlappedHistogramData = chartData(referenceData)\n",
       "        lineData = verticalLine(targetData)\n",
       "\n",
       "        const sizes = new GenerateChartParams($(window).height()-80, $(window).width(), histogramData, overlappedHistogramData)\n",
       "        const {\n",
       "          MARGIN,\n",
       "          SVG_WIDTH,\n",
       "          SVG_HEIGHT,\n",
       "          CHART_WIDTH,\n",
       "          CHART_HEIGHT,\n",
       "          svgEl,\n",
       "          maxYValue,\n",
       "          minYValue,\n",
       "          xScale,\n",
       "          yScale\n",
       "        } = sizes\n",
       "\n",
       "        const rectColors = [&quot;#44C0E7&quot;, &quot;#F5843C&quot;]\n",
       "        const yAxis = d3.axisLeft(yScale).ticks(SVG_HEIGHT / 40);\n",
       "\n",
       "        svgEl.append(&quot;g&quot;)\n",
       "          .attr(&quot;transform&quot;, `translate(${MARGIN.LEFT}, ${MARGIN.BOTTOM})`)\n",
       "          .call(yAxis)\n",
       "          .call(g =&gt; g.select(&quot;.domain&quot;).remove())\n",
       "          .call(g =&gt; g.selectAll(&quot;.tick line&quot;)\n",
       "              .attr(&quot;x2&quot;, CHART_WIDTH)\n",
       "              .attr(&quot;stroke-opacity&quot;, 0.1))\n",
       "          .call(g =&gt; g.append(&quot;text&quot;)\n",
       "              .attr(&quot;x&quot;, -MARGIN.LEFT)\n",
       "              .attr(&quot;y&quot;, 10)\n",
       "              .attr(&quot;fill&quot;, &quot;currentColor&quot;)\n",
       "              .attr(&quot;text-anchor&quot;, &quot;start&quot;))\n",
       "\n",
       "        svgEl.append(&quot;line&quot;)\n",
       "          .attr(&quot;transform&quot;, `translate(${MARGIN.LEFT}, ${MARGIN.BOTTOM})`)\n",
       "          .data(lineData)\n",
       "          .attr(&quot;x1&quot;, (d) =&gt; xScale(d.axisX))\n",
       "          .attr(&quot;y1&quot;, MARGIN.TOP + MARGIN.TOP)\n",
       "          .attr(&quot;x2&quot;, (d) =&gt; xScale(d.axisX))\n",
       "          .attr(&quot;y2&quot;, CHART_HEIGHT + MARGIN.TOP)\n",
       "          .style(&quot;stroke-width&quot;, 2)\n",
       "          .style(&quot;stroke&quot;, &quot;#44C0E7&quot;)\n",
       "          .style(&quot;stroke-dasharray&quot;, (3,3))\n",
       "          .style(&quot;fill&quot;, &quot;none&quot;);\n",
       "\n",
       "        svgEl.append(&quot;text&quot;)\n",
       "          .attr(&quot;transform&quot;, &quot;rotate(-90)&quot;)\n",
       "          .data(lineData)\n",
       "          .attr(&quot;y&quot;, (d) =&gt; xScale(d.axisX) + MARGIN.LEFT)\n",
       "          .attr(&quot;x&quot;, 0 - (SVG_HEIGHT / 2))\n",
       "          .attr(&quot;dy&quot;, &quot;1em&quot;)\n",
       "          .style(&quot;text-anchor&quot;, &quot;middle&quot;)\n",
       "          .text(&quot;single value&quot;)\n",
       "          .style(&quot;font-size&quot;, &quot;15&quot;)\n",
       "          .style(&quot;opacity&quot;, &quot;0.6&quot;)\n",
       "\n",
       "        svgEl.append(&quot;text&quot;)\n",
       "          .attr(&quot;transform&quot;,\n",
       "                &quot;translate(&quot; + (CHART_WIDTH/2) + &quot; ,&quot; +\n",
       "                               (CHART_HEIGHT + MARGIN.TOP + 75) + &quot;)&quot;)\n",
       "          .style(&quot;text-anchor&quot;, &quot;middle&quot;)\n",
       "          .text(&quot;Values&quot;)\n",
       "          .style(&quot;font-size&quot;, &quot;15&quot;)\n",
       "          .style(&quot;opacity&quot;, &quot;0.6&quot;)\n",
       "\n",
       "        svgEl.append(&quot;text&quot;)\n",
       "          .attr(&quot;transform&quot;, &quot;rotate(-90)&quot;)\n",
       "          .attr(&quot;y&quot;, 0)\n",
       "          .attr(&quot;x&quot;, 0 - (SVG_HEIGHT / 2))\n",
       "          .attr(&quot;dy&quot;, &quot;1em&quot;)\n",
       "          .style(&quot;text-anchor&quot;, &quot;middle&quot;)\n",
       "          .text(&quot;Counts&quot;)\n",
       "          .style(&quot;font-size&quot;, &quot;15&quot;)\n",
       "          .style(&quot;opacity&quot;, &quot;0.6&quot;)\n",
       "\n",
       "          const gChart = svgEl.append(&quot;g&quot;);\n",
       "          gChart\n",
       "          .attr(&quot;transform&quot;, &quot;translate(&quot;+ MARGIN.LEFT +&quot;,0)&quot;)\n",
       "          .selectAll(&quot;.bar&quot;)\n",
       "          .data(histogramData)\n",
       "          .enter()\n",
       "          .append(&quot;rect&quot;)\n",
       "          .style(&quot;stroke&quot;, &quot;#021826&quot;)\n",
       "          .classed(&quot;bar&quot;, true)\n",
       "          .attr(&quot;width&quot;, function(d) { return xScale(histogramData[1]?.axisX)-xScale(histogramData[0]?.axisX); })\n",
       "          .attr(&quot;height&quot;, (d) =&gt; CHART_HEIGHT - yScale(d.axisY))\n",
       "          .attr(&quot;x&quot;, 1)\n",
       "          .attr(&quot;transform&quot;, function(d) { return &quot;translate(&quot; + xScale(d.axisX) + &quot;,&quot; + 0  +  &quot;)&quot;; })\n",
       "          .attr(&quot;y&quot;, (d) =&gt; yScale(d.axisY) + MARGIN.TOP + MARGIN.BOTTOM)\n",
       "          .attr(&quot;fill&quot;, rectColors[0])\n",
       "          .style(&quot;opacity&quot;,&quot;0.6&quot;)\n",
       "\n",
       "          const gChart1 = svgEl.append(&quot;g&quot;);\n",
       "          gChart1\n",
       "          .attr(&quot;transform&quot;, &quot;translate(&quot;+ MARGIN.LEFT +&quot;,0)&quot;)\n",
       "          .selectAll(&quot;.bar&quot;)\n",
       "          .data(overlappedHistogramData)\n",
       "          .enter()\n",
       "          .append(&quot;rect&quot;)\n",
       "          .style(&quot;stroke&quot;, &quot;#021826&quot;)\n",
       "          .classed(&quot;bar&quot;, true)\n",
       "          .attr(&quot;width&quot;, function(d) { return xScale(overlappedHistogramData[1]?.axisX)-xScale(overlappedHistogramData[0]?.axisX); })\n",
       "          .attr(&quot;height&quot;, (d) =&gt; CHART_HEIGHT - yScale(d.axisY))\n",
       "          .attr(&quot;x&quot;, 1)\n",
       "          .attr(&quot;transform&quot;, function(d) { return &quot;translate(&quot; + xScale(d.axisX) + &quot;,&quot; + 0  +  &quot;)&quot;; })\n",
       "          .attr(&quot;y&quot;, (d) =&gt; yScale(d.axisY) + MARGIN.TOP + MARGIN.BOTTOM)\n",
       "          .attr(&quot;fill&quot;, rectColors[1])\n",
       "          .style(&quot;opacity&quot;,&quot;0.6&quot;)\n",
       "\n",
       "        return svgEl._groups[0][0].outerHTML;\n",
       "      }\n",
       "\n",
       "      const profileFromCSVfile = {&quot;response.relevance_to_prompt&quot;: {&quot;histogram&quot;: {&quot;start&quot;: 0.44914981722831726, &quot;end&quot;: 0.8965567054851293, &quot;width&quot;: 0, &quot;counts&quot;: [0, 0, 0], &quot;max&quot;: 0.8965566158294678, &quot;min&quot;: 0.44914981722831726, &quot;bins&quot;: [0.44914981722831726, 0.5982854466472546, 0.7474210760661919, 0.8965567054851293], &quot;n&quot;: 10}}}\n",
       "\n",
       "      Handlebars.registerHelper(&quot;getDoubleHistogramChart&quot;,(column,key) =&gt; {\n",
       "          const columnKey = key.data.key\n",
       "        try {\n",
       "          if (profileFromCSVfile) {\n",
       "          return  generateDoubleHistogramChart (\n",
       "              column,\n",
       "              profileFromCSVfile[columnKey]\n",
       "            )\n",
       "          }\n",
       "        } catch (err) {\n",
       "          $(document).ready(() =&gt;\n",
       "            $(&quot;.desktop-content&quot;).html(`\n",
       "              &lt;p style=&quot;height: ${$(window).height()}px&quot; class=&quot;error-message&quot;&gt;\n",
       "                Something went wrong. Please try again.\n",
       "              &lt;/p&gt;\n",
       "            `)\n",
       "          )\n",
       "        }\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function initWebsiteScripts() {\n",
       "      $(&quot;.svg-container&quot;).css(&quot;height&quot;, $(window).height() - 32)\n",
       "    }\n",
       "\n",
       "    function initHandlebarsTemplate() {\n",
       "      // Replace this context with JSON from .py file\n",
       "      const context = {&quot;response.relevance_to_prompt&quot;: {&quot;histogram&quot;: {&quot;start&quot;: 0.44914981722831726, &quot;end&quot;: 0.8965567054851293, &quot;width&quot;: 0, &quot;counts&quot;: [4, 4, 2], &quot;max&quot;: 0.8965566158294678, &quot;min&quot;: 0.44914981722831726, &quot;bins&quot;: [0.44914981722831726, 0.5982854466472546, 0.7474210760661919, 0.8965567054851293], &quot;n&quot;: 10}}};\n",
       "      // Config handlebars and pass data to HBS template\n",
       "      const source = document.getElementById(&quot;entry-template&quot;).innerHTML;\n",
       "      const template = Handlebars.compile(source);\n",
       "      const html = template(context);\n",
       "      const target = document.getElementById(&quot;generated-html&quot;);\n",
       "      target.innerHTML = html;\n",
       "    }\n",
       "\n",
       "    // Invoke functions -- keep in mind invokation order\n",
       "    registerHandlebarHelperFunctions();\n",
       "    initHandlebarsTemplate();\n",
       "    initWebsiteScripts();\n",
       "  &lt;/script&gt;\n",
       "&lt;/html&gt;\n",
       "\" width=100% height=300px\n",
       "        frameBorder=0></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visualize_langkit_metric(\n",
    "    df,\n",
    "    \"response.relevance_to_prompt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9790b7a6-885e-477e-b615-37176b4ce234",
   "metadata": {
    "height": 81
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "      <th>response.relevance_to_prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what are the models used in biochemistry?</td>\n",
       "      <td>AlphaFold 3 is a model that predicts the struc...</td>\n",
       "      <td>0.449150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Which AI companies are working with U.S. gover...</td>\n",
       "      <td>Meta and Anthropic are working with the U.S. g...</td>\n",
       "      <td>0.556109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What can you tell me about a new Deepseek model?</td>\n",
       "      <td>DeepSeek released DeepSeek-R1, a large languag...</td>\n",
       "      <td>0.561104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "3          what are the models used in biochemistry?   \n",
       "2  Which AI companies are working with U.S. gover...   \n",
       "0   What can you tell me about a new Deepseek model?   \n",
       "\n",
       "                                            response  \\\n",
       "3  AlphaFold 3 is a model that predicts the struc...   \n",
       "2  Meta and Anthropic are working with the U.S. g...   \n",
       "0  DeepSeek released DeepSeek-R1, a large languag...   \n",
       "\n",
       "   response.relevance_to_prompt  \n",
       "3                      0.449150  \n",
       "2                      0.556109  \n",
       "0                      0.561104  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_langkit_critical_queries(\n",
    "    df,\n",
    "    \"response.relevance_to_prompt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9072f821-e26d-43ba-88e9-59f60cfcf1df",
   "metadata": {},
   "source": [
    "### Data Leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4139c04d-a2d1-4c7c-83a8-78c4206e2818",
   "metadata": {
    "height": 81
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div></div><iframe srcdoc=\"&lt;!DOCTYPE html&gt;\n",
       "&lt;html lang=&quot;en&quot;&gt;\n",
       "  &lt;head&gt;\n",
       "    &lt;meta charset=&quot;UTF-8&quot; /&gt;\n",
       "    &lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;IE=edge&quot; /&gt;\n",
       "    &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot; /&gt;\n",
       "    &lt;meta name=&quot;description&quot; content=&quot;&quot; /&gt;\n",
       "    &lt;meta name=&quot;author&quot; content=&quot;&quot; /&gt;\n",
       "\n",
       "    &lt;title&gt;Profile Visualizer | whylogs&lt;/title&gt;\n",
       "\n",
       "    &lt;link rel=&quot;icon&quot; href=&quot;images/whylabs-favicon.png&quot; type=&quot;image/png&quot; sizes=&quot;16x16&quot; /&gt;\n",
       "    &lt;link rel=&quot;preconnect&quot; href=&quot;https://fonts.googleapis.com&quot; /&gt;\n",
       "    &lt;link rel=&quot;preconnect&quot; href=&quot;https://fonts.gstatic.com&quot; crossorigin /&gt;\n",
       "    &lt;link href=&quot;https://fonts.googleapis.com/css2?family=Asap:wght@400;500;600;700&amp;display=swap&quot; rel=&quot;stylesheet&quot; /&gt;\n",
       "    &lt;link rel=&quot;preconnect&quot; href=&quot;https://fonts.gstatic.com&quot; /&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.1.0/dist/css/bootstrap.min.css&quot; /&gt;\n",
       "\n",
       "    &lt;script\n",
       "      src=&quot;https://cdnjs.cloudflare.com/ajax/libs/handlebars.js/4.7.7/handlebars.min.js&quot;\n",
       "      integrity=&quot;sha512-RNLkV3d+aLtfcpEyFG8jRbnWHxUqVZozacROI4J2F1sTaDqo1dPQYs01OMi1t1w9Y2FdbSCDSQ2ZVdAC8bzgAg==&quot;\n",
       "      crossorigin=&quot;anonymous&quot;\n",
       "      referrerpolicy=&quot;no-referrer&quot;\n",
       "    &gt;&lt;/script&gt;\n",
       "\n",
       "    &lt;style type=&quot;text/css&quot;&gt;\n",
       "\n",
       "      :root {\n",
       "        /** Branded colors */\n",
       "        --brandSecondary900: #4f595b;\n",
       "        --secondaryLight1000: #313b3d;\n",
       "        /** Purpose colors */\n",
       "        --tealBackground: #eaf2f3;\n",
       "      }\n",
       "\n",
       "      /* RESET STYLE */\n",
       "      *,\n",
       "      *::after,\n",
       "      *::before {\n",
       "        margin: 0;\n",
       "        padding: 0;\n",
       "        box-sizing: border-box;\n",
       "        overflow-y: hidden;\n",
       "      }\n",
       "\n",
       "      /* Screen on smaller screens */\n",
       "      .no-responsive {\n",
       "        display: none;\n",
       "        position: fixed;\n",
       "        top: 0;\n",
       "        left: 0;\n",
       "        z-index: 1031;\n",
       "        width: 100vw;\n",
       "        height: 100vh;\n",
       "        background-color: var(--tealBackground);\n",
       "        display: flex;\n",
       "        align-items: center;\n",
       "        justify-content: center;\n",
       "      }\n",
       "\n",
       "      .desktop-content {\n",
       "        display: flex;\n",
       "        flex-direction: column;\n",
       "      }\n",
       "\n",
       "      .no-responsive__content {\n",
       "        max-width: 600px;\n",
       "        width: 100%;\n",
       "        padding: 0 24px;\n",
       "      }\n",
       "\n",
       "      .no-responsive__title {\n",
       "        font-size: 96px;\n",
       "        font-weight: 300;\n",
       "        color: var(--brandSecondary900);\n",
       "        line-height: 1.167;\n",
       "      }\n",
       "\n",
       "      .no-responsive__text {\n",
       "        margin: 0;\n",
       "        font-size: 16px;\n",
       "        font-weight: 400;\n",
       "        color: var(--brandSecondary900);\n",
       "        line-height: 1.5;\n",
       "      }\n",
       "\n",
       "      .svg-container {\n",
       "        display: inline-block;\n",
       "        position: relative;\n",
       "        width: 100%;\n",
       "        vertical-align: top;\n",
       "        overflow: hidden;\n",
       "      }\n",
       "\n",
       "      .svg-content-responsive {\n",
       "        display: inline-block;\n",
       "        position: absolute;\n",
       "        left: 0;\n",
       "      }\n",
       "\n",
       "      .circle-color {\n",
       "       display: inline-block;\n",
       "       padding: 5px;\n",
       "       border-radius: 50px;\n",
       "     }\n",
       "\n",
       "     .colors-for-distingushing-charts {\n",
       "       padding-right: 10px;\n",
       "     }\n",
       "\n",
       "     .display-flex{\n",
       "       display: flex;\n",
       "     }\n",
       "\n",
       "     .flex-direction-column {\n",
       "       flex-direction: column;\n",
       "     }\n",
       "\n",
       "     .align-items-flex-end {\n",
       "       align-items: flex-end;\n",
       "     }\n",
       "\n",
       "     .chart-box-title {\n",
       "       width: 98%;\n",
       "       justify-content: space-between;\n",
       "       margin: 10px;\n",
       "       margin-top: 15px;\n",
       "       bottom: 0;\n",
       "     }\n",
       "\n",
       "     .chart-box-title p{\n",
       "       margin-bottom: 0;\n",
       "       font-family: Asap;\n",
       "       font-weight: bold;\n",
       "       font-size: 18px;\n",
       "       line-height: 16px;\n",
       "       color: #4F595B;\n",
       "     }\n",
       "\n",
       "     .error-message {\n",
       "       display: flex;\n",
       "       justify-content: center;\n",
       "       align-items: center;\n",
       "       color: rgb(255, 114, 71);\n",
       "       font-size: 30px;\n",
       "       font-weight: 900;\n",
       "     }\n",
       "\n",
       "     @media screen and (min-width: 500px) {\n",
       "       .desktop-content {\n",
       "         display: block;\n",
       "       }\n",
       "       .no-responsive {\n",
       "         display: none;\n",
       "       }\n",
       "     }\n",
       "    &lt;/style&gt;\n",
       "  &lt;/head&gt;\n",
       "\n",
       "  &lt;body id=&quot;generated-html&quot;&gt;&lt;/body&gt;\n",
       "  &lt;script id=&quot;entry-template&quot; type=&quot;text/x-handlebars-template&quot;&gt;\n",
       "    \n",
       "      &lt;div class=&quot;desktop-content&quot;&gt;\n",
       "{{#each this}}              &lt;div class=&quot;chart-box&quot; id=&quot;chart-box&quot;&gt;\n",
       "                &lt;div class=&quot;chart-box-title display-flex&quot;&gt;\n",
       "                  &lt;p&gt;{{@key}}&lt;/p&gt;\n",
       "                  &lt;div class=&quot;display-flex&quot;&gt;\n",
       "                    &lt;div class=&quot;colors-for-distingushing-charts&quot;&gt;\n",
       "                      &lt;div class=&quot;circle-color&quot; style=&quot;background: #44C0E7;&quot;&gt;&lt;/div&gt;\n",
       "                      &lt;text alignment-baseline=&quot;middle&quot; style=&quot;font-size: 15px;&quot;&gt;Target&lt;/text&gt;\n",
       "                    &lt;/div&gt;\n",
       "                    &lt;div class=&quot;colors-for-distingushing-charts&quot;&gt;\n",
       "                      &lt;div class=&quot;circle-color&quot; style=&quot;background: #F5843C&quot;&gt;&lt;/div&gt;\n",
       "                      &lt;text alignment-baseline=&quot;middle&quot; style=&quot;font-size: 15px;&quot;&gt;Reference&lt;/text&gt;\n",
       "                    &lt;/div&gt;\n",
       "                  &lt;/div&gt;&lt;/div&gt;\n",
       "                &lt;div class=&quot;svg-container&quot;&gt;\n",
       "                  {{{getDoubleHistogramChart this}}}\n",
       "                &lt;/div&gt;\n",
       "              &lt;/div&gt;\n",
       "{{/each}}      &lt;/div&gt;\n",
       "      &lt;div class=&quot;no-responsive&quot;&gt;\n",
       "        &lt;div class=&quot;no-responsive__content&quot;&gt;\n",
       "          &lt;h1 class=&quot;no-responsive__title&quot;&gt;Hold on! :)&lt;/h1&gt;\n",
       "          &lt;p class=&quot;no-responsive__text&quot;&gt;\n",
       "            It looks like your current screen size or device is not yet supported by the WhyLabs Sandbox. The Sandbox is\n",
       "            best experienced on a desktop computer. Please try maximizing this window or switching to another device. We\n",
       "            are working on adding support for a larger variety of devices.\n",
       "          &lt;/p&gt;\n",
       "        &lt;/div&gt;\n",
       "      &lt;/div&gt;\n",
       "    \n",
       "  &lt;/script&gt;\n",
       "\n",
       "  &lt;script src=&quot;https://code.jquery.com/jquery-3.6.0.min.js&quot; integrity=&quot;sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=&quot; crossorigin=&quot;anonymous&quot;&gt;&lt;/script&gt;\n",
       "\n",
       "  &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/d3/6.7.0/d3.min.js&quot; integrity=&quot;sha512-cd6CHE+XWDQ33ElJqsi0MdNte3S+bQY819f7p3NUHgwQQLXSKjE4cPZTeGNI+vaxZynk1wVU3hoHmow3m089wA==&quot; crossorigin=&quot;anonymous&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/script&gt;\n",
       "\n",
       "  &lt;script&gt;\n",
       "   function registerHandlebarHelperFunctions() {\n",
       "\n",
       "    const findAndDeleteUndefined = (axisData) =&gt; {\n",
       "      const undefinedAxisIndex = axisData.findIndex((axis) =&gt; axis === undefined)\n",
       "      if (undefinedAxisIndex == -1) {\n",
       "        return axisData;\n",
       "      }\n",
       "\n",
       "      const result = [...axisData.slice(0, undefinedAxisIndex), ...axisData.slice(undefinedAxisIndex + 1)]\n",
       "      return result\n",
       "    }\n",
       "\n",
       "    const filterAndSortChartData = (overlappedHistogramData, histogramData) =&gt; {\n",
       "        const filteredData = overlappedHistogramData\n",
       "          .map((d) =&gt;\n",
       "            histogramData\n",
       "            .filter((ref) =&gt; d.axisX === ref.axisX )[0])\n",
       "            .sort((a, b) =&gt; {\n",
       "              if (+a.axisY &lt; +b.axisY) {\n",
       "                return 1;\n",
       "              }\n",
       "              if (+a.axisY &gt; +b.axisY) {\n",
       "                return -1;\n",
       "              }\n",
       "\n",
       "              return 0;\n",
       "            })\n",
       "            .slice(0, 20)\n",
       "\n",
       "        return findAndDeleteUndefined(filteredData)\n",
       "      }\n",
       "\n",
       "      class GenerateChartParams {\n",
       "        constructor(height, width, data, referenceData, bottomMargin=30, topMargin=5) {\n",
       "          this.MARGIN = {\n",
       "            TOP: topMargin,\n",
       "            RIGHT: 5,\n",
       "            BOTTOM: bottomMargin,\n",
       "            LEFT: 55,\n",
       "          };\n",
       "          this.SVG_WIDTH = width;\n",
       "          this.SVG_HEIGHT = height;\n",
       "          this.CHART_WIDTH = this.SVG_WIDTH - this.MARGIN.LEFT - this.MARGIN.RIGHT;\n",
       "          this.CHART_HEIGHT = this.SVG_HEIGHT - this.MARGIN.TOP - this.MARGIN.BOTTOM;\n",
       "          this.svgEl = d3.create(&quot;svg&quot;)\n",
       "             .attr(&quot;preserveAspectRatio&quot;, &quot;xMinYMin meet&quot;)\n",
       "             .attr(&quot;viewBox&quot;, `0 0 ${$(window).width()} ${$(window).height()-30}`)\n",
       "             .classed(&quot;svg-content-responsive&quot;, true)\n",
       "          this.maxYValue = d3.max([...data, ...referenceData], (d) =&gt; Math.abs(d.axisY));\n",
       "          this.xScale = d3\n",
       "            .scaleBand()\n",
       "            .domain(filterAndSortChartData(data, referenceData).map((sortedCounts) =&gt; sortedCounts?.axisX))\n",
       "            .range([this.MARGIN.LEFT, this.MARGIN.LEFT + this.CHART_WIDTH]);\n",
       "          this.yScale = d3\n",
       "            .scaleLinear()\n",
       "            .domain([0, this.maxYValue * 1.2])\n",
       "            .range([this.CHART_HEIGHT, 0]);\n",
       "        }\n",
       "      }\n",
       "\n",
       "      function chartData(column) {\n",
       "        const data = [];\n",
       "          if (column.frequentItems) {\n",
       "            Object.entries(column.frequentItems).forEach(([key, {value, estimate}], index) =&gt; {\n",
       "              data.push({\n",
       "                axisY: estimate,\n",
       "                axisX: value,\n",
       "              });\n",
       "            });\n",
       "          } else {\n",
       "            $(document).ready(() =&gt;\n",
       "              $(&quot;.desktop-content&quot;).html(`\n",
       "                &lt;p style=&quot;height: ${$(window).height()}px&quot; class=&quot;error-message&quot;&gt;\n",
       "                  Something went wrong. Please try again.\n",
       "                &lt;/p&gt;\n",
       "              `)\n",
       "            )\n",
       "          }\n",
       "\n",
       "        return data\n",
       "      }\n",
       "\n",
       "      function generateBarChart(histogramData, overlappedHistogramData) {\n",
       "        let yFormat,\n",
       "            xFormat;\n",
       "        const data = filterAndSortChartData(chartData(histogramData), chartData(overlappedHistogramData)).map((axis, index) =&gt; {\n",
       "          if (axis) {\n",
       "            const findIndex = chartData(histogramData).findIndex((value) =&gt; value.axisX === axis.axisX)\n",
       "            return {\n",
       "              group: axis.axisX,\n",
       "              profile: axis.axisY,\n",
       "              reference_profile: chartData(histogramData)[findIndex].axisY\n",
       "            }\n",
       "          }\n",
       "          return 0;\n",
       "        })\n",
       "\n",
       "        const sizes = new GenerateChartParams($(window).height()-60, $(window).width(), chartData(histogramData), chartData(overlappedHistogramData))\n",
       "        let {\n",
       "          MARGIN,\n",
       "          SVG_WIDTH,\n",
       "          SVG_HEIGHT,\n",
       "          CHART_WIDTH,\n",
       "          CHART_HEIGHT,\n",
       "          svgEl,\n",
       "          xScale,\n",
       "          yScale\n",
       "        } = sizes\n",
       "\n",
       "        const rectColors = [&quot;#44C0E7&quot;, &quot;#F5843C&quot;]\n",
       "        const subgroups = [&#x27;reference_profile&#x27;, &#x27;profile&#x27;]\n",
       "\n",
       "        xScale.padding([0.3])\n",
       "\n",
       "        const xAxis = d3.axisBottom(xScale).ticks(SVG_WIDTH / 80, xFormat).tickSizeOuter(0);\n",
       "        const yAxis = d3.axisLeft(yScale).ticks(SVG_HEIGHT / 40, yFormat);\n",
       "        yFormat = yScale.tickFormat(100, yFormat);\n",
       "\n",
       "        svgEl.append(&quot;g&quot;)\n",
       "          .attr(&quot;transform&quot;, `translate(${MARGIN.LEFT}, 0)`)\n",
       "          .attr(&quot;id&quot;, &quot;g1&quot;)\n",
       "          .call(yAxis)\n",
       "          .call(g =&gt; g.select(&quot;.domain&quot;).remove())\n",
       "          .call(g =&gt; g.selectAll(&quot;.tick line&quot;)\n",
       "              .attr(&quot;x2&quot;, CHART_WIDTH)\n",
       "              .attr(&quot;stroke-opacity&quot;, 0.1))\n",
       "          .call(g =&gt; g.append(&quot;text&quot;)\n",
       "              .attr(&quot;x&quot;, -MARGIN.LEFT)\n",
       "              .attr(&quot;y&quot;, 10)\n",
       "              .attr(&quot;fill&quot;, &quot;currentColor&quot;)\n",
       "              .attr(&quot;text-anchor&quot;, &quot;start&quot;));\n",
       "\n",
       "        svgEl.append(&quot;text&quot;)\n",
       "          .attr(&quot;transform&quot;,\n",
       "                &quot;translate(&quot; + (CHART_WIDTH/2) + &quot; ,&quot; +\n",
       "                               (CHART_HEIGHT + MARGIN.TOP + 40) + &quot;)&quot;)\n",
       "          .style(&quot;text-anchor&quot;, &quot;middle&quot;)\n",
       "          .text(&quot;Values&quot;)\n",
       "          .style(&quot;font-size&quot;, &quot;15&quot;)\n",
       "          .style(&quot;opacity&quot;, &quot;0.6&quot;)\n",
       "\n",
       "        svgEl.append(&quot;text&quot;)\n",
       "          .attr(&quot;transform&quot;, &quot;rotate(-90)&quot;)\n",
       "          .attr(&quot;y&quot;, 0)\n",
       "          .attr(&quot;x&quot;, 0 - (SVG_HEIGHT / 2))\n",
       "          .attr(&quot;dy&quot;, &quot;1em&quot;)\n",
       "          .style(&quot;text-anchor&quot;, &quot;middle&quot;)\n",
       "          .text(&quot;Counts&quot;)\n",
       "          .style(&quot;font-size&quot;, &quot;15&quot;)\n",
       "          .style(&quot;opacity&quot;, &quot;0.6&quot;)\n",
       "\n",
       "        svgEl.append(&quot;g&quot;)\n",
       "            .attr(&quot;transform&quot;, `translate(0,${SVG_HEIGHT - MARGIN.BOTTOM})`)\n",
       "            .attr(&quot;id&quot;, &quot;g2&quot;)\n",
       "            .call(xAxis)\n",
       "            .call(g =&gt; g.select(&quot;.domain&quot;).remove())\n",
       "            .call(g =&gt; g.selectAll(&quot;.tick line&quot;).remove())\n",
       "            .call(g =&gt; g.append(&quot;text&quot;)\n",
       "                .attr(&quot;x&quot;, SVG_WIDTH - MARGIN.RIGHT)\n",
       "                .attr(&quot;y&quot;, 27)\n",
       "                .attr(&quot;fill&quot;, &quot;currentColor&quot;)\n",
       "                .attr(&quot;text-anchor&quot;, &quot;end&quot;));\n",
       "\n",
       "        const xSubgroup = d3.scaleBand()\n",
       "          .domain(subgroups)\n",
       "          .range([0, xScale.bandwidth()])\n",
       "\n",
       "        const color = d3.scaleOrdinal()\n",
       "          .domain(subgroups)\n",
       "          .range(rectColors)\n",
       "\n",
       "        svgEl.append(&quot;g&quot;)\n",
       "           .attr(&quot;id&quot;, &quot;g3&quot;)\n",
       "           .selectAll(&quot;g&quot;)\n",
       "           .data(data)\n",
       "           .enter()\n",
       "           .append(&quot;g&quot;)\n",
       "             .attr(&quot;transform&quot;, function(d) { return &quot;translate(&quot; + xScale(d?.group) + &quot;,0)&quot;; })\n",
       "             .attr(&quot;id&quot;, &quot;g4&quot;)\n",
       "           .selectAll(&quot;rect&quot;)\n",
       "           .data(function(d) { return subgroups.map(function(key) { return {key: key, value: d &amp;&amp; d[key]}; }); })\n",
       "           .enter().append(&quot;rect&quot;)\n",
       "             .attr(&quot;x&quot;, function(d) { return xSubgroup(d.key); })\n",
       "             .attr(&quot;y&quot;, function(d) { return yScale(d.value); })\n",
       "             .attr(&quot;width&quot;, xSubgroup.bandwidth())\n",
       "             .attr(&quot;height&quot;, function(d) { return (CHART_HEIGHT - yScale(d.value)); })\n",
       "             .attr(&quot;fill&quot;, function(d) { return color(d.key); })\n",
       "             .style(&quot;opacity&quot;, &quot;0.8&quot;);\n",
       "\n",
       "\n",
       "         return svgEl._groups[0][0].outerHTML;\n",
       "      }\n",
       "\n",
       "\n",
       "      const profileFromCSVfile = {&quot;prompt.has_patterns&quot;: {&quot;frequentItems&quot;: []}}\n",
       "\n",
       "      Handlebars.registerHelper(&quot;getDoubleHistogramChart&quot;,(column,key) =&gt; {\n",
       "        const columnKey = key.data.key\n",
       "        try {\n",
       "          if (profileFromCSVfile) {\n",
       "            return generateBarChart(\n",
       "                     column,\n",
       "                     profileFromCSVfile[columnKey]\n",
       "                   )\n",
       "          }\n",
       "        } catch (err) {\n",
       "          $(document).ready(() =&gt;\n",
       "            $(&quot;.desktop-content&quot;).html(`\n",
       "              &lt;p style=&quot;height: ${$(window).height()}px&quot; class=&quot;error-message&quot;&gt;\n",
       "                Something went wrong. Please try again.\n",
       "              &lt;/p&gt;\n",
       "            `)\n",
       "          )\n",
       "        }\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function initWebsiteScripts() {\n",
       "      $(&quot;.svg-container&quot;).css(&quot;height&quot;, $(window).height() - 32)\n",
       "    }\n",
       "\n",
       "    function initHandlebarsTemplate() {\n",
       "      // Replace this context with JSON from .py file\n",
       "      const context = {&quot;prompt.has_patterns&quot;: {&quot;frequentItems&quot;: []}};\n",
       "      // Config handlebars and pass data to HBS template\n",
       "      const source = document.getElementById(&quot;entry-template&quot;).innerHTML;\n",
       "      const template = Handlebars.compile(source);\n",
       "      const html = template(context);\n",
       "      const target = document.getElementById(&quot;generated-html&quot;);\n",
       "      target.innerHTML = html;\n",
       "    }\n",
       "\n",
       "    // Invoke functions -- keep in mind invokation order\n",
       "    registerHandlebarHelperFunctions();\n",
       "    initHandlebarsTemplate();\n",
       "    initWebsiteScripts();\n",
       "  &lt;/script&gt;\n",
       "&lt;/html&gt;\n",
       "\" width=100% height=277px\n",
       "        frameBorder=0></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visualize_langkit_metric(\n",
    "    df,\n",
    "    \"prompt.has_patterns\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "73d0e55c-917e-4bf7-a11c-1335949345d8",
   "metadata": {
    "height": 64
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div></div><iframe srcdoc=\"&lt;!DOCTYPE html&gt;\n",
       "&lt;html lang=&quot;en&quot;&gt;\n",
       "  &lt;head&gt;\n",
       "    &lt;meta charset=&quot;UTF-8&quot; /&gt;\n",
       "    &lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;IE=edge&quot; /&gt;\n",
       "    &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot; /&gt;\n",
       "    &lt;meta name=&quot;description&quot; content=&quot;&quot; /&gt;\n",
       "    &lt;meta name=&quot;author&quot; content=&quot;&quot; /&gt;\n",
       "\n",
       "    &lt;title&gt;Profile Visualizer | whylogs&lt;/title&gt;\n",
       "\n",
       "    &lt;link rel=&quot;icon&quot; href=&quot;images/whylabs-favicon.png&quot; type=&quot;image/png&quot; sizes=&quot;16x16&quot; /&gt;\n",
       "    &lt;link rel=&quot;preconnect&quot; href=&quot;https://fonts.googleapis.com&quot; /&gt;\n",
       "    &lt;link rel=&quot;preconnect&quot; href=&quot;https://fonts.gstatic.com&quot; crossorigin /&gt;\n",
       "    &lt;link href=&quot;https://fonts.googleapis.com/css2?family=Asap:wght@400;500;600;700&amp;display=swap&quot; rel=&quot;stylesheet&quot; /&gt;\n",
       "    &lt;link rel=&quot;preconnect&quot; href=&quot;https://fonts.gstatic.com&quot; /&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.1.0/dist/css/bootstrap.min.css&quot; /&gt;\n",
       "\n",
       "    &lt;script\n",
       "      src=&quot;https://cdnjs.cloudflare.com/ajax/libs/handlebars.js/4.7.7/handlebars.min.js&quot;\n",
       "      integrity=&quot;sha512-RNLkV3d+aLtfcpEyFG8jRbnWHxUqVZozacROI4J2F1sTaDqo1dPQYs01OMi1t1w9Y2FdbSCDSQ2ZVdAC8bzgAg==&quot;\n",
       "      crossorigin=&quot;anonymous&quot;\n",
       "      referrerpolicy=&quot;no-referrer&quot;\n",
       "    &gt;&lt;/script&gt;\n",
       "\n",
       "    &lt;style type=&quot;text/css&quot;&gt;\n",
       "\n",
       "      :root {\n",
       "        /** Branded colors */\n",
       "        --brandSecondary900: #4f595b;\n",
       "        --secondaryLight1000: #313b3d;\n",
       "        /** Purpose colors */\n",
       "        --tealBackground: #eaf2f3;\n",
       "      }\n",
       "\n",
       "      /* RESET STYLE */\n",
       "      *,\n",
       "      *::after,\n",
       "      *::before {\n",
       "        margin: 0;\n",
       "        padding: 0;\n",
       "        box-sizing: border-box;\n",
       "        overflow-y: hidden;\n",
       "      }\n",
       "\n",
       "      /* Screen on smaller screens */\n",
       "      .no-responsive {\n",
       "        display: none;\n",
       "        position: fixed;\n",
       "        top: 0;\n",
       "        left: 0;\n",
       "        z-index: 1031;\n",
       "        width: 100vw;\n",
       "        height: 100vh;\n",
       "        background-color: var(--tealBackground);\n",
       "        display: flex;\n",
       "        align-items: center;\n",
       "        justify-content: center;\n",
       "      }\n",
       "\n",
       "      .desktop-content {\n",
       "        display: flex;\n",
       "        flex-direction: column;\n",
       "      }\n",
       "\n",
       "      .no-responsive__content {\n",
       "        max-width: 600px;\n",
       "        width: 100%;\n",
       "        padding: 0 24px;\n",
       "      }\n",
       "\n",
       "      .no-responsive__title {\n",
       "        font-size: 96px;\n",
       "        font-weight: 300;\n",
       "        color: var(--brandSecondary900);\n",
       "        line-height: 1.167;\n",
       "      }\n",
       "\n",
       "      .no-responsive__text {\n",
       "        margin: 0;\n",
       "        font-size: 16px;\n",
       "        font-weight: 400;\n",
       "        color: var(--brandSecondary900);\n",
       "        line-height: 1.5;\n",
       "      }\n",
       "\n",
       "      .svg-container {\n",
       "        display: inline-block;\n",
       "        position: relative;\n",
       "        width: 100%;\n",
       "        vertical-align: top;\n",
       "        overflow: hidden;\n",
       "      }\n",
       "\n",
       "      .svg-content-responsive {\n",
       "        display: inline-block;\n",
       "        position: absolute;\n",
       "        left: 0;\n",
       "      }\n",
       "\n",
       "      .circle-color {\n",
       "       display: inline-block;\n",
       "       padding: 5px;\n",
       "       border-radius: 50px;\n",
       "     }\n",
       "\n",
       "     .colors-for-distingushing-charts {\n",
       "       padding-right: 10px;\n",
       "     }\n",
       "\n",
       "     .display-flex{\n",
       "       display: flex;\n",
       "     }\n",
       "\n",
       "     .flex-direction-column {\n",
       "       flex-direction: column;\n",
       "     }\n",
       "\n",
       "     .align-items-flex-end {\n",
       "       align-items: flex-end;\n",
       "     }\n",
       "\n",
       "     .chart-box-title {\n",
       "       width: 98%;\n",
       "       justify-content: space-between;\n",
       "       margin: 10px;\n",
       "       margin-top: 15px;\n",
       "       bottom: 0;\n",
       "     }\n",
       "\n",
       "     .chart-box-title p{\n",
       "       margin-bottom: 0;\n",
       "       font-family: Asap;\n",
       "       font-weight: bold;\n",
       "       font-size: 18px;\n",
       "       line-height: 16px;\n",
       "       color: #4F595B;\n",
       "     }\n",
       "\n",
       "     .error-message {\n",
       "       display: flex;\n",
       "       justify-content: center;\n",
       "       align-items: center;\n",
       "       color: rgb(255, 114, 71);\n",
       "       font-size: 30px;\n",
       "       font-weight: 900;\n",
       "     }\n",
       "\n",
       "     @media screen and (min-width: 500px) {\n",
       "       .desktop-content {\n",
       "         display: block;\n",
       "       }\n",
       "       .no-responsive {\n",
       "         display: none;\n",
       "       }\n",
       "     }\n",
       "    &lt;/style&gt;\n",
       "  &lt;/head&gt;\n",
       "\n",
       "  &lt;body id=&quot;generated-html&quot;&gt;&lt;/body&gt;\n",
       "  &lt;script id=&quot;entry-template&quot; type=&quot;text/x-handlebars-template&quot;&gt;\n",
       "    \n",
       "      &lt;div class=&quot;desktop-content&quot;&gt;\n",
       "{{#each this}}              &lt;div class=&quot;chart-box&quot; id=&quot;chart-box&quot;&gt;\n",
       "                &lt;div class=&quot;chart-box-title display-flex&quot;&gt;\n",
       "                  &lt;p&gt;{{@key}}&lt;/p&gt;\n",
       "                  &lt;div class=&quot;display-flex&quot;&gt;\n",
       "                    &lt;div class=&quot;colors-for-distingushing-charts&quot;&gt;\n",
       "                      &lt;div class=&quot;circle-color&quot; style=&quot;background: #44C0E7;&quot;&gt;&lt;/div&gt;\n",
       "                      &lt;text alignment-baseline=&quot;middle&quot; style=&quot;font-size: 15px;&quot;&gt;Target&lt;/text&gt;\n",
       "                    &lt;/div&gt;\n",
       "                    &lt;div class=&quot;colors-for-distingushing-charts&quot;&gt;\n",
       "                      &lt;div class=&quot;circle-color&quot; style=&quot;background: #F5843C&quot;&gt;&lt;/div&gt;\n",
       "                      &lt;text alignment-baseline=&quot;middle&quot; style=&quot;font-size: 15px;&quot;&gt;Reference&lt;/text&gt;\n",
       "                    &lt;/div&gt;\n",
       "                  &lt;/div&gt;&lt;/div&gt;\n",
       "                &lt;div class=&quot;svg-container&quot;&gt;\n",
       "                  {{{getDoubleHistogramChart this}}}\n",
       "                &lt;/div&gt;\n",
       "              &lt;/div&gt;\n",
       "{{/each}}      &lt;/div&gt;\n",
       "      &lt;div class=&quot;no-responsive&quot;&gt;\n",
       "        &lt;div class=&quot;no-responsive__content&quot;&gt;\n",
       "          &lt;h1 class=&quot;no-responsive__title&quot;&gt;Hold on! :)&lt;/h1&gt;\n",
       "          &lt;p class=&quot;no-responsive__text&quot;&gt;\n",
       "            It looks like your current screen size or device is not yet supported by the WhyLabs Sandbox. The Sandbox is\n",
       "            best experienced on a desktop computer. Please try maximizing this window or switching to another device. We\n",
       "            are working on adding support for a larger variety of devices.\n",
       "          &lt;/p&gt;\n",
       "        &lt;/div&gt;\n",
       "      &lt;/div&gt;\n",
       "    \n",
       "  &lt;/script&gt;\n",
       "\n",
       "  &lt;script src=&quot;https://code.jquery.com/jquery-3.6.0.min.js&quot; integrity=&quot;sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=&quot; crossorigin=&quot;anonymous&quot;&gt;&lt;/script&gt;\n",
       "\n",
       "  &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/d3/6.7.0/d3.min.js&quot; integrity=&quot;sha512-cd6CHE+XWDQ33ElJqsi0MdNte3S+bQY819f7p3NUHgwQQLXSKjE4cPZTeGNI+vaxZynk1wVU3hoHmow3m089wA==&quot; crossorigin=&quot;anonymous&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/script&gt;\n",
       "\n",
       "  &lt;script&gt;\n",
       "   function registerHandlebarHelperFunctions() {\n",
       "\n",
       "    const findAndDeleteUndefined = (axisData) =&gt; {\n",
       "      const undefinedAxisIndex = axisData.findIndex((axis) =&gt; axis === undefined)\n",
       "      if (undefinedAxisIndex == -1) {\n",
       "        return axisData;\n",
       "      }\n",
       "\n",
       "      const result = [...axisData.slice(0, undefinedAxisIndex), ...axisData.slice(undefinedAxisIndex + 1)]\n",
       "      return result\n",
       "    }\n",
       "\n",
       "    const filterAndSortChartData = (overlappedHistogramData, histogramData) =&gt; {\n",
       "        const filteredData = overlappedHistogramData\n",
       "          .map((d) =&gt;\n",
       "            histogramData\n",
       "            .filter((ref) =&gt; d.axisX === ref.axisX )[0])\n",
       "            .sort((a, b) =&gt; {\n",
       "              if (+a.axisY &lt; +b.axisY) {\n",
       "                return 1;\n",
       "              }\n",
       "              if (+a.axisY &gt; +b.axisY) {\n",
       "                return -1;\n",
       "              }\n",
       "\n",
       "              return 0;\n",
       "            })\n",
       "            .slice(0, 20)\n",
       "\n",
       "        return findAndDeleteUndefined(filteredData)\n",
       "      }\n",
       "\n",
       "      class GenerateChartParams {\n",
       "        constructor(height, width, data, referenceData, bottomMargin=30, topMargin=5) {\n",
       "          this.MARGIN = {\n",
       "            TOP: topMargin,\n",
       "            RIGHT: 5,\n",
       "            BOTTOM: bottomMargin,\n",
       "            LEFT: 55,\n",
       "          };\n",
       "          this.SVG_WIDTH = width;\n",
       "          this.SVG_HEIGHT = height;\n",
       "          this.CHART_WIDTH = this.SVG_WIDTH - this.MARGIN.LEFT - this.MARGIN.RIGHT;\n",
       "          this.CHART_HEIGHT = this.SVG_HEIGHT - this.MARGIN.TOP - this.MARGIN.BOTTOM;\n",
       "          this.svgEl = d3.create(&quot;svg&quot;)\n",
       "             .attr(&quot;preserveAspectRatio&quot;, &quot;xMinYMin meet&quot;)\n",
       "             .attr(&quot;viewBox&quot;, `0 0 ${$(window).width()} ${$(window).height()-30}`)\n",
       "             .classed(&quot;svg-content-responsive&quot;, true)\n",
       "          this.maxYValue = d3.max([...data, ...referenceData], (d) =&gt; Math.abs(d.axisY));\n",
       "          this.xScale = d3\n",
       "            .scaleBand()\n",
       "            .domain(filterAndSortChartData(data, referenceData).map((sortedCounts) =&gt; sortedCounts?.axisX))\n",
       "            .range([this.MARGIN.LEFT, this.MARGIN.LEFT + this.CHART_WIDTH]);\n",
       "          this.yScale = d3\n",
       "            .scaleLinear()\n",
       "            .domain([0, this.maxYValue * 1.2])\n",
       "            .range([this.CHART_HEIGHT, 0]);\n",
       "        }\n",
       "      }\n",
       "\n",
       "      function chartData(column) {\n",
       "        const data = [];\n",
       "          if (column.frequentItems) {\n",
       "            Object.entries(column.frequentItems).forEach(([key, {value, estimate}], index) =&gt; {\n",
       "              data.push({\n",
       "                axisY: estimate,\n",
       "                axisX: value,\n",
       "              });\n",
       "            });\n",
       "          } else {\n",
       "            $(document).ready(() =&gt;\n",
       "              $(&quot;.desktop-content&quot;).html(`\n",
       "                &lt;p style=&quot;height: ${$(window).height()}px&quot; class=&quot;error-message&quot;&gt;\n",
       "                  Something went wrong. Please try again.\n",
       "                &lt;/p&gt;\n",
       "              `)\n",
       "            )\n",
       "          }\n",
       "\n",
       "        return data\n",
       "      }\n",
       "\n",
       "      function generateBarChart(histogramData, overlappedHistogramData) {\n",
       "        let yFormat,\n",
       "            xFormat;\n",
       "        const data = filterAndSortChartData(chartData(histogramData), chartData(overlappedHistogramData)).map((axis, index) =&gt; {\n",
       "          if (axis) {\n",
       "            const findIndex = chartData(histogramData).findIndex((value) =&gt; value.axisX === axis.axisX)\n",
       "            return {\n",
       "              group: axis.axisX,\n",
       "              profile: axis.axisY,\n",
       "              reference_profile: chartData(histogramData)[findIndex].axisY\n",
       "            }\n",
       "          }\n",
       "          return 0;\n",
       "        })\n",
       "\n",
       "        const sizes = new GenerateChartParams($(window).height()-60, $(window).width(), chartData(histogramData), chartData(overlappedHistogramData))\n",
       "        let {\n",
       "          MARGIN,\n",
       "          SVG_WIDTH,\n",
       "          SVG_HEIGHT,\n",
       "          CHART_WIDTH,\n",
       "          CHART_HEIGHT,\n",
       "          svgEl,\n",
       "          xScale,\n",
       "          yScale\n",
       "        } = sizes\n",
       "\n",
       "        const rectColors = [&quot;#44C0E7&quot;, &quot;#F5843C&quot;]\n",
       "        const subgroups = [&#x27;reference_profile&#x27;, &#x27;profile&#x27;]\n",
       "\n",
       "        xScale.padding([0.3])\n",
       "\n",
       "        const xAxis = d3.axisBottom(xScale).ticks(SVG_WIDTH / 80, xFormat).tickSizeOuter(0);\n",
       "        const yAxis = d3.axisLeft(yScale).ticks(SVG_HEIGHT / 40, yFormat);\n",
       "        yFormat = yScale.tickFormat(100, yFormat);\n",
       "\n",
       "        svgEl.append(&quot;g&quot;)\n",
       "          .attr(&quot;transform&quot;, `translate(${MARGIN.LEFT}, 0)`)\n",
       "          .attr(&quot;id&quot;, &quot;g1&quot;)\n",
       "          .call(yAxis)\n",
       "          .call(g =&gt; g.select(&quot;.domain&quot;).remove())\n",
       "          .call(g =&gt; g.selectAll(&quot;.tick line&quot;)\n",
       "              .attr(&quot;x2&quot;, CHART_WIDTH)\n",
       "              .attr(&quot;stroke-opacity&quot;, 0.1))\n",
       "          .call(g =&gt; g.append(&quot;text&quot;)\n",
       "              .attr(&quot;x&quot;, -MARGIN.LEFT)\n",
       "              .attr(&quot;y&quot;, 10)\n",
       "              .attr(&quot;fill&quot;, &quot;currentColor&quot;)\n",
       "              .attr(&quot;text-anchor&quot;, &quot;start&quot;));\n",
       "\n",
       "        svgEl.append(&quot;text&quot;)\n",
       "          .attr(&quot;transform&quot;,\n",
       "                &quot;translate(&quot; + (CHART_WIDTH/2) + &quot; ,&quot; +\n",
       "                               (CHART_HEIGHT + MARGIN.TOP + 40) + &quot;)&quot;)\n",
       "          .style(&quot;text-anchor&quot;, &quot;middle&quot;)\n",
       "          .text(&quot;Values&quot;)\n",
       "          .style(&quot;font-size&quot;, &quot;15&quot;)\n",
       "          .style(&quot;opacity&quot;, &quot;0.6&quot;)\n",
       "\n",
       "        svgEl.append(&quot;text&quot;)\n",
       "          .attr(&quot;transform&quot;, &quot;rotate(-90)&quot;)\n",
       "          .attr(&quot;y&quot;, 0)\n",
       "          .attr(&quot;x&quot;, 0 - (SVG_HEIGHT / 2))\n",
       "          .attr(&quot;dy&quot;, &quot;1em&quot;)\n",
       "          .style(&quot;text-anchor&quot;, &quot;middle&quot;)\n",
       "          .text(&quot;Counts&quot;)\n",
       "          .style(&quot;font-size&quot;, &quot;15&quot;)\n",
       "          .style(&quot;opacity&quot;, &quot;0.6&quot;)\n",
       "\n",
       "        svgEl.append(&quot;g&quot;)\n",
       "            .attr(&quot;transform&quot;, `translate(0,${SVG_HEIGHT - MARGIN.BOTTOM})`)\n",
       "            .attr(&quot;id&quot;, &quot;g2&quot;)\n",
       "            .call(xAxis)\n",
       "            .call(g =&gt; g.select(&quot;.domain&quot;).remove())\n",
       "            .call(g =&gt; g.selectAll(&quot;.tick line&quot;).remove())\n",
       "            .call(g =&gt; g.append(&quot;text&quot;)\n",
       "                .attr(&quot;x&quot;, SVG_WIDTH - MARGIN.RIGHT)\n",
       "                .attr(&quot;y&quot;, 27)\n",
       "                .attr(&quot;fill&quot;, &quot;currentColor&quot;)\n",
       "                .attr(&quot;text-anchor&quot;, &quot;end&quot;));\n",
       "\n",
       "        const xSubgroup = d3.scaleBand()\n",
       "          .domain(subgroups)\n",
       "          .range([0, xScale.bandwidth()])\n",
       "\n",
       "        const color = d3.scaleOrdinal()\n",
       "          .domain(subgroups)\n",
       "          .range(rectColors)\n",
       "\n",
       "        svgEl.append(&quot;g&quot;)\n",
       "           .attr(&quot;id&quot;, &quot;g3&quot;)\n",
       "           .selectAll(&quot;g&quot;)\n",
       "           .data(data)\n",
       "           .enter()\n",
       "           .append(&quot;g&quot;)\n",
       "             .attr(&quot;transform&quot;, function(d) { return &quot;translate(&quot; + xScale(d?.group) + &quot;,0)&quot;; })\n",
       "             .attr(&quot;id&quot;, &quot;g4&quot;)\n",
       "           .selectAll(&quot;rect&quot;)\n",
       "           .data(function(d) { return subgroups.map(function(key) { return {key: key, value: d &amp;&amp; d[key]}; }); })\n",
       "           .enter().append(&quot;rect&quot;)\n",
       "             .attr(&quot;x&quot;, function(d) { return xSubgroup(d.key); })\n",
       "             .attr(&quot;y&quot;, function(d) { return yScale(d.value); })\n",
       "             .attr(&quot;width&quot;, xSubgroup.bandwidth())\n",
       "             .attr(&quot;height&quot;, function(d) { return (CHART_HEIGHT - yScale(d.value)); })\n",
       "             .attr(&quot;fill&quot;, function(d) { return color(d.key); })\n",
       "             .style(&quot;opacity&quot;, &quot;0.8&quot;);\n",
       "\n",
       "\n",
       "         return svgEl._groups[0][0].outerHTML;\n",
       "      }\n",
       "\n",
       "\n",
       "      const profileFromCSVfile = {&quot;response.has_patterns&quot;: {&quot;frequentItems&quot;: []}}\n",
       "\n",
       "      Handlebars.registerHelper(&quot;getDoubleHistogramChart&quot;,(column,key) =&gt; {\n",
       "        const columnKey = key.data.key\n",
       "        try {\n",
       "          if (profileFromCSVfile) {\n",
       "            return generateBarChart(\n",
       "                     column,\n",
       "                     profileFromCSVfile[columnKey]\n",
       "                   )\n",
       "          }\n",
       "        } catch (err) {\n",
       "          $(document).ready(() =&gt;\n",
       "            $(&quot;.desktop-content&quot;).html(`\n",
       "              &lt;p style=&quot;height: ${$(window).height()}px&quot; class=&quot;error-message&quot;&gt;\n",
       "                Something went wrong. Please try again.\n",
       "              &lt;/p&gt;\n",
       "            `)\n",
       "          )\n",
       "        }\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function initWebsiteScripts() {\n",
       "      $(&quot;.svg-container&quot;).css(&quot;height&quot;, $(window).height() - 32)\n",
       "    }\n",
       "\n",
       "    function initHandlebarsTemplate() {\n",
       "      // Replace this context with JSON from .py file\n",
       "      const context = {&quot;response.has_patterns&quot;: {&quot;frequentItems&quot;: []}};\n",
       "      // Config handlebars and pass data to HBS template\n",
       "      const source = document.getElementById(&quot;entry-template&quot;).innerHTML;\n",
       "      const template = Handlebars.compile(source);\n",
       "      const html = template(context);\n",
       "      const target = document.getElementById(&quot;generated-html&quot;);\n",
       "      target.innerHTML = html;\n",
       "    }\n",
       "\n",
       "    // Invoke functions -- keep in mind invokation order\n",
       "    registerHandlebarHelperFunctions();\n",
       "    initHandlebarsTemplate();\n",
       "    initWebsiteScripts();\n",
       "  &lt;/script&gt;\n",
       "&lt;/html&gt;\n",
       "\" width=100% height=277px\n",
       "        frameBorder=0></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visualize_langkit_metric(\n",
    "    df, \n",
    "    \"response.has_patterns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afba5e12-03f7-410d-80dc-1494638bbc8b",
   "metadata": {},
   "source": [
    "### Toxicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf6c4a9a-3bc3-4a80-b0b4-6cf4043084e2",
   "metadata": {
    "height": 64
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div></div><iframe srcdoc=\"&lt;!DOCTYPE html&gt;\n",
       "&lt;html lang=&quot;en&quot;&gt;\n",
       "  &lt;head&gt;\n",
       "    &lt;meta charset=&quot;UTF-8&quot; /&gt;\n",
       "    &lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;IE=edge&quot; /&gt;\n",
       "    &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot; /&gt;\n",
       "    &lt;meta name=&quot;description&quot; content=&quot;&quot; /&gt;\n",
       "    &lt;meta name=&quot;author&quot; content=&quot;&quot; /&gt;\n",
       "\n",
       "    &lt;title&gt;Profile Visualizer | whylogs&lt;/title&gt;\n",
       "\n",
       "    &lt;link rel=&quot;icon&quot; href=&quot;images/whylabs-favicon.png&quot; type=&quot;image/png&quot; sizes=&quot;16x16&quot; /&gt;\n",
       "    &lt;link rel=&quot;preconnect&quot; href=&quot;https://fonts.googleapis.com&quot; /&gt;\n",
       "    &lt;link rel=&quot;preconnect&quot; href=&quot;https://fonts.gstatic.com&quot; crossorigin /&gt;\n",
       "    &lt;link href=&quot;https://fonts.googleapis.com/css2?family=Asap:wght@400;500;600;700&amp;display=swap&quot; rel=&quot;stylesheet&quot; /&gt;\n",
       "    &lt;link rel=&quot;preconnect&quot; href=&quot;https://fonts.gstatic.com&quot; /&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.1.0/dist/css/bootstrap.min.css&quot; /&gt;\n",
       "\n",
       "    &lt;script\n",
       "      src=&quot;https://cdnjs.cloudflare.com/ajax/libs/handlebars.js/4.7.7/handlebars.min.js&quot;\n",
       "      integrity=&quot;sha512-RNLkV3d+aLtfcpEyFG8jRbnWHxUqVZozacROI4J2F1sTaDqo1dPQYs01OMi1t1w9Y2FdbSCDSQ2ZVdAC8bzgAg==&quot;\n",
       "      crossorigin=&quot;anonymous&quot;\n",
       "      referrerpolicy=&quot;no-referrer&quot;\n",
       "    &gt;&lt;/script&gt;\n",
       "\n",
       "    &lt;style type=&quot;text/css&quot;&gt;\n",
       "\n",
       "      :root {\n",
       "        /** Branded colors */\n",
       "        --brandSecondary900: #4f595b;\n",
       "        --secondaryLight1000: #313b3d;\n",
       "        /** Purpose colors */\n",
       "        --tealBackground: #eaf2f3;\n",
       "      }\n",
       "\n",
       "      /* RESET STYLE */\n",
       "      *,\n",
       "      *::after,\n",
       "      *::before {\n",
       "        margin: 0;\n",
       "        padding: 0;\n",
       "        box-sizing: border-box;\n",
       "        overflow-y: hidden;\n",
       "      }\n",
       "\n",
       "      /* Screen on smaller screens */\n",
       "      .no-responsive {\n",
       "        display: none;\n",
       "        position: fixed;\n",
       "        top: 0;\n",
       "        left: 0;\n",
       "        z-index: 1031;\n",
       "        width: 100vw;\n",
       "        height: 100vh;\n",
       "        background-color: var(--tealBackground);\n",
       "        display: flex;\n",
       "        align-items: center;\n",
       "        justify-content: center;\n",
       "      }\n",
       "\n",
       "      .desktop-content {\n",
       "        display: flex;\n",
       "        flex-direction: column;\n",
       "      }\n",
       "\n",
       "      .no-responsive__content {\n",
       "        max-width: 600px;\n",
       "        width: 100%;\n",
       "        padding: 0 24px;\n",
       "      }\n",
       "\n",
       "      .no-responsive__title {\n",
       "        font-size: 96px;\n",
       "        font-weight: 300;\n",
       "        color: var(--brandSecondary900);\n",
       "        line-height: 1.167;\n",
       "      }\n",
       "\n",
       "      .no-responsive__text {\n",
       "        margin: 0;\n",
       "        font-size: 16px;\n",
       "        font-weight: 400;\n",
       "        color: var(--brandSecondary900);\n",
       "        line-height: 1.5;\n",
       "      }\n",
       "\n",
       "      .svg-container {\n",
       "        display: inline-block;\n",
       "        position: relative;\n",
       "        width: 100%;\n",
       "        vertical-align: top;\n",
       "        overflow: hidden;\n",
       "      }\n",
       "\n",
       "      .svg-content-responsive {\n",
       "        display: inline-block;\n",
       "        position: absolute;\n",
       "        left: 0;\n",
       "      }\n",
       "\n",
       "      .circle-color {\n",
       "       display: inline-block;\n",
       "       padding: 5px;\n",
       "       border-radius: 50px;\n",
       "     }\n",
       "\n",
       "     .colors-for-distingushing-charts {\n",
       "       padding-right: 10px;\n",
       "     }\n",
       "\n",
       "     .display-flex{\n",
       "       display: flex;\n",
       "     }\n",
       "\n",
       "     .align-items-flex-end {\n",
       "       align-items: flex-end;\n",
       "     }\n",
       "\n",
       "     .chart-box-title {\n",
       "       width: 88%;\n",
       "       justify-content: space-between;\n",
       "       margin: 10px;\n",
       "       margin-top: 15px;\n",
       "       bottom: 0;\n",
       "     }\n",
       "\n",
       "     .chart-box-title p{\n",
       "       margin-bottom: 0;\n",
       "       font-family: Asap;\n",
       "       font-weight: bold;\n",
       "       font-size: 18px;\n",
       "       line-height: 16px;\n",
       "       color: #4F595B;\n",
       "     }\n",
       "\n",
       "    .bar {\n",
       "      font: 10px sans-serif;\n",
       "    }\n",
       "\n",
       "    .bar path,\n",
       "    .bar line {\n",
       "      fill: none;\n",
       "      stroke: #000;\n",
       "      shape-rendering: crispEdges;\n",
       "    }\n",
       "\n",
       "    .error-message {\n",
       "      display: flex;\n",
       "      justify-content: center;\n",
       "      align-items: center;\n",
       "      color: rgb(255, 114, 71);\n",
       "      font-size: 30px;\n",
       "      font-weight: 900;\n",
       "    }\n",
       "\n",
       "     @media screen and (min-width: 500px) {\n",
       "       .desktop-content {\n",
       "         display: block;\n",
       "       }\n",
       "       .no-responsive {\n",
       "         display: none;\n",
       "       }\n",
       "     }\n",
       "    &lt;/style&gt;\n",
       "  &lt;/head&gt;\n",
       "\n",
       "  &lt;body id=&quot;generated-html&quot;&gt;&lt;/body&gt;\n",
       "  &lt;script id=&quot;entry-template&quot; type=&quot;text/x-handlebars-template&quot;&gt;\n",
       "    \n",
       "      &lt;div class=&quot;desktop-content&quot;&gt;\n",
       "{{#each this}}              &lt;div class=&quot;chart-box&quot; id=&quot;chart-box&quot;&gt;\n",
       "                &lt;div class=&quot;chart-box-title display-flex&quot;&gt;\n",
       "                  &lt;p&gt;{{@key}}&lt;/p&gt;\n",
       "                  &lt;div class=&quot;display-flex&quot;&gt;\n",
       "                    &lt;div class=&quot;colors-for-distingushing-charts&quot;&gt;\n",
       "                      &lt;div class=&quot;circle-color&quot; style=&quot;background: #44C0E7;&quot;&gt;&lt;/div&gt;\n",
       "                      &lt;text alignment-baseline=&quot;middle&quot; style=&quot;font-size: 15px;&quot;&gt;Target&lt;/text&gt;\n",
       "                    &lt;/div&gt;\n",
       "                    &lt;div class=&quot;colors-for-distingushing-charts&quot;&gt;\n",
       "                      &lt;div class=&quot;circle-color&quot; style=&quot;background: #F5843C&quot;&gt;&lt;/div&gt;\n",
       "                      &lt;text alignment-baseline=&quot;middle&quot; style=&quot;font-size: 15px;&quot;&gt;Reference&lt;/text&gt;\n",
       "                    &lt;/div&gt;\n",
       "                  &lt;/div&gt;&lt;/div&gt;\n",
       "                &lt;div class=&quot;svg-container&quot;&gt;{{{getDoubleHistogramChart this}}}&lt;/div&gt;\n",
       "              &lt;/div&gt;\n",
       "{{/each}}      &lt;/div&gt;\n",
       "      &lt;div class=&quot;no-responsive&quot;&gt;\n",
       "        &lt;div class=&quot;no-responsive__content&quot;&gt;\n",
       "          &lt;h1 class=&quot;no-responsive__title&quot;&gt;Hold on! :)&lt;/h1&gt;\n",
       "          &lt;p class=&quot;no-responsive__text&quot;&gt;\n",
       "            It looks like your current screen size or device is not yet supported by the WhyLabs Sandbox. The Sandbox is\n",
       "            best experienced on a desktop computer. Please try maximizing this window or switching to another device. We\n",
       "            are working on adding support for a larger variety of devices.\n",
       "          &lt;/p&gt;\n",
       "        &lt;/div&gt;\n",
       "      &lt;/div&gt;\n",
       "    \n",
       "  &lt;/script&gt;\n",
       "\n",
       "  &lt;script src=&quot;https://code.jquery.com/jquery-3.6.0.min.js&quot; integrity=&quot;sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=&quot; crossorigin=&quot;anonymous&quot;&gt;&lt;/script&gt;\n",
       "\n",
       "  &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/d3/6.7.0/d3.min.js&quot; integrity=&quot;sha512-cd6CHE+XWDQ33ElJqsi0MdNte3S+bQY819f7p3NUHgwQQLXSKjE4cPZTeGNI+vaxZynk1wVU3hoHmow3m089wA==&quot; crossorigin=&quot;anonymous&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/script&gt;\n",
       "\n",
       "  &lt;script&gt;\n",
       "    function registerHandlebarHelperFunctions() {\n",
       "      //helper fun\n",
       "\n",
       "      class GenerateChartParams {\n",
       "        constructor(height, width, targetData, referenceData, bottomMargin=30, topMargin=5) {\n",
       "          this.MARGIN = {\n",
       "            TOP: topMargin,\n",
       "            RIGHT: 5,\n",
       "            BOTTOM: bottomMargin,\n",
       "            LEFT: 55,\n",
       "          };\n",
       "          this.SVG_WIDTH = width;\n",
       "          this.SVG_HEIGHT = height;\n",
       "          this.CHART_WIDTH = this.SVG_WIDTH - this.MARGIN.LEFT - this.MARGIN.RIGHT;\n",
       "          this.CHART_HEIGHT = this.SVG_HEIGHT - this.MARGIN.TOP - this.MARGIN.BOTTOM;\n",
       "          this.svgEl = d3.create(&quot;svg&quot;)\n",
       "             .attr(&quot;preserveAspectRatio&quot;, &quot;xMinYMin meet&quot;)\n",
       "             .attr(&quot;viewBox&quot;, `0 0 ${$(window).width()+100} ${$(window).height()-30}`)\n",
       "             .classed(&quot;svg-content-responsive&quot;, true)\n",
       "          this.maxYValue = d3.max(targetData, (d) =&gt; Math.abs(d.axisY));\n",
       "          this.minYValue = d3.min(targetData, (d) =&gt; Math.abs(d.axisY));\n",
       "          const mergedReferenceData = referenceData.map(({axisX, axisY}) =&gt; {\n",
       "            return {axisX, axisY}\n",
       "          })\n",
       "          const mergedTargetedData = targetData.map(({axisX, axisY}) =&gt; {\n",
       "            return {axisX, axisY}\n",
       "          })\n",
       "\n",
       "          this.charts2 = mergedReferenceData.concat(mergedTargetedData)\n",
       "          this.charts2 = this.charts2.sort(function(a, b) { return a - b; });\n",
       "\n",
       "          this.targetBinWidth = targetData[1]?.axisX - targetData[0]?.axisX\n",
       "          this.referenceBinWidth = referenceData[1]?.axisX - referenceData[0]?.axisX\n",
       "          this.maxTargetXValue = d3.max(targetData, (d) =&gt; d.axisX);\n",
       "\n",
       "          this.maxReferenceXValue = d3.max(referenceData, (d) =&gt; d.axisX);\n",
       "\n",
       "          this.xScale = d3\n",
       "              .scaleLinear()\n",
       "         .domain([d3.min(this.charts2, function(d) { return parseFloat(d.axisX); }),(this.maxTargetXValue+this.targetBinWidth &gt;= this.maxReferenceXValue+this.referenceBinWidth) ? this.maxTargetXValue+this.targetBinWidth:this.maxReferenceXValue+this.referenceBinWidth])\n",
       "         .range([0, this.CHART_WIDTH ]);\n",
       "\n",
       "         this.svgEl.append(&quot;g&quot;)\n",
       "             .attr(&quot;transform&quot;, &quot;translate(&quot;+ this.MARGIN.LEFT +&quot;,&quot; + this.SVG_HEIGHT + &quot;)&quot;)\n",
       "             .call(d3.axisBottom(this.xScale));\n",
       "          this.yScale = d3.scaleLinear()\n",
       "              .range([this.CHART_HEIGHT , 0])\n",
       "              .domain([d3.min(this.charts2, function(d) { return parseFloat(d.axisY); }), d3.max(this.charts2, function(d) { return parseFloat(d.axisY); })*1.2])\n",
       "              .nice();\n",
       "        }\n",
       "      }\n",
       "\n",
       "      function chartData(column) {\n",
       "        const data = [];\n",
       "        if (column?.histogram) {\n",
       "          for (let i = 0; i&lt;column.histogram.bins.length; i++) {\n",
       "            data.push({\n",
       "              axisY: column.histogram.counts[i] || 0,\n",
       "              axisX: column.histogram.bins[i] || 0,\n",
       "            });\n",
       "          }\n",
       "        } else {\n",
       "            $(document).ready(() =&gt;\n",
       "              $(&quot;.desktop-content&quot;).html(`\n",
       "                &lt;p style=&quot;height: ${$(window).height()}px&quot; class=&quot;error-message&quot;&gt;\n",
       "                  Something went wrong. Please try again.\n",
       "                &lt;/p&gt;\n",
       "              `)\n",
       "            )\n",
       "          }\n",
       "\n",
       "        return data\n",
       "      }\n",
       "\n",
       "      function verticalLine(column) {\n",
       "        const line_data = [];\n",
       "        if (column?.vertical_line) {\n",
       "            line_data.push({\n",
       "              axisX: column?.vertical_line || 0,\n",
       "            });\n",
       "\n",
       "        }\n",
       "\n",
       "        return line_data\n",
       "      }\n",
       "\n",
       "      function generateDoubleHistogramChart(targetData, referenceData) {\n",
       "        let histogramData = [],\n",
       "            overlappedHistogramData = [];\n",
       "        let yFormat;\n",
       "\n",
       "        histogramData = chartData(targetData)\n",
       "        overlappedHistogramData = chartData(referenceData)\n",
       "        lineData = verticalLine(targetData)\n",
       "\n",
       "        const sizes = new GenerateChartParams($(window).height()-80, $(window).width(), histogramData, overlappedHistogramData)\n",
       "        const {\n",
       "          MARGIN,\n",
       "          SVG_WIDTH,\n",
       "          SVG_HEIGHT,\n",
       "          CHART_WIDTH,\n",
       "          CHART_HEIGHT,\n",
       "          svgEl,\n",
       "          maxYValue,\n",
       "          minYValue,\n",
       "          xScale,\n",
       "          yScale\n",
       "        } = sizes\n",
       "\n",
       "        const rectColors = [&quot;#44C0E7&quot;, &quot;#F5843C&quot;]\n",
       "        const yAxis = d3.axisLeft(yScale).ticks(SVG_HEIGHT / 40);\n",
       "\n",
       "        svgEl.append(&quot;g&quot;)\n",
       "          .attr(&quot;transform&quot;, `translate(${MARGIN.LEFT}, ${MARGIN.BOTTOM})`)\n",
       "          .call(yAxis)\n",
       "          .call(g =&gt; g.select(&quot;.domain&quot;).remove())\n",
       "          .call(g =&gt; g.selectAll(&quot;.tick line&quot;)\n",
       "              .attr(&quot;x2&quot;, CHART_WIDTH)\n",
       "              .attr(&quot;stroke-opacity&quot;, 0.1))\n",
       "          .call(g =&gt; g.append(&quot;text&quot;)\n",
       "              .attr(&quot;x&quot;, -MARGIN.LEFT)\n",
       "              .attr(&quot;y&quot;, 10)\n",
       "              .attr(&quot;fill&quot;, &quot;currentColor&quot;)\n",
       "              .attr(&quot;text-anchor&quot;, &quot;start&quot;))\n",
       "\n",
       "        svgEl.append(&quot;line&quot;)\n",
       "          .attr(&quot;transform&quot;, `translate(${MARGIN.LEFT}, ${MARGIN.BOTTOM})`)\n",
       "          .data(lineData)\n",
       "          .attr(&quot;x1&quot;, (d) =&gt; xScale(d.axisX))\n",
       "          .attr(&quot;y1&quot;, MARGIN.TOP + MARGIN.TOP)\n",
       "          .attr(&quot;x2&quot;, (d) =&gt; xScale(d.axisX))\n",
       "          .attr(&quot;y2&quot;, CHART_HEIGHT + MARGIN.TOP)\n",
       "          .style(&quot;stroke-width&quot;, 2)\n",
       "          .style(&quot;stroke&quot;, &quot;#44C0E7&quot;)\n",
       "          .style(&quot;stroke-dasharray&quot;, (3,3))\n",
       "          .style(&quot;fill&quot;, &quot;none&quot;);\n",
       "\n",
       "        svgEl.append(&quot;text&quot;)\n",
       "          .attr(&quot;transform&quot;, &quot;rotate(-90)&quot;)\n",
       "          .data(lineData)\n",
       "          .attr(&quot;y&quot;, (d) =&gt; xScale(d.axisX) + MARGIN.LEFT)\n",
       "          .attr(&quot;x&quot;, 0 - (SVG_HEIGHT / 2))\n",
       "          .attr(&quot;dy&quot;, &quot;1em&quot;)\n",
       "          .style(&quot;text-anchor&quot;, &quot;middle&quot;)\n",
       "          .text(&quot;single value&quot;)\n",
       "          .style(&quot;font-size&quot;, &quot;15&quot;)\n",
       "          .style(&quot;opacity&quot;, &quot;0.6&quot;)\n",
       "\n",
       "        svgEl.append(&quot;text&quot;)\n",
       "          .attr(&quot;transform&quot;,\n",
       "                &quot;translate(&quot; + (CHART_WIDTH/2) + &quot; ,&quot; +\n",
       "                               (CHART_HEIGHT + MARGIN.TOP + 75) + &quot;)&quot;)\n",
       "          .style(&quot;text-anchor&quot;, &quot;middle&quot;)\n",
       "          .text(&quot;Values&quot;)\n",
       "          .style(&quot;font-size&quot;, &quot;15&quot;)\n",
       "          .style(&quot;opacity&quot;, &quot;0.6&quot;)\n",
       "\n",
       "        svgEl.append(&quot;text&quot;)\n",
       "          .attr(&quot;transform&quot;, &quot;rotate(-90)&quot;)\n",
       "          .attr(&quot;y&quot;, 0)\n",
       "          .attr(&quot;x&quot;, 0 - (SVG_HEIGHT / 2))\n",
       "          .attr(&quot;dy&quot;, &quot;1em&quot;)\n",
       "          .style(&quot;text-anchor&quot;, &quot;middle&quot;)\n",
       "          .text(&quot;Counts&quot;)\n",
       "          .style(&quot;font-size&quot;, &quot;15&quot;)\n",
       "          .style(&quot;opacity&quot;, &quot;0.6&quot;)\n",
       "\n",
       "          const gChart = svgEl.append(&quot;g&quot;);\n",
       "          gChart\n",
       "          .attr(&quot;transform&quot;, &quot;translate(&quot;+ MARGIN.LEFT +&quot;,0)&quot;)\n",
       "          .selectAll(&quot;.bar&quot;)\n",
       "          .data(histogramData)\n",
       "          .enter()\n",
       "          .append(&quot;rect&quot;)\n",
       "          .style(&quot;stroke&quot;, &quot;#021826&quot;)\n",
       "          .classed(&quot;bar&quot;, true)\n",
       "          .attr(&quot;width&quot;, function(d) { return xScale(histogramData[1]?.axisX)-xScale(histogramData[0]?.axisX); })\n",
       "          .attr(&quot;height&quot;, (d) =&gt; CHART_HEIGHT - yScale(d.axisY))\n",
       "          .attr(&quot;x&quot;, 1)\n",
       "          .attr(&quot;transform&quot;, function(d) { return &quot;translate(&quot; + xScale(d.axisX) + &quot;,&quot; + 0  +  &quot;)&quot;; })\n",
       "          .attr(&quot;y&quot;, (d) =&gt; yScale(d.axisY) + MARGIN.TOP + MARGIN.BOTTOM)\n",
       "          .attr(&quot;fill&quot;, rectColors[0])\n",
       "          .style(&quot;opacity&quot;,&quot;0.6&quot;)\n",
       "\n",
       "          const gChart1 = svgEl.append(&quot;g&quot;);\n",
       "          gChart1\n",
       "          .attr(&quot;transform&quot;, &quot;translate(&quot;+ MARGIN.LEFT +&quot;,0)&quot;)\n",
       "          .selectAll(&quot;.bar&quot;)\n",
       "          .data(overlappedHistogramData)\n",
       "          .enter()\n",
       "          .append(&quot;rect&quot;)\n",
       "          .style(&quot;stroke&quot;, &quot;#021826&quot;)\n",
       "          .classed(&quot;bar&quot;, true)\n",
       "          .attr(&quot;width&quot;, function(d) { return xScale(overlappedHistogramData[1]?.axisX)-xScale(overlappedHistogramData[0]?.axisX); })\n",
       "          .attr(&quot;height&quot;, (d) =&gt; CHART_HEIGHT - yScale(d.axisY))\n",
       "          .attr(&quot;x&quot;, 1)\n",
       "          .attr(&quot;transform&quot;, function(d) { return &quot;translate(&quot; + xScale(d.axisX) + &quot;,&quot; + 0  +  &quot;)&quot;; })\n",
       "          .attr(&quot;y&quot;, (d) =&gt; yScale(d.axisY) + MARGIN.TOP + MARGIN.BOTTOM)\n",
       "          .attr(&quot;fill&quot;, rectColors[1])\n",
       "          .style(&quot;opacity&quot;,&quot;0.6&quot;)\n",
       "\n",
       "        return svgEl._groups[0][0].outerHTML;\n",
       "      }\n",
       "\n",
       "      const profileFromCSVfile = {&quot;prompt.toxicity&quot;: {&quot;histogram&quot;: {&quot;start&quot;: 0.0008265376091003418, &quot;end&quot;: 0.019972385973221065, &quot;width&quot;: 0, &quot;counts&quot;: [0, 0, 0], &quot;max&quot;: 0.019972383975982666, &quot;min&quot;: 0.0008265376091003418, &quot;bins&quot;: [0.0008265376091003418, 0.00720848706380725, 0.013590436518514158, 0.019972385973221065], &quot;n&quot;: 10}}}\n",
       "\n",
       "      Handlebars.registerHelper(&quot;getDoubleHistogramChart&quot;,(column,key) =&gt; {\n",
       "          const columnKey = key.data.key\n",
       "        try {\n",
       "          if (profileFromCSVfile) {\n",
       "          return  generateDoubleHistogramChart (\n",
       "              column,\n",
       "              profileFromCSVfile[columnKey]\n",
       "            )\n",
       "          }\n",
       "        } catch (err) {\n",
       "          $(document).ready(() =&gt;\n",
       "            $(&quot;.desktop-content&quot;).html(`\n",
       "              &lt;p style=&quot;height: ${$(window).height()}px&quot; class=&quot;error-message&quot;&gt;\n",
       "                Something went wrong. Please try again.\n",
       "              &lt;/p&gt;\n",
       "            `)\n",
       "          )\n",
       "        }\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function initWebsiteScripts() {\n",
       "      $(&quot;.svg-container&quot;).css(&quot;height&quot;, $(window).height() - 32)\n",
       "    }\n",
       "\n",
       "    function initHandlebarsTemplate() {\n",
       "      // Replace this context with JSON from .py file\n",
       "      const context = {&quot;prompt.toxicity&quot;: {&quot;histogram&quot;: {&quot;start&quot;: 0.0008265376091003418, &quot;end&quot;: 0.019972385973221065, &quot;width&quot;: 0, &quot;counts&quot;: [9, 0, 1], &quot;max&quot;: 0.019972383975982666, &quot;min&quot;: 0.0008265376091003418, &quot;bins&quot;: [0.0008265376091003418, 0.00720848706380725, 0.013590436518514158, 0.019972385973221065], &quot;n&quot;: 10}}};\n",
       "      // Config handlebars and pass data to HBS template\n",
       "      const source = document.getElementById(&quot;entry-template&quot;).innerHTML;\n",
       "      const template = Handlebars.compile(source);\n",
       "      const html = template(context);\n",
       "      const target = document.getElementById(&quot;generated-html&quot;);\n",
       "      target.innerHTML = html;\n",
       "    }\n",
       "\n",
       "    // Invoke functions -- keep in mind invokation order\n",
       "    registerHandlebarHelperFunctions();\n",
       "    initHandlebarsTemplate();\n",
       "    initWebsiteScripts();\n",
       "  &lt;/script&gt;\n",
       "&lt;/html&gt;\n",
       "\" width=100% height=300px\n",
       "        frameBorder=0></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visualize_langkit_metric(\n",
    "    df, \n",
    "    \"prompt.toxicity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2009e62b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "      <th>prompt.toxicity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Is there a blackmarket for AI services?</td>\n",
       "      <td>Yes, there is a black market for AI services. ...</td>\n",
       "      <td>0.019972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Who is Anna Cielas?</td>\n",
       "      <td>The context provided does not contain any info...</td>\n",
       "      <td>0.003536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What can you tell me about a new Deepseek model?</td>\n",
       "      <td>DeepSeek released DeepSeek-R1, a large languag...</td>\n",
       "      <td>0.001265</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             prompt  \\\n",
       "9           Is there a blackmarket for AI services?   \n",
       "6                               Who is Anna Cielas?   \n",
       "0  What can you tell me about a new Deepseek model?   \n",
       "\n",
       "                                            response  prompt.toxicity  \n",
       "9  Yes, there is a black market for AI services. ...         0.019972  \n",
       "6  The context provided does not contain any info...         0.003536  \n",
       "0  DeepSeek released DeepSeek-R1, a large languag...         0.001265  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_langkit_critical_queries(\n",
    "    df,\n",
    "    \"prompt.toxicity\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06ae8e5f-68aa-4e8f-9d77-3e57cdec3054",
   "metadata": {
    "height": 64
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div></div><iframe srcdoc=\"&lt;!DOCTYPE html&gt;\n",
       "&lt;html lang=&quot;en&quot;&gt;\n",
       "  &lt;head&gt;\n",
       "    &lt;meta charset=&quot;UTF-8&quot; /&gt;\n",
       "    &lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;IE=edge&quot; /&gt;\n",
       "    &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot; /&gt;\n",
       "    &lt;meta name=&quot;description&quot; content=&quot;&quot; /&gt;\n",
       "    &lt;meta name=&quot;author&quot; content=&quot;&quot; /&gt;\n",
       "\n",
       "    &lt;title&gt;Profile Visualizer | whylogs&lt;/title&gt;\n",
       "\n",
       "    &lt;link rel=&quot;icon&quot; href=&quot;images/whylabs-favicon.png&quot; type=&quot;image/png&quot; sizes=&quot;16x16&quot; /&gt;\n",
       "    &lt;link rel=&quot;preconnect&quot; href=&quot;https://fonts.googleapis.com&quot; /&gt;\n",
       "    &lt;link rel=&quot;preconnect&quot; href=&quot;https://fonts.gstatic.com&quot; crossorigin /&gt;\n",
       "    &lt;link href=&quot;https://fonts.googleapis.com/css2?family=Asap:wght@400;500;600;700&amp;display=swap&quot; rel=&quot;stylesheet&quot; /&gt;\n",
       "    &lt;link rel=&quot;preconnect&quot; href=&quot;https://fonts.gstatic.com&quot; /&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.1.0/dist/css/bootstrap.min.css&quot; /&gt;\n",
       "\n",
       "    &lt;script\n",
       "      src=&quot;https://cdnjs.cloudflare.com/ajax/libs/handlebars.js/4.7.7/handlebars.min.js&quot;\n",
       "      integrity=&quot;sha512-RNLkV3d+aLtfcpEyFG8jRbnWHxUqVZozacROI4J2F1sTaDqo1dPQYs01OMi1t1w9Y2FdbSCDSQ2ZVdAC8bzgAg==&quot;\n",
       "      crossorigin=&quot;anonymous&quot;\n",
       "      referrerpolicy=&quot;no-referrer&quot;\n",
       "    &gt;&lt;/script&gt;\n",
       "\n",
       "    &lt;style type=&quot;text/css&quot;&gt;\n",
       "\n",
       "      :root {\n",
       "        /** Branded colors */\n",
       "        --brandSecondary900: #4f595b;\n",
       "        --secondaryLight1000: #313b3d;\n",
       "        /** Purpose colors */\n",
       "        --tealBackground: #eaf2f3;\n",
       "      }\n",
       "\n",
       "      /* RESET STYLE */\n",
       "      *,\n",
       "      *::after,\n",
       "      *::before {\n",
       "        margin: 0;\n",
       "        padding: 0;\n",
       "        box-sizing: border-box;\n",
       "        overflow-y: hidden;\n",
       "      }\n",
       "\n",
       "      /* Screen on smaller screens */\n",
       "      .no-responsive {\n",
       "        display: none;\n",
       "        position: fixed;\n",
       "        top: 0;\n",
       "        left: 0;\n",
       "        z-index: 1031;\n",
       "        width: 100vw;\n",
       "        height: 100vh;\n",
       "        background-color: var(--tealBackground);\n",
       "        display: flex;\n",
       "        align-items: center;\n",
       "        justify-content: center;\n",
       "      }\n",
       "\n",
       "      .desktop-content {\n",
       "        display: flex;\n",
       "        flex-direction: column;\n",
       "      }\n",
       "\n",
       "      .no-responsive__content {\n",
       "        max-width: 600px;\n",
       "        width: 100%;\n",
       "        padding: 0 24px;\n",
       "      }\n",
       "\n",
       "      .no-responsive__title {\n",
       "        font-size: 96px;\n",
       "        font-weight: 300;\n",
       "        color: var(--brandSecondary900);\n",
       "        line-height: 1.167;\n",
       "      }\n",
       "\n",
       "      .no-responsive__text {\n",
       "        margin: 0;\n",
       "        font-size: 16px;\n",
       "        font-weight: 400;\n",
       "        color: var(--brandSecondary900);\n",
       "        line-height: 1.5;\n",
       "      }\n",
       "\n",
       "      .svg-container {\n",
       "        display: inline-block;\n",
       "        position: relative;\n",
       "        width: 100%;\n",
       "        vertical-align: top;\n",
       "        overflow: hidden;\n",
       "      }\n",
       "\n",
       "      .svg-content-responsive {\n",
       "        display: inline-block;\n",
       "        position: absolute;\n",
       "        left: 0;\n",
       "      }\n",
       "\n",
       "      .circle-color {\n",
       "       display: inline-block;\n",
       "       padding: 5px;\n",
       "       border-radius: 50px;\n",
       "     }\n",
       "\n",
       "     .colors-for-distingushing-charts {\n",
       "       padding-right: 10px;\n",
       "     }\n",
       "\n",
       "     .display-flex{\n",
       "       display: flex;\n",
       "     }\n",
       "\n",
       "     .align-items-flex-end {\n",
       "       align-items: flex-end;\n",
       "     }\n",
       "\n",
       "     .chart-box-title {\n",
       "       width: 88%;\n",
       "       justify-content: space-between;\n",
       "       margin: 10px;\n",
       "       margin-top: 15px;\n",
       "       bottom: 0;\n",
       "     }\n",
       "\n",
       "     .chart-box-title p{\n",
       "       margin-bottom: 0;\n",
       "       font-family: Asap;\n",
       "       font-weight: bold;\n",
       "       font-size: 18px;\n",
       "       line-height: 16px;\n",
       "       color: #4F595B;\n",
       "     }\n",
       "\n",
       "    .bar {\n",
       "      font: 10px sans-serif;\n",
       "    }\n",
       "\n",
       "    .bar path,\n",
       "    .bar line {\n",
       "      fill: none;\n",
       "      stroke: #000;\n",
       "      shape-rendering: crispEdges;\n",
       "    }\n",
       "\n",
       "    .error-message {\n",
       "      display: flex;\n",
       "      justify-content: center;\n",
       "      align-items: center;\n",
       "      color: rgb(255, 114, 71);\n",
       "      font-size: 30px;\n",
       "      font-weight: 900;\n",
       "    }\n",
       "\n",
       "     @media screen and (min-width: 500px) {\n",
       "       .desktop-content {\n",
       "         display: block;\n",
       "       }\n",
       "       .no-responsive {\n",
       "         display: none;\n",
       "       }\n",
       "     }\n",
       "    &lt;/style&gt;\n",
       "  &lt;/head&gt;\n",
       "\n",
       "  &lt;body id=&quot;generated-html&quot;&gt;&lt;/body&gt;\n",
       "  &lt;script id=&quot;entry-template&quot; type=&quot;text/x-handlebars-template&quot;&gt;\n",
       "    \n",
       "      &lt;div class=&quot;desktop-content&quot;&gt;\n",
       "{{#each this}}              &lt;div class=&quot;chart-box&quot; id=&quot;chart-box&quot;&gt;\n",
       "                &lt;div class=&quot;chart-box-title display-flex&quot;&gt;\n",
       "                  &lt;p&gt;{{@key}}&lt;/p&gt;\n",
       "                  &lt;div class=&quot;display-flex&quot;&gt;\n",
       "                    &lt;div class=&quot;colors-for-distingushing-charts&quot;&gt;\n",
       "                      &lt;div class=&quot;circle-color&quot; style=&quot;background: #44C0E7;&quot;&gt;&lt;/div&gt;\n",
       "                      &lt;text alignment-baseline=&quot;middle&quot; style=&quot;font-size: 15px;&quot;&gt;Target&lt;/text&gt;\n",
       "                    &lt;/div&gt;\n",
       "                    &lt;div class=&quot;colors-for-distingushing-charts&quot;&gt;\n",
       "                      &lt;div class=&quot;circle-color&quot; style=&quot;background: #F5843C&quot;&gt;&lt;/div&gt;\n",
       "                      &lt;text alignment-baseline=&quot;middle&quot; style=&quot;font-size: 15px;&quot;&gt;Reference&lt;/text&gt;\n",
       "                    &lt;/div&gt;\n",
       "                  &lt;/div&gt;&lt;/div&gt;\n",
       "                &lt;div class=&quot;svg-container&quot;&gt;{{{getDoubleHistogramChart this}}}&lt;/div&gt;\n",
       "              &lt;/div&gt;\n",
       "{{/each}}      &lt;/div&gt;\n",
       "      &lt;div class=&quot;no-responsive&quot;&gt;\n",
       "        &lt;div class=&quot;no-responsive__content&quot;&gt;\n",
       "          &lt;h1 class=&quot;no-responsive__title&quot;&gt;Hold on! :)&lt;/h1&gt;\n",
       "          &lt;p class=&quot;no-responsive__text&quot;&gt;\n",
       "            It looks like your current screen size or device is not yet supported by the WhyLabs Sandbox. The Sandbox is\n",
       "            best experienced on a desktop computer. Please try maximizing this window or switching to another device. We\n",
       "            are working on adding support for a larger variety of devices.\n",
       "          &lt;/p&gt;\n",
       "        &lt;/div&gt;\n",
       "      &lt;/div&gt;\n",
       "    \n",
       "  &lt;/script&gt;\n",
       "\n",
       "  &lt;script src=&quot;https://code.jquery.com/jquery-3.6.0.min.js&quot; integrity=&quot;sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=&quot; crossorigin=&quot;anonymous&quot;&gt;&lt;/script&gt;\n",
       "\n",
       "  &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/d3/6.7.0/d3.min.js&quot; integrity=&quot;sha512-cd6CHE+XWDQ33ElJqsi0MdNte3S+bQY819f7p3NUHgwQQLXSKjE4cPZTeGNI+vaxZynk1wVU3hoHmow3m089wA==&quot; crossorigin=&quot;anonymous&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/script&gt;\n",
       "\n",
       "  &lt;script&gt;\n",
       "    function registerHandlebarHelperFunctions() {\n",
       "      //helper fun\n",
       "\n",
       "      class GenerateChartParams {\n",
       "        constructor(height, width, targetData, referenceData, bottomMargin=30, topMargin=5) {\n",
       "          this.MARGIN = {\n",
       "            TOP: topMargin,\n",
       "            RIGHT: 5,\n",
       "            BOTTOM: bottomMargin,\n",
       "            LEFT: 55,\n",
       "          };\n",
       "          this.SVG_WIDTH = width;\n",
       "          this.SVG_HEIGHT = height;\n",
       "          this.CHART_WIDTH = this.SVG_WIDTH - this.MARGIN.LEFT - this.MARGIN.RIGHT;\n",
       "          this.CHART_HEIGHT = this.SVG_HEIGHT - this.MARGIN.TOP - this.MARGIN.BOTTOM;\n",
       "          this.svgEl = d3.create(&quot;svg&quot;)\n",
       "             .attr(&quot;preserveAspectRatio&quot;, &quot;xMinYMin meet&quot;)\n",
       "             .attr(&quot;viewBox&quot;, `0 0 ${$(window).width()+100} ${$(window).height()-30}`)\n",
       "             .classed(&quot;svg-content-responsive&quot;, true)\n",
       "          this.maxYValue = d3.max(targetData, (d) =&gt; Math.abs(d.axisY));\n",
       "          this.minYValue = d3.min(targetData, (d) =&gt; Math.abs(d.axisY));\n",
       "          const mergedReferenceData = referenceData.map(({axisX, axisY}) =&gt; {\n",
       "            return {axisX, axisY}\n",
       "          })\n",
       "          const mergedTargetedData = targetData.map(({axisX, axisY}) =&gt; {\n",
       "            return {axisX, axisY}\n",
       "          })\n",
       "\n",
       "          this.charts2 = mergedReferenceData.concat(mergedTargetedData)\n",
       "          this.charts2 = this.charts2.sort(function(a, b) { return a - b; });\n",
       "\n",
       "          this.targetBinWidth = targetData[1]?.axisX - targetData[0]?.axisX\n",
       "          this.referenceBinWidth = referenceData[1]?.axisX - referenceData[0]?.axisX\n",
       "          this.maxTargetXValue = d3.max(targetData, (d) =&gt; d.axisX);\n",
       "\n",
       "          this.maxReferenceXValue = d3.max(referenceData, (d) =&gt; d.axisX);\n",
       "\n",
       "          this.xScale = d3\n",
       "              .scaleLinear()\n",
       "         .domain([d3.min(this.charts2, function(d) { return parseFloat(d.axisX); }),(this.maxTargetXValue+this.targetBinWidth &gt;= this.maxReferenceXValue+this.referenceBinWidth) ? this.maxTargetXValue+this.targetBinWidth:this.maxReferenceXValue+this.referenceBinWidth])\n",
       "         .range([0, this.CHART_WIDTH ]);\n",
       "\n",
       "         this.svgEl.append(&quot;g&quot;)\n",
       "             .attr(&quot;transform&quot;, &quot;translate(&quot;+ this.MARGIN.LEFT +&quot;,&quot; + this.SVG_HEIGHT + &quot;)&quot;)\n",
       "             .call(d3.axisBottom(this.xScale));\n",
       "          this.yScale = d3.scaleLinear()\n",
       "              .range([this.CHART_HEIGHT , 0])\n",
       "              .domain([d3.min(this.charts2, function(d) { return parseFloat(d.axisY); }), d3.max(this.charts2, function(d) { return parseFloat(d.axisY); })*1.2])\n",
       "              .nice();\n",
       "        }\n",
       "      }\n",
       "\n",
       "      function chartData(column) {\n",
       "        const data = [];\n",
       "        if (column?.histogram) {\n",
       "          for (let i = 0; i&lt;column.histogram.bins.length; i++) {\n",
       "            data.push({\n",
       "              axisY: column.histogram.counts[i] || 0,\n",
       "              axisX: column.histogram.bins[i] || 0,\n",
       "            });\n",
       "          }\n",
       "        } else {\n",
       "            $(document).ready(() =&gt;\n",
       "              $(&quot;.desktop-content&quot;).html(`\n",
       "                &lt;p style=&quot;height: ${$(window).height()}px&quot; class=&quot;error-message&quot;&gt;\n",
       "                  Something went wrong. Please try again.\n",
       "                &lt;/p&gt;\n",
       "              `)\n",
       "            )\n",
       "          }\n",
       "\n",
       "        return data\n",
       "      }\n",
       "\n",
       "      function verticalLine(column) {\n",
       "        const line_data = [];\n",
       "        if (column?.vertical_line) {\n",
       "            line_data.push({\n",
       "              axisX: column?.vertical_line || 0,\n",
       "            });\n",
       "\n",
       "        }\n",
       "\n",
       "        return line_data\n",
       "      }\n",
       "\n",
       "      function generateDoubleHistogramChart(targetData, referenceData) {\n",
       "        let histogramData = [],\n",
       "            overlappedHistogramData = [];\n",
       "        let yFormat;\n",
       "\n",
       "        histogramData = chartData(targetData)\n",
       "        overlappedHistogramData = chartData(referenceData)\n",
       "        lineData = verticalLine(targetData)\n",
       "\n",
       "        const sizes = new GenerateChartParams($(window).height()-80, $(window).width(), histogramData, overlappedHistogramData)\n",
       "        const {\n",
       "          MARGIN,\n",
       "          SVG_WIDTH,\n",
       "          SVG_HEIGHT,\n",
       "          CHART_WIDTH,\n",
       "          CHART_HEIGHT,\n",
       "          svgEl,\n",
       "          maxYValue,\n",
       "          minYValue,\n",
       "          xScale,\n",
       "          yScale\n",
       "        } = sizes\n",
       "\n",
       "        const rectColors = [&quot;#44C0E7&quot;, &quot;#F5843C&quot;]\n",
       "        const yAxis = d3.axisLeft(yScale).ticks(SVG_HEIGHT / 40);\n",
       "\n",
       "        svgEl.append(&quot;g&quot;)\n",
       "          .attr(&quot;transform&quot;, `translate(${MARGIN.LEFT}, ${MARGIN.BOTTOM})`)\n",
       "          .call(yAxis)\n",
       "          .call(g =&gt; g.select(&quot;.domain&quot;).remove())\n",
       "          .call(g =&gt; g.selectAll(&quot;.tick line&quot;)\n",
       "              .attr(&quot;x2&quot;, CHART_WIDTH)\n",
       "              .attr(&quot;stroke-opacity&quot;, 0.1))\n",
       "          .call(g =&gt; g.append(&quot;text&quot;)\n",
       "              .attr(&quot;x&quot;, -MARGIN.LEFT)\n",
       "              .attr(&quot;y&quot;, 10)\n",
       "              .attr(&quot;fill&quot;, &quot;currentColor&quot;)\n",
       "              .attr(&quot;text-anchor&quot;, &quot;start&quot;))\n",
       "\n",
       "        svgEl.append(&quot;line&quot;)\n",
       "          .attr(&quot;transform&quot;, `translate(${MARGIN.LEFT}, ${MARGIN.BOTTOM})`)\n",
       "          .data(lineData)\n",
       "          .attr(&quot;x1&quot;, (d) =&gt; xScale(d.axisX))\n",
       "          .attr(&quot;y1&quot;, MARGIN.TOP + MARGIN.TOP)\n",
       "          .attr(&quot;x2&quot;, (d) =&gt; xScale(d.axisX))\n",
       "          .attr(&quot;y2&quot;, CHART_HEIGHT + MARGIN.TOP)\n",
       "          .style(&quot;stroke-width&quot;, 2)\n",
       "          .style(&quot;stroke&quot;, &quot;#44C0E7&quot;)\n",
       "          .style(&quot;stroke-dasharray&quot;, (3,3))\n",
       "          .style(&quot;fill&quot;, &quot;none&quot;);\n",
       "\n",
       "        svgEl.append(&quot;text&quot;)\n",
       "          .attr(&quot;transform&quot;, &quot;rotate(-90)&quot;)\n",
       "          .data(lineData)\n",
       "          .attr(&quot;y&quot;, (d) =&gt; xScale(d.axisX) + MARGIN.LEFT)\n",
       "          .attr(&quot;x&quot;, 0 - (SVG_HEIGHT / 2))\n",
       "          .attr(&quot;dy&quot;, &quot;1em&quot;)\n",
       "          .style(&quot;text-anchor&quot;, &quot;middle&quot;)\n",
       "          .text(&quot;single value&quot;)\n",
       "          .style(&quot;font-size&quot;, &quot;15&quot;)\n",
       "          .style(&quot;opacity&quot;, &quot;0.6&quot;)\n",
       "\n",
       "        svgEl.append(&quot;text&quot;)\n",
       "          .attr(&quot;transform&quot;,\n",
       "                &quot;translate(&quot; + (CHART_WIDTH/2) + &quot; ,&quot; +\n",
       "                               (CHART_HEIGHT + MARGIN.TOP + 75) + &quot;)&quot;)\n",
       "          .style(&quot;text-anchor&quot;, &quot;middle&quot;)\n",
       "          .text(&quot;Values&quot;)\n",
       "          .style(&quot;font-size&quot;, &quot;15&quot;)\n",
       "          .style(&quot;opacity&quot;, &quot;0.6&quot;)\n",
       "\n",
       "        svgEl.append(&quot;text&quot;)\n",
       "          .attr(&quot;transform&quot;, &quot;rotate(-90)&quot;)\n",
       "          .attr(&quot;y&quot;, 0)\n",
       "          .attr(&quot;x&quot;, 0 - (SVG_HEIGHT / 2))\n",
       "          .attr(&quot;dy&quot;, &quot;1em&quot;)\n",
       "          .style(&quot;text-anchor&quot;, &quot;middle&quot;)\n",
       "          .text(&quot;Counts&quot;)\n",
       "          .style(&quot;font-size&quot;, &quot;15&quot;)\n",
       "          .style(&quot;opacity&quot;, &quot;0.6&quot;)\n",
       "\n",
       "          const gChart = svgEl.append(&quot;g&quot;);\n",
       "          gChart\n",
       "          .attr(&quot;transform&quot;, &quot;translate(&quot;+ MARGIN.LEFT +&quot;,0)&quot;)\n",
       "          .selectAll(&quot;.bar&quot;)\n",
       "          .data(histogramData)\n",
       "          .enter()\n",
       "          .append(&quot;rect&quot;)\n",
       "          .style(&quot;stroke&quot;, &quot;#021826&quot;)\n",
       "          .classed(&quot;bar&quot;, true)\n",
       "          .attr(&quot;width&quot;, function(d) { return xScale(histogramData[1]?.axisX)-xScale(histogramData[0]?.axisX); })\n",
       "          .attr(&quot;height&quot;, (d) =&gt; CHART_HEIGHT - yScale(d.axisY))\n",
       "          .attr(&quot;x&quot;, 1)\n",
       "          .attr(&quot;transform&quot;, function(d) { return &quot;translate(&quot; + xScale(d.axisX) + &quot;,&quot; + 0  +  &quot;)&quot;; })\n",
       "          .attr(&quot;y&quot;, (d) =&gt; yScale(d.axisY) + MARGIN.TOP + MARGIN.BOTTOM)\n",
       "          .attr(&quot;fill&quot;, rectColors[0])\n",
       "          .style(&quot;opacity&quot;,&quot;0.6&quot;)\n",
       "\n",
       "          const gChart1 = svgEl.append(&quot;g&quot;);\n",
       "          gChart1\n",
       "          .attr(&quot;transform&quot;, &quot;translate(&quot;+ MARGIN.LEFT +&quot;,0)&quot;)\n",
       "          .selectAll(&quot;.bar&quot;)\n",
       "          .data(overlappedHistogramData)\n",
       "          .enter()\n",
       "          .append(&quot;rect&quot;)\n",
       "          .style(&quot;stroke&quot;, &quot;#021826&quot;)\n",
       "          .classed(&quot;bar&quot;, true)\n",
       "          .attr(&quot;width&quot;, function(d) { return xScale(overlappedHistogramData[1]?.axisX)-xScale(overlappedHistogramData[0]?.axisX); })\n",
       "          .attr(&quot;height&quot;, (d) =&gt; CHART_HEIGHT - yScale(d.axisY))\n",
       "          .attr(&quot;x&quot;, 1)\n",
       "          .attr(&quot;transform&quot;, function(d) { return &quot;translate(&quot; + xScale(d.axisX) + &quot;,&quot; + 0  +  &quot;)&quot;; })\n",
       "          .attr(&quot;y&quot;, (d) =&gt; yScale(d.axisY) + MARGIN.TOP + MARGIN.BOTTOM)\n",
       "          .attr(&quot;fill&quot;, rectColors[1])\n",
       "          .style(&quot;opacity&quot;,&quot;0.6&quot;)\n",
       "\n",
       "        return svgEl._groups[0][0].outerHTML;\n",
       "      }\n",
       "\n",
       "      const profileFromCSVfile = {&quot;response.toxicity&quot;: {&quot;histogram&quot;: {&quot;start&quot;: 0.0007464289665222168, &quot;end&quot;: 0.001603901546651125, &quot;width&quot;: 0, &quot;counts&quot;: [0, 0, 0], &quot;max&quot;: 0.0016039013862609863, &quot;min&quot;: 0.0007464289665222168, &quot;bins&quot;: [0.0007464289665222168, 0.0010322531598985195, 0.0013180773532748221, 0.001603901546651125], &quot;n&quot;: 10}}}\n",
       "\n",
       "      Handlebars.registerHelper(&quot;getDoubleHistogramChart&quot;,(column,key) =&gt; {\n",
       "          const columnKey = key.data.key\n",
       "        try {\n",
       "          if (profileFromCSVfile) {\n",
       "          return  generateDoubleHistogramChart (\n",
       "              column,\n",
       "              profileFromCSVfile[columnKey]\n",
       "            )\n",
       "          }\n",
       "        } catch (err) {\n",
       "          $(document).ready(() =&gt;\n",
       "            $(&quot;.desktop-content&quot;).html(`\n",
       "              &lt;p style=&quot;height: ${$(window).height()}px&quot; class=&quot;error-message&quot;&gt;\n",
       "                Something went wrong. Please try again.\n",
       "              &lt;/p&gt;\n",
       "            `)\n",
       "          )\n",
       "        }\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function initWebsiteScripts() {\n",
       "      $(&quot;.svg-container&quot;).css(&quot;height&quot;, $(window).height() - 32)\n",
       "    }\n",
       "\n",
       "    function initHandlebarsTemplate() {\n",
       "      // Replace this context with JSON from .py file\n",
       "      const context = {&quot;response.toxicity&quot;: {&quot;histogram&quot;: {&quot;start&quot;: 0.0007464289665222168, &quot;end&quot;: 0.001603901546651125, &quot;width&quot;: 0, &quot;counts&quot;: [8, 1, 1], &quot;max&quot;: 0.0016039013862609863, &quot;min&quot;: 0.0007464289665222168, &quot;bins&quot;: [0.0007464289665222168, 0.0010322531598985195, 0.0013180773532748221, 0.001603901546651125], &quot;n&quot;: 10}}};\n",
       "      // Config handlebars and pass data to HBS template\n",
       "      const source = document.getElementById(&quot;entry-template&quot;).innerHTML;\n",
       "      const template = Handlebars.compile(source);\n",
       "      const html = template(context);\n",
       "      const target = document.getElementById(&quot;generated-html&quot;);\n",
       "      target.innerHTML = html;\n",
       "    }\n",
       "\n",
       "    // Invoke functions -- keep in mind invokation order\n",
       "    registerHandlebarHelperFunctions();\n",
       "    initHandlebarsTemplate();\n",
       "    initWebsiteScripts();\n",
       "  &lt;/script&gt;\n",
       "&lt;/html&gt;\n",
       "\" width=100% height=300px\n",
       "        frameBorder=0></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visualize_langkit_metric(\n",
    "    df,\n",
    "    \"response.toxicity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1bc0bd61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "      <th>response.toxicity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Which AI companies are working with U.S. government on military and intelligence applications?</td>\n",
       "      <td>Meta and Anthropic are working with the U.S. government on military and intelligence applications. Meta made its Llama family of large language models available to the U.S. government for national security purposes. \"Meta's partners in the defense and intelligence markets include Accenture, Amazon, Anduril, Booz Allen, Databricks, Deloitte, IBM, Leidos, Lockheed Martin, Microsoft, Oracle, Palantir, Scale AI, and Snowflake.</td>\n",
       "      <td>0.000866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Is Sony Music Group working with Generative AI?</td>\n",
       "      <td>Yes, Sony Music Group is working with AI and has sent letters to AI developers. Specifically, Sony Music Group has forbidden the use of its music or other media such as lyrics, music videos, and album art for “training, developing, or commercializing any AI systems.”</td>\n",
       "      <td>0.000776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What can you tell me about a new Deepseek model?</td>\n",
       "      <td>DeepSeek released DeepSeek-R1, a large language model that executes long lines of reasoning before producing output. The code and weights are licensed freely for commercial and personal use, including training new models on R1 outputs. DeepSeek-R1 is a mixture-of-experts transformer with 671 billion total parameters, 37 billion of which are active at any given time, and it processes 128,000 tokens of input context. DeepSeek-R1 went toe-to-toe with o1, outperforming that model on 5 of 11 of the benchmarks tested. \"DeepSeek released DeepSeek-R1 , a large language model that executes long lines of reasoning before producing output. The code and weights are licensed freely for commercial and personal use, including training new models on R1 outputs.\" \"DeepSeek-R1 is a mixture-of-experts transformer with 671 billion total parameters, 37 billion of which are active at any given time, and it processes 128,000 tokens of input context.\" \"In DeepSeek's tests, DeepSeek-R1 went toe-to-toe with o1, outperforming that model on 5 of 11 of the benchmarks tested.\"</td>\n",
       "      <td>0.000750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                           prompt  \\\n",
       "2  Which AI companies are working with U.S. government on military and intelligence applications?   \n",
       "1                                                 Is Sony Music Group working with Generative AI?   \n",
       "0                                                What can you tell me about a new Deepseek model?   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  response  \\\n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Meta and Anthropic are working with the U.S. government on military and intelligence applications. Meta made its Llama family of large language models available to the U.S. government for national security purposes. \"Meta's partners in the defense and intelligence markets include Accenture, Amazon, Anduril, Booz Allen, Databricks, Deloitte, IBM, Leidos, Lockheed Martin, Microsoft, Oracle, Palantir, Scale AI, and Snowflake.   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Yes, Sony Music Group is working with AI and has sent letters to AI developers. Specifically, Sony Music Group has forbidden the use of its music or other media such as lyrics, music videos, and album art for “training, developing, or commercializing any AI systems.”   \n",
       "0  DeepSeek released DeepSeek-R1, a large language model that executes long lines of reasoning before producing output. The code and weights are licensed freely for commercial and personal use, including training new models on R1 outputs. DeepSeek-R1 is a mixture-of-experts transformer with 671 billion total parameters, 37 billion of which are active at any given time, and it processes 128,000 tokens of input context. DeepSeek-R1 went toe-to-toe with o1, outperforming that model on 5 of 11 of the benchmarks tested. \"DeepSeek released DeepSeek-R1 , a large language model that executes long lines of reasoning before producing output. The code and weights are licensed freely for commercial and personal use, including training new models on R1 outputs.\" \"DeepSeek-R1 is a mixture-of-experts transformer with 671 billion total parameters, 37 billion of which are active at any given time, and it processes 128,000 tokens of input context.\" \"In DeepSeek's tests, DeepSeek-R1 went toe-to-toe with o1, outperforming that model on 5 of 11 of the benchmarks tested.\"   \n",
       "\n",
       "   response.toxicity  \n",
       "2           0.000866  \n",
       "1           0.000776  \n",
       "0           0.000750  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_langkit_critical_queries(\n",
    "    df,\n",
    "    \"response.toxicity\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d9d4a7",
   "metadata": {},
   "source": [
    "## Hallucinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271cf298",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "from whylogs.experimental.core.udf_schema import register_dataset_udf # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa78ee0",
   "metadata": {},
   "source": [
    "### BLEU Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e8aacdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu = evaluate.load(\"bleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3c91c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@register_dataset_udf([\"prompt\", \"response\"], \n",
    "                      \"response.bleu_score_to_prompt\")\n",
    "def bleu_score(text):\n",
    "  scores = []\n",
    "  for x, y in zip(text[\"prompt\"], text[\"response\"]):\n",
    "    scores.append(\n",
    "      bleu.compute(\n",
    "        predictions=[x], \n",
    "        references=[y], \n",
    "        max_order=2\n",
    "      )[\"bleu\"]\n",
    "    )\n",
    "  return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "099e04fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div></div><iframe srcdoc=\"&lt;!DOCTYPE html&gt;\n",
       "&lt;html lang=&quot;en&quot;&gt;\n",
       "  &lt;head&gt;\n",
       "    &lt;meta charset=&quot;UTF-8&quot; /&gt;\n",
       "    &lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;IE=edge&quot; /&gt;\n",
       "    &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot; /&gt;\n",
       "    &lt;meta name=&quot;description&quot; content=&quot;&quot; /&gt;\n",
       "    &lt;meta name=&quot;author&quot; content=&quot;&quot; /&gt;\n",
       "\n",
       "    &lt;title&gt;Profile Visualizer | whylogs&lt;/title&gt;\n",
       "\n",
       "    &lt;link rel=&quot;icon&quot; href=&quot;images/whylabs-favicon.png&quot; type=&quot;image/png&quot; sizes=&quot;16x16&quot; /&gt;\n",
       "    &lt;link rel=&quot;preconnect&quot; href=&quot;https://fonts.googleapis.com&quot; /&gt;\n",
       "    &lt;link rel=&quot;preconnect&quot; href=&quot;https://fonts.gstatic.com&quot; crossorigin /&gt;\n",
       "    &lt;link href=&quot;https://fonts.googleapis.com/css2?family=Asap:wght@400;500;600;700&amp;display=swap&quot; rel=&quot;stylesheet&quot; /&gt;\n",
       "    &lt;link rel=&quot;preconnect&quot; href=&quot;https://fonts.gstatic.com&quot; /&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.1.0/dist/css/bootstrap.min.css&quot; /&gt;\n",
       "\n",
       "    &lt;script\n",
       "      src=&quot;https://cdnjs.cloudflare.com/ajax/libs/handlebars.js/4.7.7/handlebars.min.js&quot;\n",
       "      integrity=&quot;sha512-RNLkV3d+aLtfcpEyFG8jRbnWHxUqVZozacROI4J2F1sTaDqo1dPQYs01OMi1t1w9Y2FdbSCDSQ2ZVdAC8bzgAg==&quot;\n",
       "      crossorigin=&quot;anonymous&quot;\n",
       "      referrerpolicy=&quot;no-referrer&quot;\n",
       "    &gt;&lt;/script&gt;\n",
       "\n",
       "    &lt;style type=&quot;text/css&quot;&gt;\n",
       "\n",
       "      :root {\n",
       "        /** Branded colors */\n",
       "        --brandSecondary900: #4f595b;\n",
       "        --secondaryLight1000: #313b3d;\n",
       "        /** Purpose colors */\n",
       "        --tealBackground: #eaf2f3;\n",
       "      }\n",
       "\n",
       "      /* RESET STYLE */\n",
       "      *,\n",
       "      *::after,\n",
       "      *::before {\n",
       "        margin: 0;\n",
       "        padding: 0;\n",
       "        box-sizing: border-box;\n",
       "        overflow-y: hidden;\n",
       "      }\n",
       "\n",
       "      /* Screen on smaller screens */\n",
       "      .no-responsive {\n",
       "        display: none;\n",
       "        position: fixed;\n",
       "        top: 0;\n",
       "        left: 0;\n",
       "        z-index: 1031;\n",
       "        width: 100vw;\n",
       "        height: 100vh;\n",
       "        background-color: var(--tealBackground);\n",
       "        display: flex;\n",
       "        align-items: center;\n",
       "        justify-content: center;\n",
       "      }\n",
       "\n",
       "      .desktop-content {\n",
       "        display: flex;\n",
       "        flex-direction: column;\n",
       "      }\n",
       "\n",
       "      .no-responsive__content {\n",
       "        max-width: 600px;\n",
       "        width: 100%;\n",
       "        padding: 0 24px;\n",
       "      }\n",
       "\n",
       "      .no-responsive__title {\n",
       "        font-size: 96px;\n",
       "        font-weight: 300;\n",
       "        color: var(--brandSecondary900);\n",
       "        line-height: 1.167;\n",
       "      }\n",
       "\n",
       "      .no-responsive__text {\n",
       "        margin: 0;\n",
       "        font-size: 16px;\n",
       "        font-weight: 400;\n",
       "        color: var(--brandSecondary900);\n",
       "        line-height: 1.5;\n",
       "      }\n",
       "\n",
       "      .svg-container {\n",
       "        display: inline-block;\n",
       "        position: relative;\n",
       "        width: 100%;\n",
       "        vertical-align: top;\n",
       "        overflow: hidden;\n",
       "      }\n",
       "\n",
       "      .svg-content-responsive {\n",
       "        display: inline-block;\n",
       "        position: absolute;\n",
       "        left: 0;\n",
       "      }\n",
       "\n",
       "      .circle-color {\n",
       "       display: inline-block;\n",
       "       padding: 5px;\n",
       "       border-radius: 50px;\n",
       "     }\n",
       "\n",
       "     .colors-for-distingushing-charts {\n",
       "       padding-right: 10px;\n",
       "     }\n",
       "\n",
       "     .display-flex{\n",
       "       display: flex;\n",
       "     }\n",
       "\n",
       "     .align-items-flex-end {\n",
       "       align-items: flex-end;\n",
       "     }\n",
       "\n",
       "     .chart-box-title {\n",
       "       width: 88%;\n",
       "       justify-content: space-between;\n",
       "       margin: 10px;\n",
       "       margin-top: 15px;\n",
       "       bottom: 0;\n",
       "     }\n",
       "\n",
       "     .chart-box-title p{\n",
       "       margin-bottom: 0;\n",
       "       font-family: Asap;\n",
       "       font-weight: bold;\n",
       "       font-size: 18px;\n",
       "       line-height: 16px;\n",
       "       color: #4F595B;\n",
       "     }\n",
       "\n",
       "    .bar {\n",
       "      font: 10px sans-serif;\n",
       "    }\n",
       "\n",
       "    .bar path,\n",
       "    .bar line {\n",
       "      fill: none;\n",
       "      stroke: #000;\n",
       "      shape-rendering: crispEdges;\n",
       "    }\n",
       "\n",
       "    .error-message {\n",
       "      display: flex;\n",
       "      justify-content: center;\n",
       "      align-items: center;\n",
       "      color: rgb(255, 114, 71);\n",
       "      font-size: 30px;\n",
       "      font-weight: 900;\n",
       "    }\n",
       "\n",
       "     @media screen and (min-width: 500px) {\n",
       "       .desktop-content {\n",
       "         display: block;\n",
       "       }\n",
       "       .no-responsive {\n",
       "         display: none;\n",
       "       }\n",
       "     }\n",
       "    &lt;/style&gt;\n",
       "  &lt;/head&gt;\n",
       "\n",
       "  &lt;body id=&quot;generated-html&quot;&gt;&lt;/body&gt;\n",
       "  &lt;script id=&quot;entry-template&quot; type=&quot;text/x-handlebars-template&quot;&gt;\n",
       "    \n",
       "      &lt;div class=&quot;desktop-content&quot;&gt;\n",
       "{{#each this}}              &lt;div class=&quot;chart-box&quot; id=&quot;chart-box&quot;&gt;\n",
       "                &lt;div class=&quot;chart-box-title display-flex&quot;&gt;\n",
       "                  &lt;p&gt;{{@key}}&lt;/p&gt;\n",
       "                  &lt;div class=&quot;display-flex&quot;&gt;\n",
       "                    &lt;div class=&quot;colors-for-distingushing-charts&quot;&gt;\n",
       "                      &lt;div class=&quot;circle-color&quot; style=&quot;background: #44C0E7;&quot;&gt;&lt;/div&gt;\n",
       "                      &lt;text alignment-baseline=&quot;middle&quot; style=&quot;font-size: 15px;&quot;&gt;Target&lt;/text&gt;\n",
       "                    &lt;/div&gt;\n",
       "                    &lt;div class=&quot;colors-for-distingushing-charts&quot;&gt;\n",
       "                      &lt;div class=&quot;circle-color&quot; style=&quot;background: #F5843C&quot;&gt;&lt;/div&gt;\n",
       "                      &lt;text alignment-baseline=&quot;middle&quot; style=&quot;font-size: 15px;&quot;&gt;Reference&lt;/text&gt;\n",
       "                    &lt;/div&gt;\n",
       "                  &lt;/div&gt;&lt;/div&gt;\n",
       "                &lt;div class=&quot;svg-container&quot;&gt;{{{getDoubleHistogramChart this}}}&lt;/div&gt;\n",
       "              &lt;/div&gt;\n",
       "{{/each}}      &lt;/div&gt;\n",
       "      &lt;div class=&quot;no-responsive&quot;&gt;\n",
       "        &lt;div class=&quot;no-responsive__content&quot;&gt;\n",
       "          &lt;h1 class=&quot;no-responsive__title&quot;&gt;Hold on! :)&lt;/h1&gt;\n",
       "          &lt;p class=&quot;no-responsive__text&quot;&gt;\n",
       "            It looks like your current screen size or device is not yet supported by the WhyLabs Sandbox. The Sandbox is\n",
       "            best experienced on a desktop computer. Please try maximizing this window or switching to another device. We\n",
       "            are working on adding support for a larger variety of devices.\n",
       "          &lt;/p&gt;\n",
       "        &lt;/div&gt;\n",
       "      &lt;/div&gt;\n",
       "    \n",
       "  &lt;/script&gt;\n",
       "\n",
       "  &lt;script src=&quot;https://code.jquery.com/jquery-3.6.0.min.js&quot; integrity=&quot;sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=&quot; crossorigin=&quot;anonymous&quot;&gt;&lt;/script&gt;\n",
       "\n",
       "  &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/d3/6.7.0/d3.min.js&quot; integrity=&quot;sha512-cd6CHE+XWDQ33ElJqsi0MdNte3S+bQY819f7p3NUHgwQQLXSKjE4cPZTeGNI+vaxZynk1wVU3hoHmow3m089wA==&quot; crossorigin=&quot;anonymous&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/script&gt;\n",
       "\n",
       "  &lt;script&gt;\n",
       "    function registerHandlebarHelperFunctions() {\n",
       "      //helper fun\n",
       "\n",
       "      class GenerateChartParams {\n",
       "        constructor(height, width, targetData, referenceData, bottomMargin=30, topMargin=5) {\n",
       "          this.MARGIN = {\n",
       "            TOP: topMargin,\n",
       "            RIGHT: 5,\n",
       "            BOTTOM: bottomMargin,\n",
       "            LEFT: 55,\n",
       "          };\n",
       "          this.SVG_WIDTH = width;\n",
       "          this.SVG_HEIGHT = height;\n",
       "          this.CHART_WIDTH = this.SVG_WIDTH - this.MARGIN.LEFT - this.MARGIN.RIGHT;\n",
       "          this.CHART_HEIGHT = this.SVG_HEIGHT - this.MARGIN.TOP - this.MARGIN.BOTTOM;\n",
       "          this.svgEl = d3.create(&quot;svg&quot;)\n",
       "             .attr(&quot;preserveAspectRatio&quot;, &quot;xMinYMin meet&quot;)\n",
       "             .attr(&quot;viewBox&quot;, `0 0 ${$(window).width()+100} ${$(window).height()-30}`)\n",
       "             .classed(&quot;svg-content-responsive&quot;, true)\n",
       "          this.maxYValue = d3.max(targetData, (d) =&gt; Math.abs(d.axisY));\n",
       "          this.minYValue = d3.min(targetData, (d) =&gt; Math.abs(d.axisY));\n",
       "          const mergedReferenceData = referenceData.map(({axisX, axisY}) =&gt; {\n",
       "            return {axisX, axisY}\n",
       "          })\n",
       "          const mergedTargetedData = targetData.map(({axisX, axisY}) =&gt; {\n",
       "            return {axisX, axisY}\n",
       "          })\n",
       "\n",
       "          this.charts2 = mergedReferenceData.concat(mergedTargetedData)\n",
       "          this.charts2 = this.charts2.sort(function(a, b) { return a - b; });\n",
       "\n",
       "          this.targetBinWidth = targetData[1]?.axisX - targetData[0]?.axisX\n",
       "          this.referenceBinWidth = referenceData[1]?.axisX - referenceData[0]?.axisX\n",
       "          this.maxTargetXValue = d3.max(targetData, (d) =&gt; d.axisX);\n",
       "\n",
       "          this.maxReferenceXValue = d3.max(referenceData, (d) =&gt; d.axisX);\n",
       "\n",
       "          this.xScale = d3\n",
       "              .scaleLinear()\n",
       "         .domain([d3.min(this.charts2, function(d) { return parseFloat(d.axisX); }),(this.maxTargetXValue+this.targetBinWidth &gt;= this.maxReferenceXValue+this.referenceBinWidth) ? this.maxTargetXValue+this.targetBinWidth:this.maxReferenceXValue+this.referenceBinWidth])\n",
       "         .range([0, this.CHART_WIDTH ]);\n",
       "\n",
       "         this.svgEl.append(&quot;g&quot;)\n",
       "             .attr(&quot;transform&quot;, &quot;translate(&quot;+ this.MARGIN.LEFT +&quot;,&quot; + this.SVG_HEIGHT + &quot;)&quot;)\n",
       "             .call(d3.axisBottom(this.xScale));\n",
       "          this.yScale = d3.scaleLinear()\n",
       "              .range([this.CHART_HEIGHT , 0])\n",
       "              .domain([d3.min(this.charts2, function(d) { return parseFloat(d.axisY); }), d3.max(this.charts2, function(d) { return parseFloat(d.axisY); })*1.2])\n",
       "              .nice();\n",
       "        }\n",
       "      }\n",
       "\n",
       "      function chartData(column) {\n",
       "        const data = [];\n",
       "        if (column?.histogram) {\n",
       "          for (let i = 0; i&lt;column.histogram.bins.length; i++) {\n",
       "            data.push({\n",
       "              axisY: column.histogram.counts[i] || 0,\n",
       "              axisX: column.histogram.bins[i] || 0,\n",
       "            });\n",
       "          }\n",
       "        } else {\n",
       "            $(document).ready(() =&gt;\n",
       "              $(&quot;.desktop-content&quot;).html(`\n",
       "                &lt;p style=&quot;height: ${$(window).height()}px&quot; class=&quot;error-message&quot;&gt;\n",
       "                  Something went wrong. Please try again.\n",
       "                &lt;/p&gt;\n",
       "              `)\n",
       "            )\n",
       "          }\n",
       "\n",
       "        return data\n",
       "      }\n",
       "\n",
       "      function verticalLine(column) {\n",
       "        const line_data = [];\n",
       "        if (column?.vertical_line) {\n",
       "            line_data.push({\n",
       "              axisX: column?.vertical_line || 0,\n",
       "            });\n",
       "\n",
       "        }\n",
       "\n",
       "        return line_data\n",
       "      }\n",
       "\n",
       "      function generateDoubleHistogramChart(targetData, referenceData) {\n",
       "        let histogramData = [],\n",
       "            overlappedHistogramData = [];\n",
       "        let yFormat;\n",
       "\n",
       "        histogramData = chartData(targetData)\n",
       "        overlappedHistogramData = chartData(referenceData)\n",
       "        lineData = verticalLine(targetData)\n",
       "\n",
       "        const sizes = new GenerateChartParams($(window).height()-80, $(window).width(), histogramData, overlappedHistogramData)\n",
       "        const {\n",
       "          MARGIN,\n",
       "          SVG_WIDTH,\n",
       "          SVG_HEIGHT,\n",
       "          CHART_WIDTH,\n",
       "          CHART_HEIGHT,\n",
       "          svgEl,\n",
       "          maxYValue,\n",
       "          minYValue,\n",
       "          xScale,\n",
       "          yScale\n",
       "        } = sizes\n",
       "\n",
       "        const rectColors = [&quot;#44C0E7&quot;, &quot;#F5843C&quot;]\n",
       "        const yAxis = d3.axisLeft(yScale).ticks(SVG_HEIGHT / 40);\n",
       "\n",
       "        svgEl.append(&quot;g&quot;)\n",
       "          .attr(&quot;transform&quot;, `translate(${MARGIN.LEFT}, ${MARGIN.BOTTOM})`)\n",
       "          .call(yAxis)\n",
       "          .call(g =&gt; g.select(&quot;.domain&quot;).remove())\n",
       "          .call(g =&gt; g.selectAll(&quot;.tick line&quot;)\n",
       "              .attr(&quot;x2&quot;, CHART_WIDTH)\n",
       "              .attr(&quot;stroke-opacity&quot;, 0.1))\n",
       "          .call(g =&gt; g.append(&quot;text&quot;)\n",
       "              .attr(&quot;x&quot;, -MARGIN.LEFT)\n",
       "              .attr(&quot;y&quot;, 10)\n",
       "              .attr(&quot;fill&quot;, &quot;currentColor&quot;)\n",
       "              .attr(&quot;text-anchor&quot;, &quot;start&quot;))\n",
       "\n",
       "        svgEl.append(&quot;line&quot;)\n",
       "          .attr(&quot;transform&quot;, `translate(${MARGIN.LEFT}, ${MARGIN.BOTTOM})`)\n",
       "          .data(lineData)\n",
       "          .attr(&quot;x1&quot;, (d) =&gt; xScale(d.axisX))\n",
       "          .attr(&quot;y1&quot;, MARGIN.TOP + MARGIN.TOP)\n",
       "          .attr(&quot;x2&quot;, (d) =&gt; xScale(d.axisX))\n",
       "          .attr(&quot;y2&quot;, CHART_HEIGHT + MARGIN.TOP)\n",
       "          .style(&quot;stroke-width&quot;, 2)\n",
       "          .style(&quot;stroke&quot;, &quot;#44C0E7&quot;)\n",
       "          .style(&quot;stroke-dasharray&quot;, (3,3))\n",
       "          .style(&quot;fill&quot;, &quot;none&quot;);\n",
       "\n",
       "        svgEl.append(&quot;text&quot;)\n",
       "          .attr(&quot;transform&quot;, &quot;rotate(-90)&quot;)\n",
       "          .data(lineData)\n",
       "          .attr(&quot;y&quot;, (d) =&gt; xScale(d.axisX) + MARGIN.LEFT)\n",
       "          .attr(&quot;x&quot;, 0 - (SVG_HEIGHT / 2))\n",
       "          .attr(&quot;dy&quot;, &quot;1em&quot;)\n",
       "          .style(&quot;text-anchor&quot;, &quot;middle&quot;)\n",
       "          .text(&quot;single value&quot;)\n",
       "          .style(&quot;font-size&quot;, &quot;15&quot;)\n",
       "          .style(&quot;opacity&quot;, &quot;0.6&quot;)\n",
       "\n",
       "        svgEl.append(&quot;text&quot;)\n",
       "          .attr(&quot;transform&quot;,\n",
       "                &quot;translate(&quot; + (CHART_WIDTH/2) + &quot; ,&quot; +\n",
       "                               (CHART_HEIGHT + MARGIN.TOP + 75) + &quot;)&quot;)\n",
       "          .style(&quot;text-anchor&quot;, &quot;middle&quot;)\n",
       "          .text(&quot;Values&quot;)\n",
       "          .style(&quot;font-size&quot;, &quot;15&quot;)\n",
       "          .style(&quot;opacity&quot;, &quot;0.6&quot;)\n",
       "\n",
       "        svgEl.append(&quot;text&quot;)\n",
       "          .attr(&quot;transform&quot;, &quot;rotate(-90)&quot;)\n",
       "          .attr(&quot;y&quot;, 0)\n",
       "          .attr(&quot;x&quot;, 0 - (SVG_HEIGHT / 2))\n",
       "          .attr(&quot;dy&quot;, &quot;1em&quot;)\n",
       "          .style(&quot;text-anchor&quot;, &quot;middle&quot;)\n",
       "          .text(&quot;Counts&quot;)\n",
       "          .style(&quot;font-size&quot;, &quot;15&quot;)\n",
       "          .style(&quot;opacity&quot;, &quot;0.6&quot;)\n",
       "\n",
       "          const gChart = svgEl.append(&quot;g&quot;);\n",
       "          gChart\n",
       "          .attr(&quot;transform&quot;, &quot;translate(&quot;+ MARGIN.LEFT +&quot;,0)&quot;)\n",
       "          .selectAll(&quot;.bar&quot;)\n",
       "          .data(histogramData)\n",
       "          .enter()\n",
       "          .append(&quot;rect&quot;)\n",
       "          .style(&quot;stroke&quot;, &quot;#021826&quot;)\n",
       "          .classed(&quot;bar&quot;, true)\n",
       "          .attr(&quot;width&quot;, function(d) { return xScale(histogramData[1]?.axisX)-xScale(histogramData[0]?.axisX); })\n",
       "          .attr(&quot;height&quot;, (d) =&gt; CHART_HEIGHT - yScale(d.axisY))\n",
       "          .attr(&quot;x&quot;, 1)\n",
       "          .attr(&quot;transform&quot;, function(d) { return &quot;translate(&quot; + xScale(d.axisX) + &quot;,&quot; + 0  +  &quot;)&quot;; })\n",
       "          .attr(&quot;y&quot;, (d) =&gt; yScale(d.axisY) + MARGIN.TOP + MARGIN.BOTTOM)\n",
       "          .attr(&quot;fill&quot;, rectColors[0])\n",
       "          .style(&quot;opacity&quot;,&quot;0.6&quot;)\n",
       "\n",
       "          const gChart1 = svgEl.append(&quot;g&quot;);\n",
       "          gChart1\n",
       "          .attr(&quot;transform&quot;, &quot;translate(&quot;+ MARGIN.LEFT +&quot;,0)&quot;)\n",
       "          .selectAll(&quot;.bar&quot;)\n",
       "          .data(overlappedHistogramData)\n",
       "          .enter()\n",
       "          .append(&quot;rect&quot;)\n",
       "          .style(&quot;stroke&quot;, &quot;#021826&quot;)\n",
       "          .classed(&quot;bar&quot;, true)\n",
       "          .attr(&quot;width&quot;, function(d) { return xScale(overlappedHistogramData[1]?.axisX)-xScale(overlappedHistogramData[0]?.axisX); })\n",
       "          .attr(&quot;height&quot;, (d) =&gt; CHART_HEIGHT - yScale(d.axisY))\n",
       "          .attr(&quot;x&quot;, 1)\n",
       "          .attr(&quot;transform&quot;, function(d) { return &quot;translate(&quot; + xScale(d.axisX) + &quot;,&quot; + 0  +  &quot;)&quot;; })\n",
       "          .attr(&quot;y&quot;, (d) =&gt; yScale(d.axisY) + MARGIN.TOP + MARGIN.BOTTOM)\n",
       "          .attr(&quot;fill&quot;, rectColors[1])\n",
       "          .style(&quot;opacity&quot;,&quot;0.6&quot;)\n",
       "\n",
       "        return svgEl._groups[0][0].outerHTML;\n",
       "      }\n",
       "\n",
       "      const profileFromCSVfile = {&quot;response.bleu_score_to_prompt&quot;: {&quot;histogram&quot;: {&quot;start&quot;: 0.0, &quot;end&quot;: 0.07798081481186966, &quot;width&quot;: 0, &quot;counts&quot;: [0, 0, 0], &quot;max&quot;: 0.07798080701378897, &quot;min&quot;: 0.0, &quot;bins&quot;: [0.0, 0.025993604937289888, 0.051987209874579776, 0.07798081481186966], &quot;n&quot;: 10}}}\n",
       "\n",
       "      Handlebars.registerHelper(&quot;getDoubleHistogramChart&quot;,(column,key) =&gt; {\n",
       "          const columnKey = key.data.key\n",
       "        try {\n",
       "          if (profileFromCSVfile) {\n",
       "          return  generateDoubleHistogramChart (\n",
       "              column,\n",
       "              profileFromCSVfile[columnKey]\n",
       "            )\n",
       "          }\n",
       "        } catch (err) {\n",
       "          $(document).ready(() =&gt;\n",
       "            $(&quot;.desktop-content&quot;).html(`\n",
       "              &lt;p style=&quot;height: ${$(window).height()}px&quot; class=&quot;error-message&quot;&gt;\n",
       "                Something went wrong. Please try again.\n",
       "              &lt;/p&gt;\n",
       "            `)\n",
       "          )\n",
       "        }\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function initWebsiteScripts() {\n",
       "      $(&quot;.svg-container&quot;).css(&quot;height&quot;, $(window).height() - 32)\n",
       "    }\n",
       "\n",
       "    function initHandlebarsTemplate() {\n",
       "      // Replace this context with JSON from .py file\n",
       "      const context = {&quot;response.bleu_score_to_prompt&quot;: {&quot;histogram&quot;: {&quot;start&quot;: 0.0, &quot;end&quot;: 0.07798081481186966, &quot;width&quot;: 0, &quot;counts&quot;: [8, 1, 1], &quot;max&quot;: 0.07798080701378897, &quot;min&quot;: 0.0, &quot;bins&quot;: [0.0, 0.025993604937289888, 0.051987209874579776, 0.07798081481186966], &quot;n&quot;: 10}}};\n",
       "      // Config handlebars and pass data to HBS template\n",
       "      const source = document.getElementById(&quot;entry-template&quot;).innerHTML;\n",
       "      const template = Handlebars.compile(source);\n",
       "      const html = template(context);\n",
       "      const target = document.getElementById(&quot;generated-html&quot;);\n",
       "      target.innerHTML = html;\n",
       "    }\n",
       "\n",
       "    // Invoke functions -- keep in mind invokation order\n",
       "    registerHandlebarHelperFunctions();\n",
       "    initHandlebarsTemplate();\n",
       "    initWebsiteScripts();\n",
       "  &lt;/script&gt;\n",
       "&lt;/html&gt;\n",
       "\" width=100% height=300px\n",
       "        frameBorder=0></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visualize_langkit_metric(\n",
    "    df, \n",
    "    \"response.bleu_score_to_prompt\", \n",
    "    numeric=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c714f7",
   "metadata": {},
   "source": [
    "### BERT Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eda2d497",
   "metadata": {},
   "outputs": [],
   "source": [
    "bertscore = evaluate.load(\"bertscore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3cd35f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "@register_dataset_udf([\"prompt\", \"response\"], \"response.bert_score_to_prompt\")\n",
    "def bert_score(text):\n",
    "  return bertscore.compute(\n",
    "      predictions=text[\"prompt\"].to_numpy(),\n",
    "      references=text[\"response\"].to_numpy(),\n",
    "      model_type=\"distilbert-base-uncased\"\n",
    "    )[\"f1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "59453826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div></div><iframe srcdoc=\"&lt;!DOCTYPE html&gt;\n",
       "&lt;html lang=&quot;en&quot;&gt;\n",
       "  &lt;head&gt;\n",
       "    &lt;meta charset=&quot;UTF-8&quot; /&gt;\n",
       "    &lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;IE=edge&quot; /&gt;\n",
       "    &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot; /&gt;\n",
       "    &lt;meta name=&quot;description&quot; content=&quot;&quot; /&gt;\n",
       "    &lt;meta name=&quot;author&quot; content=&quot;&quot; /&gt;\n",
       "\n",
       "    &lt;title&gt;Profile Visualizer | whylogs&lt;/title&gt;\n",
       "\n",
       "    &lt;link rel=&quot;icon&quot; href=&quot;images/whylabs-favicon.png&quot; type=&quot;image/png&quot; sizes=&quot;16x16&quot; /&gt;\n",
       "    &lt;link rel=&quot;preconnect&quot; href=&quot;https://fonts.googleapis.com&quot; /&gt;\n",
       "    &lt;link rel=&quot;preconnect&quot; href=&quot;https://fonts.gstatic.com&quot; crossorigin /&gt;\n",
       "    &lt;link href=&quot;https://fonts.googleapis.com/css2?family=Asap:wght@400;500;600;700&amp;display=swap&quot; rel=&quot;stylesheet&quot; /&gt;\n",
       "    &lt;link rel=&quot;preconnect&quot; href=&quot;https://fonts.gstatic.com&quot; /&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.1.0/dist/css/bootstrap.min.css&quot; /&gt;\n",
       "\n",
       "    &lt;script\n",
       "      src=&quot;https://cdnjs.cloudflare.com/ajax/libs/handlebars.js/4.7.7/handlebars.min.js&quot;\n",
       "      integrity=&quot;sha512-RNLkV3d+aLtfcpEyFG8jRbnWHxUqVZozacROI4J2F1sTaDqo1dPQYs01OMi1t1w9Y2FdbSCDSQ2ZVdAC8bzgAg==&quot;\n",
       "      crossorigin=&quot;anonymous&quot;\n",
       "      referrerpolicy=&quot;no-referrer&quot;\n",
       "    &gt;&lt;/script&gt;\n",
       "\n",
       "    &lt;style type=&quot;text/css&quot;&gt;\n",
       "\n",
       "      :root {\n",
       "        /** Branded colors */\n",
       "        --brandSecondary900: #4f595b;\n",
       "        --secondaryLight1000: #313b3d;\n",
       "        /** Purpose colors */\n",
       "        --tealBackground: #eaf2f3;\n",
       "      }\n",
       "\n",
       "      /* RESET STYLE */\n",
       "      *,\n",
       "      *::after,\n",
       "      *::before {\n",
       "        margin: 0;\n",
       "        padding: 0;\n",
       "        box-sizing: border-box;\n",
       "        overflow-y: hidden;\n",
       "      }\n",
       "\n",
       "      /* Screen on smaller screens */\n",
       "      .no-responsive {\n",
       "        display: none;\n",
       "        position: fixed;\n",
       "        top: 0;\n",
       "        left: 0;\n",
       "        z-index: 1031;\n",
       "        width: 100vw;\n",
       "        height: 100vh;\n",
       "        background-color: var(--tealBackground);\n",
       "        display: flex;\n",
       "        align-items: center;\n",
       "        justify-content: center;\n",
       "      }\n",
       "\n",
       "      .desktop-content {\n",
       "        display: flex;\n",
       "        flex-direction: column;\n",
       "      }\n",
       "\n",
       "      .no-responsive__content {\n",
       "        max-width: 600px;\n",
       "        width: 100%;\n",
       "        padding: 0 24px;\n",
       "      }\n",
       "\n",
       "      .no-responsive__title {\n",
       "        font-size: 96px;\n",
       "        font-weight: 300;\n",
       "        color: var(--brandSecondary900);\n",
       "        line-height: 1.167;\n",
       "      }\n",
       "\n",
       "      .no-responsive__text {\n",
       "        margin: 0;\n",
       "        font-size: 16px;\n",
       "        font-weight: 400;\n",
       "        color: var(--brandSecondary900);\n",
       "        line-height: 1.5;\n",
       "      }\n",
       "\n",
       "      .svg-container {\n",
       "        display: inline-block;\n",
       "        position: relative;\n",
       "        width: 100%;\n",
       "        vertical-align: top;\n",
       "        overflow: hidden;\n",
       "      }\n",
       "\n",
       "      .svg-content-responsive {\n",
       "        display: inline-block;\n",
       "        position: absolute;\n",
       "        left: 0;\n",
       "      }\n",
       "\n",
       "      .circle-color {\n",
       "       display: inline-block;\n",
       "       padding: 5px;\n",
       "       border-radius: 50px;\n",
       "     }\n",
       "\n",
       "     .colors-for-distingushing-charts {\n",
       "       padding-right: 10px;\n",
       "     }\n",
       "\n",
       "     .display-flex{\n",
       "       display: flex;\n",
       "     }\n",
       "\n",
       "     .align-items-flex-end {\n",
       "       align-items: flex-end;\n",
       "     }\n",
       "\n",
       "     .chart-box-title {\n",
       "       width: 88%;\n",
       "       justify-content: space-between;\n",
       "       margin: 10px;\n",
       "       margin-top: 15px;\n",
       "       bottom: 0;\n",
       "     }\n",
       "\n",
       "     .chart-box-title p{\n",
       "       margin-bottom: 0;\n",
       "       font-family: Asap;\n",
       "       font-weight: bold;\n",
       "       font-size: 18px;\n",
       "       line-height: 16px;\n",
       "       color: #4F595B;\n",
       "     }\n",
       "\n",
       "    .bar {\n",
       "      font: 10px sans-serif;\n",
       "    }\n",
       "\n",
       "    .bar path,\n",
       "    .bar line {\n",
       "      fill: none;\n",
       "      stroke: #000;\n",
       "      shape-rendering: crispEdges;\n",
       "    }\n",
       "\n",
       "    .error-message {\n",
       "      display: flex;\n",
       "      justify-content: center;\n",
       "      align-items: center;\n",
       "      color: rgb(255, 114, 71);\n",
       "      font-size: 30px;\n",
       "      font-weight: 900;\n",
       "    }\n",
       "\n",
       "     @media screen and (min-width: 500px) {\n",
       "       .desktop-content {\n",
       "         display: block;\n",
       "       }\n",
       "       .no-responsive {\n",
       "         display: none;\n",
       "       }\n",
       "     }\n",
       "    &lt;/style&gt;\n",
       "  &lt;/head&gt;\n",
       "\n",
       "  &lt;body id=&quot;generated-html&quot;&gt;&lt;/body&gt;\n",
       "  &lt;script id=&quot;entry-template&quot; type=&quot;text/x-handlebars-template&quot;&gt;\n",
       "    \n",
       "      &lt;div class=&quot;desktop-content&quot;&gt;\n",
       "{{#each this}}              &lt;div class=&quot;chart-box&quot; id=&quot;chart-box&quot;&gt;\n",
       "                &lt;div class=&quot;chart-box-title display-flex&quot;&gt;\n",
       "                  &lt;p&gt;{{@key}}&lt;/p&gt;\n",
       "                  &lt;div class=&quot;display-flex&quot;&gt;\n",
       "                    &lt;div class=&quot;colors-for-distingushing-charts&quot;&gt;\n",
       "                      &lt;div class=&quot;circle-color&quot; style=&quot;background: #44C0E7;&quot;&gt;&lt;/div&gt;\n",
       "                      &lt;text alignment-baseline=&quot;middle&quot; style=&quot;font-size: 15px;&quot;&gt;Target&lt;/text&gt;\n",
       "                    &lt;/div&gt;\n",
       "                    &lt;div class=&quot;colors-for-distingushing-charts&quot;&gt;\n",
       "                      &lt;div class=&quot;circle-color&quot; style=&quot;background: #F5843C&quot;&gt;&lt;/div&gt;\n",
       "                      &lt;text alignment-baseline=&quot;middle&quot; style=&quot;font-size: 15px;&quot;&gt;Reference&lt;/text&gt;\n",
       "                    &lt;/div&gt;\n",
       "                  &lt;/div&gt;&lt;/div&gt;\n",
       "                &lt;div class=&quot;svg-container&quot;&gt;{{{getDoubleHistogramChart this}}}&lt;/div&gt;\n",
       "              &lt;/div&gt;\n",
       "{{/each}}      &lt;/div&gt;\n",
       "      &lt;div class=&quot;no-responsive&quot;&gt;\n",
       "        &lt;div class=&quot;no-responsive__content&quot;&gt;\n",
       "          &lt;h1 class=&quot;no-responsive__title&quot;&gt;Hold on! :)&lt;/h1&gt;\n",
       "          &lt;p class=&quot;no-responsive__text&quot;&gt;\n",
       "            It looks like your current screen size or device is not yet supported by the WhyLabs Sandbox. The Sandbox is\n",
       "            best experienced on a desktop computer. Please try maximizing this window or switching to another device. We\n",
       "            are working on adding support for a larger variety of devices.\n",
       "          &lt;/p&gt;\n",
       "        &lt;/div&gt;\n",
       "      &lt;/div&gt;\n",
       "    \n",
       "  &lt;/script&gt;\n",
       "\n",
       "  &lt;script src=&quot;https://code.jquery.com/jquery-3.6.0.min.js&quot; integrity=&quot;sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=&quot; crossorigin=&quot;anonymous&quot;&gt;&lt;/script&gt;\n",
       "\n",
       "  &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/d3/6.7.0/d3.min.js&quot; integrity=&quot;sha512-cd6CHE+XWDQ33ElJqsi0MdNte3S+bQY819f7p3NUHgwQQLXSKjE4cPZTeGNI+vaxZynk1wVU3hoHmow3m089wA==&quot; crossorigin=&quot;anonymous&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/script&gt;\n",
       "\n",
       "  &lt;script&gt;\n",
       "    function registerHandlebarHelperFunctions() {\n",
       "      //helper fun\n",
       "\n",
       "      class GenerateChartParams {\n",
       "        constructor(height, width, targetData, referenceData, bottomMargin=30, topMargin=5) {\n",
       "          this.MARGIN = {\n",
       "            TOP: topMargin,\n",
       "            RIGHT: 5,\n",
       "            BOTTOM: bottomMargin,\n",
       "            LEFT: 55,\n",
       "          };\n",
       "          this.SVG_WIDTH = width;\n",
       "          this.SVG_HEIGHT = height;\n",
       "          this.CHART_WIDTH = this.SVG_WIDTH - this.MARGIN.LEFT - this.MARGIN.RIGHT;\n",
       "          this.CHART_HEIGHT = this.SVG_HEIGHT - this.MARGIN.TOP - this.MARGIN.BOTTOM;\n",
       "          this.svgEl = d3.create(&quot;svg&quot;)\n",
       "             .attr(&quot;preserveAspectRatio&quot;, &quot;xMinYMin meet&quot;)\n",
       "             .attr(&quot;viewBox&quot;, `0 0 ${$(window).width()+100} ${$(window).height()-30}`)\n",
       "             .classed(&quot;svg-content-responsive&quot;, true)\n",
       "          this.maxYValue = d3.max(targetData, (d) =&gt; Math.abs(d.axisY));\n",
       "          this.minYValue = d3.min(targetData, (d) =&gt; Math.abs(d.axisY));\n",
       "          const mergedReferenceData = referenceData.map(({axisX, axisY}) =&gt; {\n",
       "            return {axisX, axisY}\n",
       "          })\n",
       "          const mergedTargetedData = targetData.map(({axisX, axisY}) =&gt; {\n",
       "            return {axisX, axisY}\n",
       "          })\n",
       "\n",
       "          this.charts2 = mergedReferenceData.concat(mergedTargetedData)\n",
       "          this.charts2 = this.charts2.sort(function(a, b) { return a - b; });\n",
       "\n",
       "          this.targetBinWidth = targetData[1]?.axisX - targetData[0]?.axisX\n",
       "          this.referenceBinWidth = referenceData[1]?.axisX - referenceData[0]?.axisX\n",
       "          this.maxTargetXValue = d3.max(targetData, (d) =&gt; d.axisX);\n",
       "\n",
       "          this.maxReferenceXValue = d3.max(referenceData, (d) =&gt; d.axisX);\n",
       "\n",
       "          this.xScale = d3\n",
       "              .scaleLinear()\n",
       "         .domain([d3.min(this.charts2, function(d) { return parseFloat(d.axisX); }),(this.maxTargetXValue+this.targetBinWidth &gt;= this.maxReferenceXValue+this.referenceBinWidth) ? this.maxTargetXValue+this.targetBinWidth:this.maxReferenceXValue+this.referenceBinWidth])\n",
       "         .range([0, this.CHART_WIDTH ]);\n",
       "\n",
       "         this.svgEl.append(&quot;g&quot;)\n",
       "             .attr(&quot;transform&quot;, &quot;translate(&quot;+ this.MARGIN.LEFT +&quot;,&quot; + this.SVG_HEIGHT + &quot;)&quot;)\n",
       "             .call(d3.axisBottom(this.xScale));\n",
       "          this.yScale = d3.scaleLinear()\n",
       "              .range([this.CHART_HEIGHT , 0])\n",
       "              .domain([d3.min(this.charts2, function(d) { return parseFloat(d.axisY); }), d3.max(this.charts2, function(d) { return parseFloat(d.axisY); })*1.2])\n",
       "              .nice();\n",
       "        }\n",
       "      }\n",
       "\n",
       "      function chartData(column) {\n",
       "        const data = [];\n",
       "        if (column?.histogram) {\n",
       "          for (let i = 0; i&lt;column.histogram.bins.length; i++) {\n",
       "            data.push({\n",
       "              axisY: column.histogram.counts[i] || 0,\n",
       "              axisX: column.histogram.bins[i] || 0,\n",
       "            });\n",
       "          }\n",
       "        } else {\n",
       "            $(document).ready(() =&gt;\n",
       "              $(&quot;.desktop-content&quot;).html(`\n",
       "                &lt;p style=&quot;height: ${$(window).height()}px&quot; class=&quot;error-message&quot;&gt;\n",
       "                  Something went wrong. Please try again.\n",
       "                &lt;/p&gt;\n",
       "              `)\n",
       "            )\n",
       "          }\n",
       "\n",
       "        return data\n",
       "      }\n",
       "\n",
       "      function verticalLine(column) {\n",
       "        const line_data = [];\n",
       "        if (column?.vertical_line) {\n",
       "            line_data.push({\n",
       "              axisX: column?.vertical_line || 0,\n",
       "            });\n",
       "\n",
       "        }\n",
       "\n",
       "        return line_data\n",
       "      }\n",
       "\n",
       "      function generateDoubleHistogramChart(targetData, referenceData) {\n",
       "        let histogramData = [],\n",
       "            overlappedHistogramData = [];\n",
       "        let yFormat;\n",
       "\n",
       "        histogramData = chartData(targetData)\n",
       "        overlappedHistogramData = chartData(referenceData)\n",
       "        lineData = verticalLine(targetData)\n",
       "\n",
       "        const sizes = new GenerateChartParams($(window).height()-80, $(window).width(), histogramData, overlappedHistogramData)\n",
       "        const {\n",
       "          MARGIN,\n",
       "          SVG_WIDTH,\n",
       "          SVG_HEIGHT,\n",
       "          CHART_WIDTH,\n",
       "          CHART_HEIGHT,\n",
       "          svgEl,\n",
       "          maxYValue,\n",
       "          minYValue,\n",
       "          xScale,\n",
       "          yScale\n",
       "        } = sizes\n",
       "\n",
       "        const rectColors = [&quot;#44C0E7&quot;, &quot;#F5843C&quot;]\n",
       "        const yAxis = d3.axisLeft(yScale).ticks(SVG_HEIGHT / 40);\n",
       "\n",
       "        svgEl.append(&quot;g&quot;)\n",
       "          .attr(&quot;transform&quot;, `translate(${MARGIN.LEFT}, ${MARGIN.BOTTOM})`)\n",
       "          .call(yAxis)\n",
       "          .call(g =&gt; g.select(&quot;.domain&quot;).remove())\n",
       "          .call(g =&gt; g.selectAll(&quot;.tick line&quot;)\n",
       "              .attr(&quot;x2&quot;, CHART_WIDTH)\n",
       "              .attr(&quot;stroke-opacity&quot;, 0.1))\n",
       "          .call(g =&gt; g.append(&quot;text&quot;)\n",
       "              .attr(&quot;x&quot;, -MARGIN.LEFT)\n",
       "              .attr(&quot;y&quot;, 10)\n",
       "              .attr(&quot;fill&quot;, &quot;currentColor&quot;)\n",
       "              .attr(&quot;text-anchor&quot;, &quot;start&quot;))\n",
       "\n",
       "        svgEl.append(&quot;line&quot;)\n",
       "          .attr(&quot;transform&quot;, `translate(${MARGIN.LEFT}, ${MARGIN.BOTTOM})`)\n",
       "          .data(lineData)\n",
       "          .attr(&quot;x1&quot;, (d) =&gt; xScale(d.axisX))\n",
       "          .attr(&quot;y1&quot;, MARGIN.TOP + MARGIN.TOP)\n",
       "          .attr(&quot;x2&quot;, (d) =&gt; xScale(d.axisX))\n",
       "          .attr(&quot;y2&quot;, CHART_HEIGHT + MARGIN.TOP)\n",
       "          .style(&quot;stroke-width&quot;, 2)\n",
       "          .style(&quot;stroke&quot;, &quot;#44C0E7&quot;)\n",
       "          .style(&quot;stroke-dasharray&quot;, (3,3))\n",
       "          .style(&quot;fill&quot;, &quot;none&quot;);\n",
       "\n",
       "        svgEl.append(&quot;text&quot;)\n",
       "          .attr(&quot;transform&quot;, &quot;rotate(-90)&quot;)\n",
       "          .data(lineData)\n",
       "          .attr(&quot;y&quot;, (d) =&gt; xScale(d.axisX) + MARGIN.LEFT)\n",
       "          .attr(&quot;x&quot;, 0 - (SVG_HEIGHT / 2))\n",
       "          .attr(&quot;dy&quot;, &quot;1em&quot;)\n",
       "          .style(&quot;text-anchor&quot;, &quot;middle&quot;)\n",
       "          .text(&quot;single value&quot;)\n",
       "          .style(&quot;font-size&quot;, &quot;15&quot;)\n",
       "          .style(&quot;opacity&quot;, &quot;0.6&quot;)\n",
       "\n",
       "        svgEl.append(&quot;text&quot;)\n",
       "          .attr(&quot;transform&quot;,\n",
       "                &quot;translate(&quot; + (CHART_WIDTH/2) + &quot; ,&quot; +\n",
       "                               (CHART_HEIGHT + MARGIN.TOP + 75) + &quot;)&quot;)\n",
       "          .style(&quot;text-anchor&quot;, &quot;middle&quot;)\n",
       "          .text(&quot;Values&quot;)\n",
       "          .style(&quot;font-size&quot;, &quot;15&quot;)\n",
       "          .style(&quot;opacity&quot;, &quot;0.6&quot;)\n",
       "\n",
       "        svgEl.append(&quot;text&quot;)\n",
       "          .attr(&quot;transform&quot;, &quot;rotate(-90)&quot;)\n",
       "          .attr(&quot;y&quot;, 0)\n",
       "          .attr(&quot;x&quot;, 0 - (SVG_HEIGHT / 2))\n",
       "          .attr(&quot;dy&quot;, &quot;1em&quot;)\n",
       "          .style(&quot;text-anchor&quot;, &quot;middle&quot;)\n",
       "          .text(&quot;Counts&quot;)\n",
       "          .style(&quot;font-size&quot;, &quot;15&quot;)\n",
       "          .style(&quot;opacity&quot;, &quot;0.6&quot;)\n",
       "\n",
       "          const gChart = svgEl.append(&quot;g&quot;);\n",
       "          gChart\n",
       "          .attr(&quot;transform&quot;, &quot;translate(&quot;+ MARGIN.LEFT +&quot;,0)&quot;)\n",
       "          .selectAll(&quot;.bar&quot;)\n",
       "          .data(histogramData)\n",
       "          .enter()\n",
       "          .append(&quot;rect&quot;)\n",
       "          .style(&quot;stroke&quot;, &quot;#021826&quot;)\n",
       "          .classed(&quot;bar&quot;, true)\n",
       "          .attr(&quot;width&quot;, function(d) { return xScale(histogramData[1]?.axisX)-xScale(histogramData[0]?.axisX); })\n",
       "          .attr(&quot;height&quot;, (d) =&gt; CHART_HEIGHT - yScale(d.axisY))\n",
       "          .attr(&quot;x&quot;, 1)\n",
       "          .attr(&quot;transform&quot;, function(d) { return &quot;translate(&quot; + xScale(d.axisX) + &quot;,&quot; + 0  +  &quot;)&quot;; })\n",
       "          .attr(&quot;y&quot;, (d) =&gt; yScale(d.axisY) + MARGIN.TOP + MARGIN.BOTTOM)\n",
       "          .attr(&quot;fill&quot;, rectColors[0])\n",
       "          .style(&quot;opacity&quot;,&quot;0.6&quot;)\n",
       "\n",
       "          const gChart1 = svgEl.append(&quot;g&quot;);\n",
       "          gChart1\n",
       "          .attr(&quot;transform&quot;, &quot;translate(&quot;+ MARGIN.LEFT +&quot;,0)&quot;)\n",
       "          .selectAll(&quot;.bar&quot;)\n",
       "          .data(overlappedHistogramData)\n",
       "          .enter()\n",
       "          .append(&quot;rect&quot;)\n",
       "          .style(&quot;stroke&quot;, &quot;#021826&quot;)\n",
       "          .classed(&quot;bar&quot;, true)\n",
       "          .attr(&quot;width&quot;, function(d) { return xScale(overlappedHistogramData[1]?.axisX)-xScale(overlappedHistogramData[0]?.axisX); })\n",
       "          .attr(&quot;height&quot;, (d) =&gt; CHART_HEIGHT - yScale(d.axisY))\n",
       "          .attr(&quot;x&quot;, 1)\n",
       "          .attr(&quot;transform&quot;, function(d) { return &quot;translate(&quot; + xScale(d.axisX) + &quot;,&quot; + 0  +  &quot;)&quot;; })\n",
       "          .attr(&quot;y&quot;, (d) =&gt; yScale(d.axisY) + MARGIN.TOP + MARGIN.BOTTOM)\n",
       "          .attr(&quot;fill&quot;, rectColors[1])\n",
       "          .style(&quot;opacity&quot;,&quot;0.6&quot;)\n",
       "\n",
       "        return svgEl._groups[0][0].outerHTML;\n",
       "      }\n",
       "\n",
       "      const profileFromCSVfile = {&quot;response.bert_score_to_prompt&quot;: {&quot;histogram&quot;: {&quot;start&quot;: 0.6212345361709595, &quot;end&quot;: 0.8124869086221874, &quot;width&quot;: 0, &quot;counts&quot;: [0, 0, 0], &quot;max&quot;: 0.8124868273735046, &quot;min&quot;: 0.6212345361709595, &quot;bins&quot;: [0.6212345361709595, 0.6849853269880355, 0.7487361178051114, 0.8124869086221874], &quot;n&quot;: 10}}}\n",
       "\n",
       "      Handlebars.registerHelper(&quot;getDoubleHistogramChart&quot;,(column,key) =&gt; {\n",
       "          const columnKey = key.data.key\n",
       "        try {\n",
       "          if (profileFromCSVfile) {\n",
       "          return  generateDoubleHistogramChart (\n",
       "              column,\n",
       "              profileFromCSVfile[columnKey]\n",
       "            )\n",
       "          }\n",
       "        } catch (err) {\n",
       "          $(document).ready(() =&gt;\n",
       "            $(&quot;.desktop-content&quot;).html(`\n",
       "              &lt;p style=&quot;height: ${$(window).height()}px&quot; class=&quot;error-message&quot;&gt;\n",
       "                Something went wrong. Please try again.\n",
       "              &lt;/p&gt;\n",
       "            `)\n",
       "          )\n",
       "        }\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function initWebsiteScripts() {\n",
       "      $(&quot;.svg-container&quot;).css(&quot;height&quot;, $(window).height() - 32)\n",
       "    }\n",
       "\n",
       "    function initHandlebarsTemplate() {\n",
       "      // Replace this context with JSON from .py file\n",
       "      const context = {&quot;response.bert_score_to_prompt&quot;: {&quot;histogram&quot;: {&quot;start&quot;: 0.6212345361709595, &quot;end&quot;: 0.8124869086221874, &quot;width&quot;: 0, &quot;counts&quot;: [1, 3, 6], &quot;max&quot;: 0.8124868273735046, &quot;min&quot;: 0.6212345361709595, &quot;bins&quot;: [0.6212345361709595, 0.6849853269880355, 0.7487361178051114, 0.8124869086221874], &quot;n&quot;: 10}}};\n",
       "      // Config handlebars and pass data to HBS template\n",
       "      const source = document.getElementById(&quot;entry-template&quot;).innerHTML;\n",
       "      const template = Handlebars.compile(source);\n",
       "      const html = template(context);\n",
       "      const target = document.getElementById(&quot;generated-html&quot;);\n",
       "      target.innerHTML = html;\n",
       "    }\n",
       "\n",
       "    // Invoke functions -- keep in mind invokation order\n",
       "    registerHandlebarHelperFunctions();\n",
       "    initHandlebarsTemplate();\n",
       "    initWebsiteScripts();\n",
       "  &lt;/script&gt;\n",
       "&lt;/html&gt;\n",
       "\" width=100% height=300px\n",
       "        frameBorder=0></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visualize_langkit_metric(\n",
    "    df, \n",
    "    \"response.bert_score_to_prompt\", \n",
    "    numeric=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9946aa",
   "metadata": {},
   "source": [
    "### Sentence embedding cosine distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9032242b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.util import pairwise_cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "21145da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "41c782c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@register_dataset_udf([\"response\", \"ground_truth\"], \n",
    "                      \"response.sentence_embedding_selfsimilarity\")\n",
    "def sentence_embedding_selfsimilarity(text):\n",
    "  response_embeddings = model.encode(text[\"response\"].to_numpy())\n",
    "  ground_truth_embeddings = model.encode(text[\"ground_truth\"].to_numpy())\n",
    "  \n",
    "  cos_sim_with_response = pairwise_cos_sim(\n",
    "    response_embeddings, ground_truth_embeddings\n",
    "    )\n",
    "  \n",
    "  return cos_sim_with_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c062e7b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8573, 0.8290, 0.4429, 0.6641, 0.8756, 0.8891, 0.9190, 0.8638, 0.7994,\n",
       "        0.9078])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_embedding_selfsimilarity(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "48ec57cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div></div><iframe srcdoc=\"&lt;!DOCTYPE html&gt;\n",
       "&lt;html lang=&quot;en&quot;&gt;\n",
       "  &lt;head&gt;\n",
       "    &lt;meta charset=&quot;UTF-8&quot; /&gt;\n",
       "    &lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;IE=edge&quot; /&gt;\n",
       "    &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot; /&gt;\n",
       "    &lt;meta name=&quot;description&quot; content=&quot;&quot; /&gt;\n",
       "    &lt;meta name=&quot;author&quot; content=&quot;&quot; /&gt;\n",
       "\n",
       "    &lt;title&gt;Profile Visualizer | whylogs&lt;/title&gt;\n",
       "\n",
       "    &lt;link rel=&quot;icon&quot; href=&quot;images/whylabs-favicon.png&quot; type=&quot;image/png&quot; sizes=&quot;16x16&quot; /&gt;\n",
       "    &lt;link rel=&quot;preconnect&quot; href=&quot;https://fonts.googleapis.com&quot; /&gt;\n",
       "    &lt;link rel=&quot;preconnect&quot; href=&quot;https://fonts.gstatic.com&quot; crossorigin /&gt;\n",
       "    &lt;link href=&quot;https://fonts.googleapis.com/css2?family=Asap:wght@400;500;600;700&amp;display=swap&quot; rel=&quot;stylesheet&quot; /&gt;\n",
       "    &lt;link rel=&quot;preconnect&quot; href=&quot;https://fonts.gstatic.com&quot; /&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.1.0/dist/css/bootstrap.min.css&quot; /&gt;\n",
       "\n",
       "    &lt;script\n",
       "      src=&quot;https://cdnjs.cloudflare.com/ajax/libs/handlebars.js/4.7.7/handlebars.min.js&quot;\n",
       "      integrity=&quot;sha512-RNLkV3d+aLtfcpEyFG8jRbnWHxUqVZozacROI4J2F1sTaDqo1dPQYs01OMi1t1w9Y2FdbSCDSQ2ZVdAC8bzgAg==&quot;\n",
       "      crossorigin=&quot;anonymous&quot;\n",
       "      referrerpolicy=&quot;no-referrer&quot;\n",
       "    &gt;&lt;/script&gt;\n",
       "\n",
       "    &lt;style type=&quot;text/css&quot;&gt;\n",
       "\n",
       "      :root {\n",
       "        /** Branded colors */\n",
       "        --brandSecondary900: #4f595b;\n",
       "        --secondaryLight1000: #313b3d;\n",
       "        /** Purpose colors */\n",
       "        --tealBackground: #eaf2f3;\n",
       "      }\n",
       "\n",
       "      /* RESET STYLE */\n",
       "      *,\n",
       "      *::after,\n",
       "      *::before {\n",
       "        margin: 0;\n",
       "        padding: 0;\n",
       "        box-sizing: border-box;\n",
       "        overflow-y: hidden;\n",
       "      }\n",
       "\n",
       "      /* Screen on smaller screens */\n",
       "      .no-responsive {\n",
       "        display: none;\n",
       "        position: fixed;\n",
       "        top: 0;\n",
       "        left: 0;\n",
       "        z-index: 1031;\n",
       "        width: 100vw;\n",
       "        height: 100vh;\n",
       "        background-color: var(--tealBackground);\n",
       "        display: flex;\n",
       "        align-items: center;\n",
       "        justify-content: center;\n",
       "      }\n",
       "\n",
       "      .desktop-content {\n",
       "        display: flex;\n",
       "        flex-direction: column;\n",
       "      }\n",
       "\n",
       "      .no-responsive__content {\n",
       "        max-width: 600px;\n",
       "        width: 100%;\n",
       "        padding: 0 24px;\n",
       "      }\n",
       "\n",
       "      .no-responsive__title {\n",
       "        font-size: 96px;\n",
       "        font-weight: 300;\n",
       "        color: var(--brandSecondary900);\n",
       "        line-height: 1.167;\n",
       "      }\n",
       "\n",
       "      .no-responsive__text {\n",
       "        margin: 0;\n",
       "        font-size: 16px;\n",
       "        font-weight: 400;\n",
       "        color: var(--brandSecondary900);\n",
       "        line-height: 1.5;\n",
       "      }\n",
       "\n",
       "      .svg-container {\n",
       "        display: inline-block;\n",
       "        position: relative;\n",
       "        width: 100%;\n",
       "        vertical-align: top;\n",
       "        overflow: hidden;\n",
       "      }\n",
       "\n",
       "      .svg-content-responsive {\n",
       "        display: inline-block;\n",
       "        position: absolute;\n",
       "        left: 0;\n",
       "      }\n",
       "\n",
       "      .circle-color {\n",
       "       display: inline-block;\n",
       "       padding: 5px;\n",
       "       border-radius: 50px;\n",
       "     }\n",
       "\n",
       "     .colors-for-distingushing-charts {\n",
       "       padding-right: 10px;\n",
       "     }\n",
       "\n",
       "     .display-flex{\n",
       "       display: flex;\n",
       "     }\n",
       "\n",
       "     .align-items-flex-end {\n",
       "       align-items: flex-end;\n",
       "     }\n",
       "\n",
       "     .chart-box-title {\n",
       "       width: 88%;\n",
       "       justify-content: space-between;\n",
       "       margin: 10px;\n",
       "       margin-top: 15px;\n",
       "       bottom: 0;\n",
       "     }\n",
       "\n",
       "     .chart-box-title p{\n",
       "       margin-bottom: 0;\n",
       "       font-family: Asap;\n",
       "       font-weight: bold;\n",
       "       font-size: 18px;\n",
       "       line-height: 16px;\n",
       "       color: #4F595B;\n",
       "     }\n",
       "\n",
       "    .bar {\n",
       "      font: 10px sans-serif;\n",
       "    }\n",
       "\n",
       "    .bar path,\n",
       "    .bar line {\n",
       "      fill: none;\n",
       "      stroke: #000;\n",
       "      shape-rendering: crispEdges;\n",
       "    }\n",
       "\n",
       "    .error-message {\n",
       "      display: flex;\n",
       "      justify-content: center;\n",
       "      align-items: center;\n",
       "      color: rgb(255, 114, 71);\n",
       "      font-size: 30px;\n",
       "      font-weight: 900;\n",
       "    }\n",
       "\n",
       "     @media screen and (min-width: 500px) {\n",
       "       .desktop-content {\n",
       "         display: block;\n",
       "       }\n",
       "       .no-responsive {\n",
       "         display: none;\n",
       "       }\n",
       "     }\n",
       "    &lt;/style&gt;\n",
       "  &lt;/head&gt;\n",
       "\n",
       "  &lt;body id=&quot;generated-html&quot;&gt;&lt;/body&gt;\n",
       "  &lt;script id=&quot;entry-template&quot; type=&quot;text/x-handlebars-template&quot;&gt;\n",
       "    \n",
       "      &lt;div class=&quot;desktop-content&quot;&gt;\n",
       "{{#each this}}              &lt;div class=&quot;chart-box&quot; id=&quot;chart-box&quot;&gt;\n",
       "                &lt;div class=&quot;chart-box-title display-flex&quot;&gt;\n",
       "                  &lt;p&gt;{{@key}}&lt;/p&gt;\n",
       "                  &lt;div class=&quot;display-flex&quot;&gt;\n",
       "                    &lt;div class=&quot;colors-for-distingushing-charts&quot;&gt;\n",
       "                      &lt;div class=&quot;circle-color&quot; style=&quot;background: #44C0E7;&quot;&gt;&lt;/div&gt;\n",
       "                      &lt;text alignment-baseline=&quot;middle&quot; style=&quot;font-size: 15px;&quot;&gt;Target&lt;/text&gt;\n",
       "                    &lt;/div&gt;\n",
       "                    &lt;div class=&quot;colors-for-distingushing-charts&quot;&gt;\n",
       "                      &lt;div class=&quot;circle-color&quot; style=&quot;background: #F5843C&quot;&gt;&lt;/div&gt;\n",
       "                      &lt;text alignment-baseline=&quot;middle&quot; style=&quot;font-size: 15px;&quot;&gt;Reference&lt;/text&gt;\n",
       "                    &lt;/div&gt;\n",
       "                  &lt;/div&gt;&lt;/div&gt;\n",
       "                &lt;div class=&quot;svg-container&quot;&gt;{{{getDoubleHistogramChart this}}}&lt;/div&gt;\n",
       "              &lt;/div&gt;\n",
       "{{/each}}      &lt;/div&gt;\n",
       "      &lt;div class=&quot;no-responsive&quot;&gt;\n",
       "        &lt;div class=&quot;no-responsive__content&quot;&gt;\n",
       "          &lt;h1 class=&quot;no-responsive__title&quot;&gt;Hold on! :)&lt;/h1&gt;\n",
       "          &lt;p class=&quot;no-responsive__text&quot;&gt;\n",
       "            It looks like your current screen size or device is not yet supported by the WhyLabs Sandbox. The Sandbox is\n",
       "            best experienced on a desktop computer. Please try maximizing this window or switching to another device. We\n",
       "            are working on adding support for a larger variety of devices.\n",
       "          &lt;/p&gt;\n",
       "        &lt;/div&gt;\n",
       "      &lt;/div&gt;\n",
       "    \n",
       "  &lt;/script&gt;\n",
       "\n",
       "  &lt;script src=&quot;https://code.jquery.com/jquery-3.6.0.min.js&quot; integrity=&quot;sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=&quot; crossorigin=&quot;anonymous&quot;&gt;&lt;/script&gt;\n",
       "\n",
       "  &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/d3/6.7.0/d3.min.js&quot; integrity=&quot;sha512-cd6CHE+XWDQ33ElJqsi0MdNte3S+bQY819f7p3NUHgwQQLXSKjE4cPZTeGNI+vaxZynk1wVU3hoHmow3m089wA==&quot; crossorigin=&quot;anonymous&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/script&gt;\n",
       "\n",
       "  &lt;script&gt;\n",
       "    function registerHandlebarHelperFunctions() {\n",
       "      //helper fun\n",
       "\n",
       "      class GenerateChartParams {\n",
       "        constructor(height, width, targetData, referenceData, bottomMargin=30, topMargin=5) {\n",
       "          this.MARGIN = {\n",
       "            TOP: topMargin,\n",
       "            RIGHT: 5,\n",
       "            BOTTOM: bottomMargin,\n",
       "            LEFT: 55,\n",
       "          };\n",
       "          this.SVG_WIDTH = width;\n",
       "          this.SVG_HEIGHT = height;\n",
       "          this.CHART_WIDTH = this.SVG_WIDTH - this.MARGIN.LEFT - this.MARGIN.RIGHT;\n",
       "          this.CHART_HEIGHT = this.SVG_HEIGHT - this.MARGIN.TOP - this.MARGIN.BOTTOM;\n",
       "          this.svgEl = d3.create(&quot;svg&quot;)\n",
       "             .attr(&quot;preserveAspectRatio&quot;, &quot;xMinYMin meet&quot;)\n",
       "             .attr(&quot;viewBox&quot;, `0 0 ${$(window).width()+100} ${$(window).height()-30}`)\n",
       "             .classed(&quot;svg-content-responsive&quot;, true)\n",
       "          this.maxYValue = d3.max(targetData, (d) =&gt; Math.abs(d.axisY));\n",
       "          this.minYValue = d3.min(targetData, (d) =&gt; Math.abs(d.axisY));\n",
       "          const mergedReferenceData = referenceData.map(({axisX, axisY}) =&gt; {\n",
       "            return {axisX, axisY}\n",
       "          })\n",
       "          const mergedTargetedData = targetData.map(({axisX, axisY}) =&gt; {\n",
       "            return {axisX, axisY}\n",
       "          })\n",
       "\n",
       "          this.charts2 = mergedReferenceData.concat(mergedTargetedData)\n",
       "          this.charts2 = this.charts2.sort(function(a, b) { return a - b; });\n",
       "\n",
       "          this.targetBinWidth = targetData[1]?.axisX - targetData[0]?.axisX\n",
       "          this.referenceBinWidth = referenceData[1]?.axisX - referenceData[0]?.axisX\n",
       "          this.maxTargetXValue = d3.max(targetData, (d) =&gt; d.axisX);\n",
       "\n",
       "          this.maxReferenceXValue = d3.max(referenceData, (d) =&gt; d.axisX);\n",
       "\n",
       "          this.xScale = d3\n",
       "              .scaleLinear()\n",
       "         .domain([d3.min(this.charts2, function(d) { return parseFloat(d.axisX); }),(this.maxTargetXValue+this.targetBinWidth &gt;= this.maxReferenceXValue+this.referenceBinWidth) ? this.maxTargetXValue+this.targetBinWidth:this.maxReferenceXValue+this.referenceBinWidth])\n",
       "         .range([0, this.CHART_WIDTH ]);\n",
       "\n",
       "         this.svgEl.append(&quot;g&quot;)\n",
       "             .attr(&quot;transform&quot;, &quot;translate(&quot;+ this.MARGIN.LEFT +&quot;,&quot; + this.SVG_HEIGHT + &quot;)&quot;)\n",
       "             .call(d3.axisBottom(this.xScale));\n",
       "          this.yScale = d3.scaleLinear()\n",
       "              .range([this.CHART_HEIGHT , 0])\n",
       "              .domain([d3.min(this.charts2, function(d) { return parseFloat(d.axisY); }), d3.max(this.charts2, function(d) { return parseFloat(d.axisY); })*1.2])\n",
       "              .nice();\n",
       "        }\n",
       "      }\n",
       "\n",
       "      function chartData(column) {\n",
       "        const data = [];\n",
       "        if (column?.histogram) {\n",
       "          for (let i = 0; i&lt;column.histogram.bins.length; i++) {\n",
       "            data.push({\n",
       "              axisY: column.histogram.counts[i] || 0,\n",
       "              axisX: column.histogram.bins[i] || 0,\n",
       "            });\n",
       "          }\n",
       "        } else {\n",
       "            $(document).ready(() =&gt;\n",
       "              $(&quot;.desktop-content&quot;).html(`\n",
       "                &lt;p style=&quot;height: ${$(window).height()}px&quot; class=&quot;error-message&quot;&gt;\n",
       "                  Something went wrong. Please try again.\n",
       "                &lt;/p&gt;\n",
       "              `)\n",
       "            )\n",
       "          }\n",
       "\n",
       "        return data\n",
       "      }\n",
       "\n",
       "      function verticalLine(column) {\n",
       "        const line_data = [];\n",
       "        if (column?.vertical_line) {\n",
       "            line_data.push({\n",
       "              axisX: column?.vertical_line || 0,\n",
       "            });\n",
       "\n",
       "        }\n",
       "\n",
       "        return line_data\n",
       "      }\n",
       "\n",
       "      function generateDoubleHistogramChart(targetData, referenceData) {\n",
       "        let histogramData = [],\n",
       "            overlappedHistogramData = [];\n",
       "        let yFormat;\n",
       "\n",
       "        histogramData = chartData(targetData)\n",
       "        overlappedHistogramData = chartData(referenceData)\n",
       "        lineData = verticalLine(targetData)\n",
       "\n",
       "        const sizes = new GenerateChartParams($(window).height()-80, $(window).width(), histogramData, overlappedHistogramData)\n",
       "        const {\n",
       "          MARGIN,\n",
       "          SVG_WIDTH,\n",
       "          SVG_HEIGHT,\n",
       "          CHART_WIDTH,\n",
       "          CHART_HEIGHT,\n",
       "          svgEl,\n",
       "          maxYValue,\n",
       "          minYValue,\n",
       "          xScale,\n",
       "          yScale\n",
       "        } = sizes\n",
       "\n",
       "        const rectColors = [&quot;#44C0E7&quot;, &quot;#F5843C&quot;]\n",
       "        const yAxis = d3.axisLeft(yScale).ticks(SVG_HEIGHT / 40);\n",
       "\n",
       "        svgEl.append(&quot;g&quot;)\n",
       "          .attr(&quot;transform&quot;, `translate(${MARGIN.LEFT}, ${MARGIN.BOTTOM})`)\n",
       "          .call(yAxis)\n",
       "          .call(g =&gt; g.select(&quot;.domain&quot;).remove())\n",
       "          .call(g =&gt; g.selectAll(&quot;.tick line&quot;)\n",
       "              .attr(&quot;x2&quot;, CHART_WIDTH)\n",
       "              .attr(&quot;stroke-opacity&quot;, 0.1))\n",
       "          .call(g =&gt; g.append(&quot;text&quot;)\n",
       "              .attr(&quot;x&quot;, -MARGIN.LEFT)\n",
       "              .attr(&quot;y&quot;, 10)\n",
       "              .attr(&quot;fill&quot;, &quot;currentColor&quot;)\n",
       "              .attr(&quot;text-anchor&quot;, &quot;start&quot;))\n",
       "\n",
       "        svgEl.append(&quot;line&quot;)\n",
       "          .attr(&quot;transform&quot;, `translate(${MARGIN.LEFT}, ${MARGIN.BOTTOM})`)\n",
       "          .data(lineData)\n",
       "          .attr(&quot;x1&quot;, (d) =&gt; xScale(d.axisX))\n",
       "          .attr(&quot;y1&quot;, MARGIN.TOP + MARGIN.TOP)\n",
       "          .attr(&quot;x2&quot;, (d) =&gt; xScale(d.axisX))\n",
       "          .attr(&quot;y2&quot;, CHART_HEIGHT + MARGIN.TOP)\n",
       "          .style(&quot;stroke-width&quot;, 2)\n",
       "          .style(&quot;stroke&quot;, &quot;#44C0E7&quot;)\n",
       "          .style(&quot;stroke-dasharray&quot;, (3,3))\n",
       "          .style(&quot;fill&quot;, &quot;none&quot;);\n",
       "\n",
       "        svgEl.append(&quot;text&quot;)\n",
       "          .attr(&quot;transform&quot;, &quot;rotate(-90)&quot;)\n",
       "          .data(lineData)\n",
       "          .attr(&quot;y&quot;, (d) =&gt; xScale(d.axisX) + MARGIN.LEFT)\n",
       "          .attr(&quot;x&quot;, 0 - (SVG_HEIGHT / 2))\n",
       "          .attr(&quot;dy&quot;, &quot;1em&quot;)\n",
       "          .style(&quot;text-anchor&quot;, &quot;middle&quot;)\n",
       "          .text(&quot;single value&quot;)\n",
       "          .style(&quot;font-size&quot;, &quot;15&quot;)\n",
       "          .style(&quot;opacity&quot;, &quot;0.6&quot;)\n",
       "\n",
       "        svgEl.append(&quot;text&quot;)\n",
       "          .attr(&quot;transform&quot;,\n",
       "                &quot;translate(&quot; + (CHART_WIDTH/2) + &quot; ,&quot; +\n",
       "                               (CHART_HEIGHT + MARGIN.TOP + 75) + &quot;)&quot;)\n",
       "          .style(&quot;text-anchor&quot;, &quot;middle&quot;)\n",
       "          .text(&quot;Values&quot;)\n",
       "          .style(&quot;font-size&quot;, &quot;15&quot;)\n",
       "          .style(&quot;opacity&quot;, &quot;0.6&quot;)\n",
       "\n",
       "        svgEl.append(&quot;text&quot;)\n",
       "          .attr(&quot;transform&quot;, &quot;rotate(-90)&quot;)\n",
       "          .attr(&quot;y&quot;, 0)\n",
       "          .attr(&quot;x&quot;, 0 - (SVG_HEIGHT / 2))\n",
       "          .attr(&quot;dy&quot;, &quot;1em&quot;)\n",
       "          .style(&quot;text-anchor&quot;, &quot;middle&quot;)\n",
       "          .text(&quot;Counts&quot;)\n",
       "          .style(&quot;font-size&quot;, &quot;15&quot;)\n",
       "          .style(&quot;opacity&quot;, &quot;0.6&quot;)\n",
       "\n",
       "          const gChart = svgEl.append(&quot;g&quot;);\n",
       "          gChart\n",
       "          .attr(&quot;transform&quot;, &quot;translate(&quot;+ MARGIN.LEFT +&quot;,0)&quot;)\n",
       "          .selectAll(&quot;.bar&quot;)\n",
       "          .data(histogramData)\n",
       "          .enter()\n",
       "          .append(&quot;rect&quot;)\n",
       "          .style(&quot;stroke&quot;, &quot;#021826&quot;)\n",
       "          .classed(&quot;bar&quot;, true)\n",
       "          .attr(&quot;width&quot;, function(d) { return xScale(histogramData[1]?.axisX)-xScale(histogramData[0]?.axisX); })\n",
       "          .attr(&quot;height&quot;, (d) =&gt; CHART_HEIGHT - yScale(d.axisY))\n",
       "          .attr(&quot;x&quot;, 1)\n",
       "          .attr(&quot;transform&quot;, function(d) { return &quot;translate(&quot; + xScale(d.axisX) + &quot;,&quot; + 0  +  &quot;)&quot;; })\n",
       "          .attr(&quot;y&quot;, (d) =&gt; yScale(d.axisY) + MARGIN.TOP + MARGIN.BOTTOM)\n",
       "          .attr(&quot;fill&quot;, rectColors[0])\n",
       "          .style(&quot;opacity&quot;,&quot;0.6&quot;)\n",
       "\n",
       "          const gChart1 = svgEl.append(&quot;g&quot;);\n",
       "          gChart1\n",
       "          .attr(&quot;transform&quot;, &quot;translate(&quot;+ MARGIN.LEFT +&quot;,0)&quot;)\n",
       "          .selectAll(&quot;.bar&quot;)\n",
       "          .data(overlappedHistogramData)\n",
       "          .enter()\n",
       "          .append(&quot;rect&quot;)\n",
       "          .style(&quot;stroke&quot;, &quot;#021826&quot;)\n",
       "          .classed(&quot;bar&quot;, true)\n",
       "          .attr(&quot;width&quot;, function(d) { return xScale(overlappedHistogramData[1]?.axisX)-xScale(overlappedHistogramData[0]?.axisX); })\n",
       "          .attr(&quot;height&quot;, (d) =&gt; CHART_HEIGHT - yScale(d.axisY))\n",
       "          .attr(&quot;x&quot;, 1)\n",
       "          .attr(&quot;transform&quot;, function(d) { return &quot;translate(&quot; + xScale(d.axisX) + &quot;,&quot; + 0  +  &quot;)&quot;; })\n",
       "          .attr(&quot;y&quot;, (d) =&gt; yScale(d.axisY) + MARGIN.TOP + MARGIN.BOTTOM)\n",
       "          .attr(&quot;fill&quot;, rectColors[1])\n",
       "          .style(&quot;opacity&quot;,&quot;0.6&quot;)\n",
       "\n",
       "        return svgEl._groups[0][0].outerHTML;\n",
       "      }\n",
       "\n",
       "      const profileFromCSVfile = {&quot;response.sentence_embedding_selfsimilarity&quot;: {&quot;histogram&quot;: {&quot;start&quot;: 0.44289880990982056, &quot;end&quot;: 0.9190082276964069, &quot;width&quot;: 0, &quot;counts&quot;: [0, 0, 0], &quot;max&quot;: 0.9190081357955933, &quot;min&quot;: 0.44289880990982056, &quot;bins&quot;: [0.44289880990982056, 0.601601949172016, 0.7603050884342115, 0.9190082276964069], &quot;n&quot;: 10}}}\n",
       "\n",
       "      Handlebars.registerHelper(&quot;getDoubleHistogramChart&quot;,(column,key) =&gt; {\n",
       "          const columnKey = key.data.key\n",
       "        try {\n",
       "          if (profileFromCSVfile) {\n",
       "          return  generateDoubleHistogramChart (\n",
       "              column,\n",
       "              profileFromCSVfile[columnKey]\n",
       "            )\n",
       "          }\n",
       "        } catch (err) {\n",
       "          $(document).ready(() =&gt;\n",
       "            $(&quot;.desktop-content&quot;).html(`\n",
       "              &lt;p style=&quot;height: ${$(window).height()}px&quot; class=&quot;error-message&quot;&gt;\n",
       "                Something went wrong. Please try again.\n",
       "              &lt;/p&gt;\n",
       "            `)\n",
       "          )\n",
       "        }\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function initWebsiteScripts() {\n",
       "      $(&quot;.svg-container&quot;).css(&quot;height&quot;, $(window).height() - 32)\n",
       "    }\n",
       "\n",
       "    function initHandlebarsTemplate() {\n",
       "      // Replace this context with JSON from .py file\n",
       "      const context = {&quot;response.sentence_embedding_selfsimilarity&quot;: {&quot;histogram&quot;: {&quot;start&quot;: 0.44289880990982056, &quot;end&quot;: 0.9190082276964069, &quot;width&quot;: 0, &quot;counts&quot;: [1, 1, 8], &quot;max&quot;: 0.9190081357955933, &quot;min&quot;: 0.44289880990982056, &quot;bins&quot;: [0.44289880990982056, 0.601601949172016, 0.7603050884342115, 0.9190082276964069], &quot;n&quot;: 10}}};\n",
       "      // Config handlebars and pass data to HBS template\n",
       "      const source = document.getElementById(&quot;entry-template&quot;).innerHTML;\n",
       "      const template = Handlebars.compile(source);\n",
       "      const html = template(context);\n",
       "      const target = document.getElementById(&quot;generated-html&quot;);\n",
       "      target.innerHTML = html;\n",
       "    }\n",
       "\n",
       "    // Invoke functions -- keep in mind invokation order\n",
       "    registerHandlebarHelperFunctions();\n",
       "    initHandlebarsTemplate();\n",
       "    initWebsiteScripts();\n",
       "  &lt;/script&gt;\n",
       "&lt;/html&gt;\n",
       "\" width=100% height=300px\n",
       "        frameBorder=0></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visualize_langkit_metric(\n",
    "    df, \n",
    "    \"response.sentence_embedding_selfsimilarity\", \n",
    "    numeric=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6f33a798",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_df, _ = udf_schema().apply_udfs(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "839d4138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "      <th>article_url</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>prompt.sentiment_nltk</th>\n",
       "      <th>response.sentiment_nltk</th>\n",
       "      <th>prompt.flesch_reading_ease</th>\n",
       "      <th>response.flesch_reading_ease</th>\n",
       "      <th>prompt.automated_readability_index</th>\n",
       "      <th>response.automated_readability_index</th>\n",
       "      <th>...</th>\n",
       "      <th>prompt.jailbreak_similarity</th>\n",
       "      <th>response.refusal_similarity</th>\n",
       "      <th>prompt.toxicity</th>\n",
       "      <th>response.toxicity</th>\n",
       "      <th>response.relevance_to_prompt</th>\n",
       "      <th>prompt.has_patterns</th>\n",
       "      <th>response.has_patterns</th>\n",
       "      <th>response.bleu_score_to_prompt</th>\n",
       "      <th>response.bert_score_to_prompt</th>\n",
       "      <th>response.sentence_embedding_selfsimilarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What can you tell me about a new Deepseek model?</td>\n",
       "      <td>DeepSeek released DeepSeek-R1, a large languag...</td>\n",
       "      <td>https://www.deeplearning.ai/the-batch/issue-285/</td>\n",
       "      <td>DeepSeek released DeepSeek-R1, a mixture-of-ex...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8807</td>\n",
       "      <td>86.71</td>\n",
       "      <td>59.53</td>\n",
       "      <td>1.9</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.172156</td>\n",
       "      <td>0.085639</td>\n",
       "      <td>0.001265</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>0.561104</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.621235</td>\n",
       "      <td>0.857284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Is Sony Music Group working with Generative AI?</td>\n",
       "      <td>Yes, Sony Music Group is working with AI and h...</td>\n",
       "      <td>https://www.deeplearning.ai/the-batch/sony-mus...</td>\n",
       "      <td>Sony Music Group has prohibited the use of its...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.0258</td>\n",
       "      <td>46.44</td>\n",
       "      <td>40.18</td>\n",
       "      <td>6.1</td>\n",
       "      <td>13.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.243147</td>\n",
       "      <td>0.260159</td>\n",
       "      <td>0.000827</td>\n",
       "      <td>0.000776</td>\n",
       "      <td>0.746343</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.003369</td>\n",
       "      <td>0.775768</td>\n",
       "      <td>0.829011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Which AI companies are working with U.S. gover...</td>\n",
       "      <td>Meta and Anthropic are working with the U.S. g...</td>\n",
       "      <td>https://www.deeplearning.ai/the-batch/meta-and...</td>\n",
       "      <td>Meta and Anthropic</td>\n",
       "      <td>0.4767</td>\n",
       "      <td>0.8689</td>\n",
       "      <td>22.58</td>\n",
       "      <td>25.66</td>\n",
       "      <td>11.5</td>\n",
       "      <td>13.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.324931</td>\n",
       "      <td>0.297555</td>\n",
       "      <td>0.000861</td>\n",
       "      <td>0.000866</td>\n",
       "      <td>0.556109</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.016441</td>\n",
       "      <td>0.803309</td>\n",
       "      <td>0.442899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what are the models used in biochemistry?</td>\n",
       "      <td>AlphaFold 3 is a model that predicts the struc...</td>\n",
       "      <td>https://www.deeplearning.ai/the-batch/deepmind...</td>\n",
       "      <td>AlphaFold 3</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4019</td>\n",
       "      <td>64.37</td>\n",
       "      <td>17.34</td>\n",
       "      <td>5.6</td>\n",
       "      <td>17.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.185594</td>\n",
       "      <td>0.027965</td>\n",
       "      <td>0.000863</td>\n",
       "      <td>0.000761</td>\n",
       "      <td>0.449150</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.740436</td>\n",
       "      <td>0.664142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Are neural networks assisting brain surgeons, ...</td>\n",
       "      <td>Yes, the article indicates that neural network...</td>\n",
       "      <td>https://www.deeplearning.ai/the-batch/research...</td>\n",
       "      <td>The article describes a deep learning-based te...</td>\n",
       "      <td>0.4019</td>\n",
       "      <td>-0.5346</td>\n",
       "      <td>74.19</td>\n",
       "      <td>43.73</td>\n",
       "      <td>9.4</td>\n",
       "      <td>12.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.174729</td>\n",
       "      <td>0.100100</td>\n",
       "      <td>0.001265</td>\n",
       "      <td>0.000767</td>\n",
       "      <td>0.724774</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.001934</td>\n",
       "      <td>0.768410</td>\n",
       "      <td>0.875606</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0   What can you tell me about a new Deepseek model?   \n",
       "1    Is Sony Music Group working with Generative AI?   \n",
       "2  Which AI companies are working with U.S. gover...   \n",
       "3          what are the models used in biochemistry?   \n",
       "4  Are neural networks assisting brain surgeons, ...   \n",
       "\n",
       "                                            response  \\\n",
       "0  DeepSeek released DeepSeek-R1, a large languag...   \n",
       "1  Yes, Sony Music Group is working with AI and h...   \n",
       "2  Meta and Anthropic are working with the U.S. g...   \n",
       "3  AlphaFold 3 is a model that predicts the struc...   \n",
       "4  Yes, the article indicates that neural network...   \n",
       "\n",
       "                                         article_url  \\\n",
       "0   https://www.deeplearning.ai/the-batch/issue-285/   \n",
       "1  https://www.deeplearning.ai/the-batch/sony-mus...   \n",
       "2  https://www.deeplearning.ai/the-batch/meta-and...   \n",
       "3  https://www.deeplearning.ai/the-batch/deepmind...   \n",
       "4  https://www.deeplearning.ai/the-batch/research...   \n",
       "\n",
       "                                        ground_truth  prompt.sentiment_nltk  \\\n",
       "0  DeepSeek released DeepSeek-R1, a mixture-of-ex...                 0.0000   \n",
       "1  Sony Music Group has prohibited the use of its...                 0.0000   \n",
       "2                                Meta and Anthropic                  0.4767   \n",
       "3                                        AlphaFold 3                 0.0000   \n",
       "4  The article describes a deep learning-based te...                 0.4019   \n",
       "\n",
       "   response.sentiment_nltk  prompt.flesch_reading_ease  \\\n",
       "0                   0.8807                       86.71   \n",
       "1                  -0.0258                       46.44   \n",
       "2                   0.8689                       22.58   \n",
       "3                   0.4019                       64.37   \n",
       "4                  -0.5346                       74.19   \n",
       "\n",
       "   response.flesch_reading_ease  prompt.automated_readability_index  \\\n",
       "0                         59.53                                 1.9   \n",
       "1                         40.18                                 6.1   \n",
       "2                         25.66                                11.5   \n",
       "3                         17.34                                 5.6   \n",
       "4                         43.73                                 9.4   \n",
       "\n",
       "   response.automated_readability_index  ...  prompt.jailbreak_similarity  \\\n",
       "0                                  15.0  ...                     0.172156   \n",
       "1                                  13.2  ...                     0.243147   \n",
       "2                                  13.9  ...                     0.324931   \n",
       "3                                  17.1  ...                     0.185594   \n",
       "4                                  12.9  ...                     0.174729   \n",
       "\n",
       "   response.refusal_similarity  prompt.toxicity  response.toxicity  \\\n",
       "0                     0.085639         0.001265           0.000750   \n",
       "1                     0.260159         0.000827           0.000776   \n",
       "2                     0.297555         0.000861           0.000866   \n",
       "3                     0.027965         0.000863           0.000761   \n",
       "4                     0.100100         0.001265           0.000767   \n",
       "\n",
       "   response.relevance_to_prompt  prompt.has_patterns  response.has_patterns  \\\n",
       "0                      0.561104                 None                   None   \n",
       "1                      0.746343                 None                   None   \n",
       "2                      0.556109                 None                   None   \n",
       "3                      0.449150                 None                   None   \n",
       "4                      0.724774                 None                   None   \n",
       "\n",
       "   response.bleu_score_to_prompt  response.bert_score_to_prompt  \\\n",
       "0                       0.000000                       0.621235   \n",
       "1                       0.003369                       0.775768   \n",
       "2                       0.016441                       0.803309   \n",
       "3                       0.000000                       0.740436   \n",
       "4                       0.001934                       0.768410   \n",
       "\n",
       "   response.sentence_embedding_selfsimilarity  \n",
       "0                                    0.857284  \n",
       "1                                    0.829011  \n",
       "2                                    0.442899  \n",
       "3                                    0.664142  \n",
       "4                                    0.875606  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotated_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52060db4",
   "metadata": {},
   "source": [
    "# Evaluation using LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "156b5fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "GEMINI_MODEL = \"gemini-2.0-flash-lite-preview-02-05\"\n",
    "\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "Human: You are an AI assistant. You can find answers to the questions from the articles provided.\n",
    "\"\"\"\n",
    "\n",
    "gemini_model = genai.GenerativeModel(GEMINI_MODEL, system_instruction=SYSTEM_PROMPT)\n",
    "\n",
    "\n",
    "def prompt_single_llm_selfsimilarity(dataset, index):\n",
    "    USER_PROMPT = f\"\"\"You will be provided with a text passage \\\n",
    "and your task is to rate the consistency of that text to \\\n",
    "that of the provided ground truth. Your answer must be only \\\n",
    "a number between 0.0 and 1.0 rounded to the nearest one \\\n",
    "decimal place where 0.0 represents no consistency and \\\n",
    "1.0 represents perfect consistency and similarity. \\n\\n \\\n",
    "Text passage: {dataset['response'][index]}. \\n\\n \\\n",
    "Context: {dataset['ground_truth'][index]}.\n",
    "\"\"\"\n",
    "    response = gemini_model.generate_content(USER_PROMPT)\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c96ef9a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt_single_llm_selfsimilarity(df, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbe50fa",
   "metadata": {},
   "source": [
    "# Evaluation with DeepEval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ed0a636e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating 1 test case(s) in parallel: |█|100% (1/1) [Time Taken: 00:04,  4.91s/\n",
      "Evaluating 1 test case(s) in parallel: |█|100% (1/1) [Time Taken: 00:02,  2.64s/\n",
      "Evaluating 1 test case(s) in parallel: |█|100% (1/1) [Time Taken: 00:02,  2.25s/\n",
      "Evaluating 1 test case(s) in parallel: | |  0% (0/1) [Time Taken: 00:02, ?test c\n",
      "Evaluating 1 test case(s) in parallel: | |  0% (0/1) [Time Taken: 00:02, ?test c\n",
      "Evaluating 1 test case(s) in parallel: | |  0% (0/1) [Time Taken: 00:02, ?test c\n",
      "Evaluating 1 test case(s) in parallel: | |  0% (0/1) [Time Taken: 00:02, ?test c\n",
      "Evaluating 1 test case(s) in parallel: | |  0% (0/1) [Time Taken: 00:02, ?test c\n",
      "Evaluating 1 test case(s) in parallel: | |  0% (0/1) [Time Taken: 00:02, ?test c\n",
      "Evaluating 1 test case(s) in parallel: | |  0% (0/1) [Time Taken: 00:02, ?test c\n",
      "\u001b[31mF\u001b[0mRunning teardown with pytest sessionfinish\u001b[33m...\u001b[0m\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m_________________________ test_chat_model[test_case0] __________________________\u001b[0m\n",
      "\n",
      "test_case = LLMTestCase(input='What can you tell me about a new Deepseek model?', actual_output='DeepSeek released DeepSeek-R1, a ...all sizes.\\n'], additional_metadata=None, comments=None, tools_called=[], expected_tools=[], reasoning=None, name=None)\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[90m\u001b[39;49;00m\n",
      "      \u001b[33m\"\u001b[39;49;00m\u001b[33mtest_case\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "      dataset\u001b[90m\u001b[39;49;00m\n",
      "    )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.asyncio\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_chat_model\u001b[39;49;00m(test_case: LLMTestCase):\u001b[90m\u001b[39;49;00m\n",
      "        answer_relevancy_metric = AnswerRelevancyMetric(\u001b[90m\u001b[39;49;00m\n",
      "          threshold=\u001b[94m0.7\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "          model=vertexai_gemini,\u001b[90m\u001b[39;49;00m\n",
      "          include_reason=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "        bias_metric = FaithfulnessMetric(\u001b[90m\u001b[39;49;00m\n",
      "           threshold=\u001b[94m0.8\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "            model=vertexai_gemini,\u001b[90m\u001b[39;49;00m\n",
      "            include_reason=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "        toxicity_metric = ToxicityMetric(\u001b[90m\u001b[39;49;00m\n",
      "          threshold=\u001b[94m0.5\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "          model=vertexai_gemini,\u001b[90m\u001b[39;49;00m\n",
      "          include_reason=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "        correctness_metric = GEval(\u001b[90m\u001b[39;49;00m\n",
      "            threshold=\u001b[94m0.8\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "            name=\u001b[33m\"\u001b[39;49;00m\u001b[33mCorrectness\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "            evaluation_steps=[\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[33m\"\u001b[39;49;00m\u001b[33mCheck whether the facts in \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mactual output\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m contradict any facts in \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mexpected output\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[33m\"\u001b[39;49;00m\u001b[33mHeavily penalize omission of detail\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[33m\"\u001b[39;49;00m\u001b[33mVague language, or contradicting OPINIONS, are not okay\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            ],\u001b[90m\u001b[39;49;00m\n",
      "            evaluation_params=[\u001b[90m\u001b[39;49;00m\n",
      "              LLMTestCaseParams.INPUT,\u001b[90m\u001b[39;49;00m\n",
      "              LLMTestCaseParams.ACTUAL_OUTPUT,\u001b[90m\u001b[39;49;00m\n",
      "              LLMTestCaseParams.EXPECTED_OUTPUT\u001b[90m\u001b[39;49;00m\n",
      "            ],\u001b[90m\u001b[39;49;00m\n",
      "            model=vertexai_gemini\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "        rouge_metric = RougeMetric(threshold=\u001b[94m0.6\u001b[39;49;00m) \u001b[90m#custom metric created above\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       assert_test(test_case, [\u001b[90m\u001b[39;49;00m\n",
      "          bias_metric,\u001b[90m\u001b[39;49;00m\n",
      "          toxicity_metric,\u001b[90m\u001b[39;49;00m\n",
      "          correctness_metric,\u001b[90m\u001b[39;49;00m\n",
      "          answer_relevancy_metric,\u001b[90m\u001b[39;49;00m\n",
      "          rouge_metric\u001b[90m\u001b[39;49;00m\n",
      "        ])\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtest_rag_system.py\u001b[0m:135: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "test_case = LLMTestCase(input='What can you tell me about a new Deepseek model?', actual_output='DeepSeek released DeepSeek-R1, a ...all sizes.\\n'], additional_metadata=None, comments=None, tools_called=[], expected_tools=[], reasoning=None, name=None)\n",
      "metrics = [<deepeval.metrics.faithfulness.faithfulness.FaithfulnessMetric object at 0x1713d4dd0>, <deepeval.metrics.toxicity.tox...ncy.answer_relevancy.AnswerRelevancyMetric object at 0x1713d4690>, <test_rag_system.RougeMetric object at 0x170c72490>]\n",
      "run_async = True\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92massert_test\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "        test_case: Union[LLMTestCase, ConversationalTestCase, MLLMTestCase],\u001b[90m\u001b[39;49;00m\n",
      "        metrics: List[\u001b[90m\u001b[39;49;00m\n",
      "            Union[BaseMetric, BaseConversationalMetric, BaseMultimodalMetric]\u001b[90m\u001b[39;49;00m\n",
      "        ],\u001b[90m\u001b[39;49;00m\n",
      "        run_async: \u001b[96mbool\u001b[39;49;00m = \u001b[94mTrue\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "    ):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m run_async:\u001b[90m\u001b[39;49;00m\n",
      "            loop = get_or_create_event_loop()\u001b[90m\u001b[39;49;00m\n",
      "            test_result = loop.run_until_complete(\u001b[90m\u001b[39;49;00m\n",
      "                a_execute_test_cases(\u001b[90m\u001b[39;49;00m\n",
      "                    [test_case],\u001b[90m\u001b[39;49;00m\n",
      "                    metrics,\u001b[90m\u001b[39;49;00m\n",
      "                    skip_on_missing_params=should_skip_on_missing_params(),\u001b[90m\u001b[39;49;00m\n",
      "                    ignore_errors=should_ignore_errors(),\u001b[90m\u001b[39;49;00m\n",
      "                    use_cache=should_use_cache(),\u001b[90m\u001b[39;49;00m\n",
      "                    verbose_mode=should_verbose_print(),\u001b[90m\u001b[39;49;00m\n",
      "                    throttle_value=\u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# this doesn't matter for pytest\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    max_concurrent=\u001b[94m100\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    save_to_disk=get_is_running_deepeval(),\u001b[90m\u001b[39;49;00m\n",
      "                    show_indicator=\u001b[94mTrue\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    _use_bar_indicator=\u001b[94mTrue\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "            )[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "            test_result = execute_test_cases(\u001b[90m\u001b[39;49;00m\n",
      "                [test_case],\u001b[90m\u001b[39;49;00m\n",
      "                metrics,\u001b[90m\u001b[39;49;00m\n",
      "                skip_on_missing_params=should_skip_on_missing_params(),\u001b[90m\u001b[39;49;00m\n",
      "                ignore_errors=should_ignore_errors(),\u001b[90m\u001b[39;49;00m\n",
      "                use_cache=should_use_cache(),\u001b[90m\u001b[39;49;00m\n",
      "                verbose_mode=should_verbose_print(),\u001b[90m\u001b[39;49;00m\n",
      "                save_to_disk=get_is_running_deepeval(),\u001b[90m\u001b[39;49;00m\n",
      "                show_indicator=\u001b[94mTrue\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                _use_bar_indicator=\u001b[94mFalse\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "            )[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m test_result.success:\u001b[90m\u001b[39;49;00m\n",
      "            failed_metrics_data: List[MetricData] = []\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# even for conversations, test_result right now is just the\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# result for the last message\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mfor\u001b[39;49;00m metric_data \u001b[95min\u001b[39;49;00m test_result.metrics_data:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m metric_data.error \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    failed_metrics_data.append(metric_data)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# This try block is for user defined custom metrics,\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# which might not handle the score == undefined case elegantly\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94mtry\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m metric_data.success:\u001b[90m\u001b[39;49;00m\n",
      "                            failed_metrics_data.append(metric_data)\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94mexcept\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        failed_metrics_data.append(metric_data)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            failed_metrics_str = \u001b[33m\"\u001b[39;49;00m\u001b[33m, \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.join(\u001b[90m\u001b[39;49;00m\n",
      "                [\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mmetrics_data.name\u001b[33m}\u001b[39;49;00m\u001b[33m (score: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mmetrics_data.score\u001b[33m}\u001b[39;49;00m\u001b[33m, threshold: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mmetrics_data.threshold\u001b[33m}\u001b[39;49;00m\u001b[33m, strict: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mmetrics_data.strict_mode\u001b[33m}\u001b[39;49;00m\u001b[33m, error: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mmetrics_data.error\u001b[33m}\u001b[39;49;00m\u001b[33m)\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94mfor\u001b[39;49;00m metrics_data \u001b[95min\u001b[39;49;00m failed_metrics_data\u001b[90m\u001b[39;49;00m\n",
      "                ]\u001b[90m\u001b[39;49;00m\n",
      "            )\u001b[90m\u001b[39;49;00m\n",
      ">           \u001b[94mraise\u001b[39;49;00m \u001b[96mAssertionError\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mMetrics: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mfailed_metrics_str\u001b[33m}\u001b[39;49;00m\u001b[33m failed.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AssertionError: Metrics: Rouge Metric (score: 0.4482758620689656, threshold: 0.6, strict: False, error: None) failed.\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/deepeval/evaluate.py\u001b[0m:1004: AssertionError\n",
      "\u001b[31m\u001b[1m_________________________ test_chat_model[test_case2] __________________________\u001b[0m\n",
      "\n",
      "test_case = LLMTestCase(input='Which AI companies are working with U.S. government on military and intelligence applications?', ac...uman rights.'], additional_metadata=None, comments=None, tools_called=[], expected_tools=[], reasoning=None, name=None)\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[90m\u001b[39;49;00m\n",
      "      \u001b[33m\"\u001b[39;49;00m\u001b[33mtest_case\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "      dataset\u001b[90m\u001b[39;49;00m\n",
      "    )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.asyncio\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_chat_model\u001b[39;49;00m(test_case: LLMTestCase):\u001b[90m\u001b[39;49;00m\n",
      "        answer_relevancy_metric = AnswerRelevancyMetric(\u001b[90m\u001b[39;49;00m\n",
      "          threshold=\u001b[94m0.7\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "          model=vertexai_gemini,\u001b[90m\u001b[39;49;00m\n",
      "          include_reason=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "        bias_metric = FaithfulnessMetric(\u001b[90m\u001b[39;49;00m\n",
      "           threshold=\u001b[94m0.8\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "            model=vertexai_gemini,\u001b[90m\u001b[39;49;00m\n",
      "            include_reason=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "        toxicity_metric = ToxicityMetric(\u001b[90m\u001b[39;49;00m\n",
      "          threshold=\u001b[94m0.5\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "          model=vertexai_gemini,\u001b[90m\u001b[39;49;00m\n",
      "          include_reason=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "        correctness_metric = GEval(\u001b[90m\u001b[39;49;00m\n",
      "            threshold=\u001b[94m0.8\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "            name=\u001b[33m\"\u001b[39;49;00m\u001b[33mCorrectness\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "            evaluation_steps=[\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[33m\"\u001b[39;49;00m\u001b[33mCheck whether the facts in \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mactual output\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m contradict any facts in \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mexpected output\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[33m\"\u001b[39;49;00m\u001b[33mHeavily penalize omission of detail\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[33m\"\u001b[39;49;00m\u001b[33mVague language, or contradicting OPINIONS, are not okay\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            ],\u001b[90m\u001b[39;49;00m\n",
      "            evaluation_params=[\u001b[90m\u001b[39;49;00m\n",
      "              LLMTestCaseParams.INPUT,\u001b[90m\u001b[39;49;00m\n",
      "              LLMTestCaseParams.ACTUAL_OUTPUT,\u001b[90m\u001b[39;49;00m\n",
      "              LLMTestCaseParams.EXPECTED_OUTPUT\u001b[90m\u001b[39;49;00m\n",
      "            ],\u001b[90m\u001b[39;49;00m\n",
      "            model=vertexai_gemini\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "        rouge_metric = RougeMetric(threshold=\u001b[94m0.6\u001b[39;49;00m) \u001b[90m#custom metric created above\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       assert_test(test_case, [\u001b[90m\u001b[39;49;00m\n",
      "          bias_metric,\u001b[90m\u001b[39;49;00m\n",
      "          toxicity_metric,\u001b[90m\u001b[39;49;00m\n",
      "          correctness_metric,\u001b[90m\u001b[39;49;00m\n",
      "          answer_relevancy_metric,\u001b[90m\u001b[39;49;00m\n",
      "          rouge_metric\u001b[90m\u001b[39;49;00m\n",
      "        ])\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtest_rag_system.py\u001b[0m:135: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "test_case = LLMTestCase(input='Which AI companies are working with U.S. government on military and intelligence applications?', ac...uman rights.'], additional_metadata=None, comments=None, tools_called=[], expected_tools=[], reasoning=None, name=None)\n",
      "metrics = [<deepeval.metrics.faithfulness.faithfulness.FaithfulnessMetric object at 0x1714164d0>, <deepeval.metrics.toxicity.tox...ncy.answer_relevancy.AnswerRelevancyMetric object at 0x171414a90>, <test_rag_system.RougeMetric object at 0x171415510>]\n",
      "run_async = True\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92massert_test\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "        test_case: Union[LLMTestCase, ConversationalTestCase, MLLMTestCase],\u001b[90m\u001b[39;49;00m\n",
      "        metrics: List[\u001b[90m\u001b[39;49;00m\n",
      "            Union[BaseMetric, BaseConversationalMetric, BaseMultimodalMetric]\u001b[90m\u001b[39;49;00m\n",
      "        ],\u001b[90m\u001b[39;49;00m\n",
      "        run_async: \u001b[96mbool\u001b[39;49;00m = \u001b[94mTrue\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "    ):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m run_async:\u001b[90m\u001b[39;49;00m\n",
      "            loop = get_or_create_event_loop()\u001b[90m\u001b[39;49;00m\n",
      "            test_result = loop.run_until_complete(\u001b[90m\u001b[39;49;00m\n",
      "                a_execute_test_cases(\u001b[90m\u001b[39;49;00m\n",
      "                    [test_case],\u001b[90m\u001b[39;49;00m\n",
      "                    metrics,\u001b[90m\u001b[39;49;00m\n",
      "                    skip_on_missing_params=should_skip_on_missing_params(),\u001b[90m\u001b[39;49;00m\n",
      "                    ignore_errors=should_ignore_errors(),\u001b[90m\u001b[39;49;00m\n",
      "                    use_cache=should_use_cache(),\u001b[90m\u001b[39;49;00m\n",
      "                    verbose_mode=should_verbose_print(),\u001b[90m\u001b[39;49;00m\n",
      "                    throttle_value=\u001b[94m0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# this doesn't matter for pytest\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    max_concurrent=\u001b[94m100\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    save_to_disk=get_is_running_deepeval(),\u001b[90m\u001b[39;49;00m\n",
      "                    show_indicator=\u001b[94mTrue\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    _use_bar_indicator=\u001b[94mTrue\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "            )[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "            test_result = execute_test_cases(\u001b[90m\u001b[39;49;00m\n",
      "                [test_case],\u001b[90m\u001b[39;49;00m\n",
      "                metrics,\u001b[90m\u001b[39;49;00m\n",
      "                skip_on_missing_params=should_skip_on_missing_params(),\u001b[90m\u001b[39;49;00m\n",
      "                ignore_errors=should_ignore_errors(),\u001b[90m\u001b[39;49;00m\n",
      "                use_cache=should_use_cache(),\u001b[90m\u001b[39;49;00m\n",
      "                verbose_mode=should_verbose_print(),\u001b[90m\u001b[39;49;00m\n",
      "                save_to_disk=get_is_running_deepeval(),\u001b[90m\u001b[39;49;00m\n",
      "                show_indicator=\u001b[94mTrue\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                _use_bar_indicator=\u001b[94mFalse\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "            )[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m test_result.success:\u001b[90m\u001b[39;49;00m\n",
      "            failed_metrics_data: List[MetricData] = []\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# even for conversations, test_result right now is just the\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# result for the last message\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mfor\u001b[39;49;00m metric_data \u001b[95min\u001b[39;49;00m test_result.metrics_data:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m metric_data.error \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    failed_metrics_data.append(metric_data)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# This try block is for user defined custom metrics,\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# which might not handle the score == undefined case elegantly\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94mtry\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m metric_data.success:\u001b[90m\u001b[39;49;00m\n",
      "                            failed_metrics_data.append(metric_data)\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94mexcept\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        failed_metrics_data.append(metric_data)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            failed_metrics_str = \u001b[33m\"\u001b[39;49;00m\u001b[33m, \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.join(\u001b[90m\u001b[39;49;00m\n",
      "                [\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mmetrics_data.name\u001b[33m}\u001b[39;49;00m\u001b[33m (score: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mmetrics_data.score\u001b[33m}\u001b[39;49;00m\u001b[33m, threshold: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mmetrics_data.threshold\u001b[33m}\u001b[39;49;00m\u001b[33m, strict: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mmetrics_data.strict_mode\u001b[33m}\u001b[39;49;00m\u001b[33m, error: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mmetrics_data.error\u001b[33m}\u001b[39;49;00m\u001b[33m)\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94mfor\u001b[39;49;00m metrics_data \u001b[95min\u001b[39;49;00m failed_metrics_data\u001b[90m\u001b[39;49;00m\n",
      "                ]\u001b[90m\u001b[39;49;00m\n",
      "            )\u001b[90m\u001b[39;49;00m\n",
      ">           \u001b[94mraise\u001b[39;49;00m \u001b[96mAssertionError\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mMetrics: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mfailed_metrics_str\u001b[33m}\u001b[39;49;00m\u001b[33m failed.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AssertionError: Metrics: Correctness (GEval) (score: 0.6, threshold: 0.8, strict: False, error: None), Rouge Metric (score: 0.09230769230769231, threshold: 0.6, strict: False, error: None) failed.\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/deepeval/evaluate.py\u001b[0m:1004: AssertionError\n",
      "\u001b[31m\u001b[1m_________________________ test_chat_model[test_case3] __________________________\u001b[0m\n",
      "\n",
      "test_case = LLMTestCase(input='what are the models used in biochemistry?', actual_output='AlphaFold 3 is a model that predicts the...val_context=[], additional_metadata=None, comments=None, tools_called=[], expected_tools=[], reasoning=None, name=None)\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[90m\u001b[39;49;00m\n",
      "      \u001b[33m\"\u001b[39;49;00m\u001b[33mtest_case\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "      dataset\u001b[90m\u001b[39;49;00m\n",
      "    )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.asyncio\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_chat_model\u001b[39;49;00m(test_case: LLMTestCase):\u001b[90m\u001b[39;49;00m\n",
      "        answer_relevancy_metric = AnswerRelevancyMetric(\u001b[90m\u001b[39;49;00m\n",
      "          threshold=\u001b[94m0.7\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "          model=vertexai_gemini,\u001b[90m\u001b[39;49;00m\n",
      "          include_reason=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "        bias_metric = FaithfulnessMetric(\u001b[90m\u001b[39;49;00m\n",
      "           threshold=\u001b[94m0.8\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "            model=vertexai_gemini,\u001b[90m\u001b[39;49;00m\n",
      "            include_reason=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "        toxicity_metric = ToxicityMetric(\u001b[90m\u001b[39;49;00m\n",
      "          threshold=\u001b[94m0.5\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "          model=vertexai_gemini,\u001b[90m\u001b[39;49;00m\n",
      "          include_reason=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "        correctness_metric = GEval(\u001b[90m\u001b[39;49;00m\n",
      "            threshold=\u001b[94m0.8\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "            name=\u001b[33m\"\u001b[39;49;00m\u001b[33mCorrectness\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "            evaluation_steps=[\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[33m\"\u001b[39;49;00m\u001b[33mCheck whether the facts in \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mactual output\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m contradict any facts in \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mexpected output\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[33m\"\u001b[39;49;00m\u001b[33mHeavily penalize omission of detail\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[33m\"\u001b[39;49;00m\u001b[33mVague language, or contradicting OPINIONS, are not okay\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            ],\u001b[90m\u001b[39;49;00m\n",
      "            evaluation_params=[\u001b[90m\u001b[39;49;00m\n",
      "              LLMTestCaseParams.INPUT,\u001b[90m\u001b[39;49;00m\n",
      "              LLMTestCaseParams.ACTUAL_OUTPUT,\u001b[90m\u001b[39;49;00m\n",
      "              LLMTestCaseParams.EXPECTED_OUTPUT\u001b[90m\u001b[39;49;00m\n",
      "            ],\u001b[90m\u001b[39;49;00m\n",
      "            model=vertexai_gemini\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "        rouge_metric = RougeMetric(threshold=\u001b[94m0.6\u001b[39;49;00m) \u001b[90m#custom metric created above\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       assert_test(test_case, [\u001b[90m\u001b[39;49;00m\n",
      "          bias_metric,\u001b[90m\u001b[39;49;00m\n",
      "          toxicity_metric,\u001b[90m\u001b[39;49;00m\n",
      "          correctness_metric,\u001b[90m\u001b[39;49;00m\n",
      "          answer_relevancy_metric,\u001b[90m\u001b[39;49;00m\n",
      "          rouge_metric\u001b[90m\u001b[39;49;00m\n",
      "        ])\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtest_rag_system.py\u001b[0m:135: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/deepeval/evaluate.py\u001b[0m:953: in assert_test\n",
      "    \u001b[0mtest_result = loop.run_until_complete(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py\u001b[0m:654: in run_until_complete\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m future.result()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/deepeval/evaluate.py\u001b[0m:678: in a_execute_test_cases\n",
      "    \u001b[0m\u001b[94mawait\u001b[39;49;00m asyncio.gather(*tasks)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/deepeval/evaluate.py\u001b[0m:574: in execute_with_semaphore\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[94mawait\u001b[39;49;00m func(*args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/deepeval/evaluate.py\u001b[0m:785: in a_execute_llm_test_cases\n",
      "    \u001b[0m\u001b[94mawait\u001b[39;49;00m measure_metrics_with_indicator(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/deepeval/metrics/indicator.py\u001b[0m:201: in measure_metrics_with_indicator\n",
      "    \u001b[0m\u001b[94mawait\u001b[39;49;00m asyncio.gather(*tasks)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/deepeval/metrics/indicator.py\u001b[0m:211: in safe_a_measure\n",
      "    \u001b[0m\u001b[94mawait\u001b[39;49;00m metric.a_measure(tc, _show_indicator=\u001b[94mFalse\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/deepeval/metrics/faithfulness/faithfulness.py\u001b[0m:108: in a_measure\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m.truths, \u001b[96mself\u001b[39;49;00m.claims = \u001b[94mawait\u001b[39;49;00m asyncio.gather(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/deepeval/metrics/faithfulness/faithfulness.py\u001b[0m:283: in _a_generate_claims\n",
      "    \u001b[0mres = \u001b[94mawait\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.model.a_generate(prompt)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mtest_rag_system.py\u001b[0m:39: in a_generate\n",
      "    \u001b[0mres = \u001b[94mawait\u001b[39;49;00m chat_model.ainvoke(prompt)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\u001b[0m:305: in ainvoke\n",
      "    \u001b[0mllm_result = \u001b[94mawait\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.agenerate_prompt(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\u001b[0m:870: in agenerate_prompt\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[94mawait\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.agenerate(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\u001b[0m:830: in agenerate\n",
      "    \u001b[0m\u001b[94mraise\u001b[39;49;00m exceptions[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\u001b[0m:998: in _agenerate_with_cache\n",
      "    \u001b[0mresult = \u001b[94mawait\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._agenerate(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/langchain_google_genai/chat_models.py\u001b[0m:1010: in _agenerate\n",
      "    \u001b[0mresponse: GenerateContentResponse = \u001b[94mawait\u001b[39;49;00m _achat_with_retry(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/langchain_google_genai/chat_models.py\u001b[0m:229: in _achat_with_retry\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[94mawait\u001b[39;49;00m _achat_with_retry(**kwargs)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/tenacity/asyncio/__init__.py\u001b[0m:189: in async_wrapped\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[94mawait\u001b[39;49;00m copy(fn, *args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/tenacity/asyncio/__init__.py\u001b[0m:111: in __call__\n",
      "    \u001b[0mdo = \u001b[94mawait\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.iter(retry_state=retry_state)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/tenacity/asyncio/__init__.py\u001b[0m:153: in iter\n",
      "    \u001b[0mresult = \u001b[94mawait\u001b[39;49;00m action(retry_state)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/tenacity/_utils.py\u001b[0m:99: in inner\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m call(*args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/tenacity/__init__.py\u001b[0m:418: in exc_check\n",
      "    \u001b[0m\u001b[94mraise\u001b[39;49;00m retry_exc.reraise()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/tenacity/__init__.py\u001b[0m:185: in reraise\n",
      "    \u001b[0m\u001b[94mraise\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.last_attempt.result()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py\u001b[0m:449: in result\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.__get_result()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py\u001b[0m:401: in __get_result\n",
      "    \u001b[0m\u001b[94mraise\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._exception\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/tenacity/asyncio/__init__.py\u001b[0m:114: in __call__\n",
      "    \u001b[0mresult = \u001b[94mawait\u001b[39;49;00m fn(*args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/langchain_google_genai/chat_models.py\u001b[0m:227: in _achat_with_retry\n",
      "    \u001b[0m\u001b[94mraise\u001b[39;49;00m e\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/langchain_google_genai/chat_models.py\u001b[0m:220: in _achat_with_retry\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[94mawait\u001b[39;49;00m generation_method(**kwargs)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/async_client.py\u001b[0m:440: in generate_content\n",
      "    \u001b[0mresponse = \u001b[94mawait\u001b[39;49;00m rpc(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/google/api_core/retry/retry_unary_async.py\u001b[0m:230: in retry_wrapped_func\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[94mawait\u001b[39;49;00m retry_target(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/google/api_core/retry/retry_unary_async.py\u001b[0m:160: in retry_target\n",
      "    \u001b[0m_retry_error_helper(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/google/api_core/retry/retry_base.py\u001b[0m:212: in _retry_error_helper\n",
      "    \u001b[0m\u001b[94mraise\u001b[39;49;00m final_exc \u001b[94mfrom\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96msource_exc\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/google/api_core/retry/retry_unary_async.py\u001b[0m:155: in retry_target\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[94mawait\u001b[39;49;00m target()\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <google.api_core.grpc_helpers_async._WrappedUnaryUnaryCall object at 0x1716e2910>\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92m__await__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m) -> Iterator[P]:\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mtry\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "            response = \u001b[94myield from\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._call.\u001b[92m__await__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mreturn\u001b[39;49;00m response\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mexcept\u001b[39;49;00m grpc.RpcError \u001b[94mas\u001b[39;49;00m rpc_error:\u001b[90m\u001b[39;49;00m\n",
      ">           \u001b[94mraise\u001b[39;49;00m exceptions.from_grpc_error(rpc_error) \u001b[94mfrom\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mrpc_error\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           google.api_core.exceptions.ResourceExhausted: 429 Resource has been exhausted (e.g. check quota).\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/google/api_core/grpc_helpers_async.py\u001b[0m:88: ResourceExhausted\n",
      "------------------------------ Captured log call -------------------------------\n",
      "\u001b[33mWARNING \u001b[0m langchain_google_genai.chat_models:before_sleep.py:65 Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "\u001b[33mWARNING \u001b[0m langchain_google_genai.chat_models:before_sleep.py:65 Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "\u001b[33mWARNING \u001b[0m langchain_google_genai.chat_models:before_sleep.py:65 Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "\u001b[33mWARNING \u001b[0m langchain_google_genai.chat_models:before_sleep.py:65 Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "\u001b[33mWARNING \u001b[0m langchain_google_genai.chat_models:before_sleep.py:65 Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "\u001b[31m\u001b[1m_________________________ test_chat_model[test_case4] __________________________\u001b[0m\n",
      "\n",
      "test_case = LLMTestCase(input='Are neural networks assisting brain surgeons, and if yes what models are they using?', actual_outpu...en versions!'], additional_metadata=None, comments=None, tools_called=[], expected_tools=[], reasoning=None, name=None)\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[90m\u001b[39;49;00m\n",
      "      \u001b[33m\"\u001b[39;49;00m\u001b[33mtest_case\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "      dataset\u001b[90m\u001b[39;49;00m\n",
      "    )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.asyncio\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_chat_model\u001b[39;49;00m(test_case: LLMTestCase):\u001b[90m\u001b[39;49;00m\n",
      "        answer_relevancy_metric = AnswerRelevancyMetric(\u001b[90m\u001b[39;49;00m\n",
      "          threshold=\u001b[94m0.7\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "          model=vertexai_gemini,\u001b[90m\u001b[39;49;00m\n",
      "          include_reason=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "        bias_metric = FaithfulnessMetric(\u001b[90m\u001b[39;49;00m\n",
      "           threshold=\u001b[94m0.8\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "            model=vertexai_gemini,\u001b[90m\u001b[39;49;00m\n",
      "            include_reason=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "        toxicity_metric = ToxicityMetric(\u001b[90m\u001b[39;49;00m\n",
      "          threshold=\u001b[94m0.5\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "          model=vertexai_gemini,\u001b[90m\u001b[39;49;00m\n",
      "          include_reason=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "        correctness_metric = GEval(\u001b[90m\u001b[39;49;00m\n",
      "            threshold=\u001b[94m0.8\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "            name=\u001b[33m\"\u001b[39;49;00m\u001b[33mCorrectness\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "            evaluation_steps=[\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[33m\"\u001b[39;49;00m\u001b[33mCheck whether the facts in \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mactual output\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m contradict any facts in \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mexpected output\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[33m\"\u001b[39;49;00m\u001b[33mHeavily penalize omission of detail\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[33m\"\u001b[39;49;00m\u001b[33mVague language, or contradicting OPINIONS, are not okay\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            ],\u001b[90m\u001b[39;49;00m\n",
      "            evaluation_params=[\u001b[90m\u001b[39;49;00m\n",
      "              LLMTestCaseParams.INPUT,\u001b[90m\u001b[39;49;00m\n",
      "              LLMTestCaseParams.ACTUAL_OUTPUT,\u001b[90m\u001b[39;49;00m\n",
      "              LLMTestCaseParams.EXPECTED_OUTPUT\u001b[90m\u001b[39;49;00m\n",
      "            ],\u001b[90m\u001b[39;49;00m\n",
      "            model=vertexai_gemini\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "        rouge_metric = RougeMetric(threshold=\u001b[94m0.6\u001b[39;49;00m) \u001b[90m#custom metric created above\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       assert_test(test_case, [\u001b[90m\u001b[39;49;00m\n",
      "          bias_metric,\u001b[90m\u001b[39;49;00m\n",
      "          toxicity_metric,\u001b[90m\u001b[39;49;00m\n",
      "          correctness_metric,\u001b[90m\u001b[39;49;00m\n",
      "          answer_relevancy_metric,\u001b[90m\u001b[39;49;00m\n",
      "          rouge_metric\u001b[90m\u001b[39;49;00m\n",
      "        ])\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtest_rag_system.py\u001b[0m:135: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/deepeval/evaluate.py\u001b[0m:953: in assert_test\n",
      "    \u001b[0mtest_result = loop.run_until_complete(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py\u001b[0m:654: in run_until_complete\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m future.result()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/deepeval/evaluate.py\u001b[0m:678: in a_execute_test_cases\n",
      "    \u001b[0m\u001b[94mawait\u001b[39;49;00m asyncio.gather(*tasks)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/deepeval/evaluate.py\u001b[0m:574: in execute_with_semaphore\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[94mawait\u001b[39;49;00m func(*args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/deepeval/evaluate.py\u001b[0m:785: in a_execute_llm_test_cases\n",
      "    \u001b[0m\u001b[94mawait\u001b[39;49;00m measure_metrics_with_indicator(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/deepeval/metrics/indicator.py\u001b[0m:201: in measure_metrics_with_indicator\n",
      "    \u001b[0m\u001b[94mawait\u001b[39;49;00m asyncio.gather(*tasks)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/deepeval/metrics/indicator.py\u001b[0m:211: in safe_a_measure\n",
      "    \u001b[0m\u001b[94mawait\u001b[39;49;00m metric.a_measure(tc, _show_indicator=\u001b[94mFalse\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/deepeval/metrics/toxicity/toxicity.py\u001b[0m:95: in a_measure\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m.opinions: List[\u001b[96mstr\u001b[39;49;00m] = \u001b[94mawait\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._a_generate_opinions(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/deepeval/metrics/toxicity/toxicity.py\u001b[0m:234: in _a_generate_opinions\n",
      "    \u001b[0mres = \u001b[94mawait\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.model.a_generate(prompt)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mtest_rag_system.py\u001b[0m:39: in a_generate\n",
      "    \u001b[0mres = \u001b[94mawait\u001b[39;49;00m chat_model.ainvoke(prompt)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\u001b[0m:305: in ainvoke\n",
      "    \u001b[0mllm_result = \u001b[94mawait\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.agenerate_prompt(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\u001b[0m:870: in agenerate_prompt\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[94mawait\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.agenerate(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\u001b[0m:830: in agenerate\n",
      "    \u001b[0m\u001b[94mraise\u001b[39;49;00m exceptions[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\u001b[0m:998: in _agenerate_with_cache\n",
      "    \u001b[0mresult = \u001b[94mawait\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._agenerate(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/langchain_google_genai/chat_models.py\u001b[0m:1010: in _agenerate\n",
      "    \u001b[0mresponse: GenerateContentResponse = \u001b[94mawait\u001b[39;49;00m _achat_with_retry(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/langchain_google_genai/chat_models.py\u001b[0m:229: in _achat_with_retry\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[94mawait\u001b[39;49;00m _achat_with_retry(**kwargs)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/tenacity/asyncio/__init__.py\u001b[0m:189: in async_wrapped\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[94mawait\u001b[39;49;00m copy(fn, *args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/tenacity/asyncio/__init__.py\u001b[0m:111: in __call__\n",
      "    \u001b[0mdo = \u001b[94mawait\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.iter(retry_state=retry_state)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/tenacity/asyncio/__init__.py\u001b[0m:153: in iter\n",
      "    \u001b[0mresult = \u001b[94mawait\u001b[39;49;00m action(retry_state)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/tenacity/_utils.py\u001b[0m:99: in inner\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m call(*args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/tenacity/__init__.py\u001b[0m:418: in exc_check\n",
      "    \u001b[0m\u001b[94mraise\u001b[39;49;00m retry_exc.reraise()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/tenacity/__init__.py\u001b[0m:185: in reraise\n",
      "    \u001b[0m\u001b[94mraise\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.last_attempt.result()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py\u001b[0m:449: in result\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.__get_result()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py\u001b[0m:401: in __get_result\n",
      "    \u001b[0m\u001b[94mraise\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._exception\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/tenacity/asyncio/__init__.py\u001b[0m:114: in __call__\n",
      "    \u001b[0mresult = \u001b[94mawait\u001b[39;49;00m fn(*args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/langchain_google_genai/chat_models.py\u001b[0m:227: in _achat_with_retry\n",
      "    \u001b[0m\u001b[94mraise\u001b[39;49;00m e\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/langchain_google_genai/chat_models.py\u001b[0m:220: in _achat_with_retry\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[94mawait\u001b[39;49;00m generation_method(**kwargs)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/async_client.py\u001b[0m:440: in generate_content\n",
      "    \u001b[0mresponse = \u001b[94mawait\u001b[39;49;00m rpc(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/google/api_core/retry/retry_unary_async.py\u001b[0m:230: in retry_wrapped_func\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[94mawait\u001b[39;49;00m retry_target(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/google/api_core/retry/retry_unary_async.py\u001b[0m:160: in retry_target\n",
      "    \u001b[0m_retry_error_helper(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/google/api_core/retry/retry_base.py\u001b[0m:212: in _retry_error_helper\n",
      "    \u001b[0m\u001b[94mraise\u001b[39;49;00m final_exc \u001b[94mfrom\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96msource_exc\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/google/api_core/retry/retry_unary_async.py\u001b[0m:155: in retry_target\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[94mawait\u001b[39;49;00m target()\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <google.api_core.grpc_helpers_async._WrappedUnaryUnaryCall object at 0x1719cab50>\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92m__await__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m) -> Iterator[P]:\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mtry\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "            response = \u001b[94myield from\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._call.\u001b[92m__await__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mreturn\u001b[39;49;00m response\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mexcept\u001b[39;49;00m grpc.RpcError \u001b[94mas\u001b[39;49;00m rpc_error:\u001b[90m\u001b[39;49;00m\n",
      ">           \u001b[94mraise\u001b[39;49;00m exceptions.from_grpc_error(rpc_error) \u001b[94mfrom\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mrpc_error\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           google.api_core.exceptions.ResourceExhausted: 429 Resource has been exhausted (e.g. check quota).\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/google/api_core/grpc_helpers_async.py\u001b[0m:88: ResourceExhausted\n",
      "------------------------------ Captured log call -------------------------------\n",
      "\u001b[33mWARNING \u001b[0m langchain_google_genai.chat_models:before_sleep.py:65 Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "\u001b[33mWARNING \u001b[0m langchain_google_genai.chat_models:before_sleep.py:65 Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "\u001b[33mWARNING \u001b[0m langchain_google_genai.chat_models:before_sleep.py:65 Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "\u001b[33mWARNING \u001b[0m langchain_google_genai.chat_models:before_sleep.py:65 Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "\u001b[33mWARNING \u001b[0m langchain_google_genai.chat_models:before_sleep.py:65 Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "\u001b[31m\u001b[1m_________________________ test_chat_model[test_case5] __________________________\u001b[0m\n",
      "\n",
      "test_case = LLMTestCase(input='Does AI have a great influence on climate due to a big energy consumption?', actual_output='Yes, AI...initiatives.\"], additional_metadata=None, comments=None, tools_called=[], expected_tools=[], reasoning=None, name=None)\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[90m\u001b[39;49;00m\n",
      "      \u001b[33m\"\u001b[39;49;00m\u001b[33mtest_case\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "      dataset\u001b[90m\u001b[39;49;00m\n",
      "    )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.asyncio\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_chat_model\u001b[39;49;00m(test_case: LLMTestCase):\u001b[90m\u001b[39;49;00m\n",
      "        answer_relevancy_metric = AnswerRelevancyMetric(\u001b[90m\u001b[39;49;00m\n",
      "          threshold=\u001b[94m0.7\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "          model=vertexai_gemini,\u001b[90m\u001b[39;49;00m\n",
      "          include_reason=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "        bias_metric = FaithfulnessMetric(\u001b[90m\u001b[39;49;00m\n",
      "           threshold=\u001b[94m0.8\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "            model=vertexai_gemini,\u001b[90m\u001b[39;49;00m\n",
      "            include_reason=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "        toxicity_metric = ToxicityMetric(\u001b[90m\u001b[39;49;00m\n",
      "          threshold=\u001b[94m0.5\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "          model=vertexai_gemini,\u001b[90m\u001b[39;49;00m\n",
      "          include_reason=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "        correctness_metric = GEval(\u001b[90m\u001b[39;49;00m\n",
      "            threshold=\u001b[94m0.8\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "            name=\u001b[33m\"\u001b[39;49;00m\u001b[33mCorrectness\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "            evaluation_steps=[\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[33m\"\u001b[39;49;00m\u001b[33mCheck whether the facts in \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mactual output\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m contradict any facts in \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mexpected output\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[33m\"\u001b[39;49;00m\u001b[33mHeavily penalize omission of detail\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[33m\"\u001b[39;49;00m\u001b[33mVague language, or contradicting OPINIONS, are not okay\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            ],\u001b[90m\u001b[39;49;00m\n",
      "            evaluation_params=[\u001b[90m\u001b[39;49;00m\n",
      "              LLMTestCaseParams.INPUT,\u001b[90m\u001b[39;49;00m\n",
      "              LLMTestCaseParams.ACTUAL_OUTPUT,\u001b[90m\u001b[39;49;00m\n",
      "              LLMTestCaseParams.EXPECTED_OUTPUT\u001b[90m\u001b[39;49;00m\n",
      "            ],\u001b[90m\u001b[39;49;00m\n",
      "            model=vertexai_gemini\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "        rouge_metric = RougeMetric(threshold=\u001b[94m0.6\u001b[39;49;00m) \u001b[90m#custom metric created above\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       assert_test(test_case, [\u001b[90m\u001b[39;49;00m\n",
      "          bias_metric,\u001b[90m\u001b[39;49;00m\n",
      "          toxicity_metric,\u001b[90m\u001b[39;49;00m\n",
      "          correctness_metric,\u001b[90m\u001b[39;49;00m\n",
      "          answer_relevancy_metric,\u001b[90m\u001b[39;49;00m\n",
      "          rouge_metric\u001b[90m\u001b[39;49;00m\n",
      "        ])\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtest_rag_system.py\u001b[0m:135: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/deepeval/evaluate.py\u001b[0m:953: in assert_test\n",
      "    \u001b[0mtest_result = loop.run_until_complete(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py\u001b[0m:654: in run_until_complete\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m future.result()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/deepeval/evaluate.py\u001b[0m:678: in a_execute_test_cases\n",
      "    \u001b[0m\u001b[94mawait\u001b[39;49;00m asyncio.gather(*tasks)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/deepeval/evaluate.py\u001b[0m:574: in execute_with_semaphore\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[94mawait\u001b[39;49;00m func(*args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/deepeval/evaluate.py\u001b[0m:785: in a_execute_llm_test_cases\n",
      "    \u001b[0m\u001b[94mawait\u001b[39;49;00m measure_metrics_with_indicator(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/deepeval/metrics/indicator.py\u001b[0m:201: in measure_metrics_with_indicator\n",
      "    \u001b[0m\u001b[94mawait\u001b[39;49;00m asyncio.gather(*tasks)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/deepeval/metrics/indicator.py\u001b[0m:211: in safe_a_measure\n",
      "    \u001b[0m\u001b[94mawait\u001b[39;49;00m metric.a_measure(tc, _show_indicator=\u001b[94mFalse\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/deepeval/metrics/toxicity/toxicity.py\u001b[0m:95: in a_measure\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m.opinions: List[\u001b[96mstr\u001b[39;49;00m] = \u001b[94mawait\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._a_generate_opinions(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/deepeval/metrics/toxicity/toxicity.py\u001b[0m:234: in _a_generate_opinions\n",
      "    \u001b[0mres = \u001b[94mawait\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.model.a_generate(prompt)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mtest_rag_system.py\u001b[0m:39: in a_generate\n",
      "    \u001b[0mres = \u001b[94mawait\u001b[39;49;00m chat_model.ainvoke(prompt)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\u001b[0m:305: in ainvoke\n",
      "    \u001b[0mllm_result = \u001b[94mawait\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.agenerate_prompt(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\u001b[0m:870: in agenerate_prompt\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[94mawait\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.agenerate(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\u001b[0m:830: in agenerate\n",
      "    \u001b[0m\u001b[94mraise\u001b[39;49;00m exceptions[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\u001b[0m:998: in _agenerate_with_cache\n",
      "    \u001b[0mresult = \u001b[94mawait\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._agenerate(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/langchain_google_genai/chat_models.py\u001b[0m:1010: in _agenerate\n",
      "    \u001b[0mresponse: GenerateContentResponse = \u001b[94mawait\u001b[39;49;00m _achat_with_retry(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/langchain_google_genai/chat_models.py\u001b[0m:229: in _achat_with_retry\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[94mawait\u001b[39;49;00m _achat_with_retry(**kwargs)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/tenacity/asyncio/__init__.py\u001b[0m:189: in async_wrapped\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[94mawait\u001b[39;49;00m copy(fn, *args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/tenacity/asyncio/__init__.py\u001b[0m:111: in __call__\n",
      "    \u001b[0mdo = \u001b[94mawait\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.iter(retry_state=retry_state)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/tenacity/asyncio/__init__.py\u001b[0m:153: in iter\n",
      "    \u001b[0mresult = \u001b[94mawait\u001b[39;49;00m action(retry_state)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/tenacity/_utils.py\u001b[0m:99: in inner\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m call(*args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/tenacity/__init__.py\u001b[0m:418: in exc_check\n",
      "    \u001b[0m\u001b[94mraise\u001b[39;49;00m retry_exc.reraise()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/tenacity/__init__.py\u001b[0m:185: in reraise\n",
      "    \u001b[0m\u001b[94mraise\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.last_attempt.result()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py\u001b[0m:449: in result\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.__get_result()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py\u001b[0m:401: in __get_result\n",
      "    \u001b[0m\u001b[94mraise\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._exception\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/tenacity/asyncio/__init__.py\u001b[0m:114: in __call__\n",
      "    \u001b[0mresult = \u001b[94mawait\u001b[39;49;00m fn(*args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/langchain_google_genai/chat_models.py\u001b[0m:227: in _achat_with_retry\n",
      "    \u001b[0m\u001b[94mraise\u001b[39;49;00m e\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/langchain_google_genai/chat_models.py\u001b[0m:220: in _achat_with_retry\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[94mawait\u001b[39;49;00m generation_method(**kwargs)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/async_client.py\u001b[0m:440: in generate_content\n",
      "    \u001b[0mresponse = \u001b[94mawait\u001b[39;49;00m rpc(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/google/api_core/retry/retry_unary_async.py\u001b[0m:230: in retry_wrapped_func\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[94mawait\u001b[39;49;00m retry_target(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/google/api_core/retry/retry_unary_async.py\u001b[0m:160: in retry_target\n",
      "    \u001b[0m_retry_error_helper(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/google/api_core/retry/retry_base.py\u001b[0m:212: in _retry_error_helper\n",
      "    \u001b[0m\u001b[94mraise\u001b[39;49;00m final_exc \u001b[94mfrom\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96msource_exc\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/google/api_core/retry/retry_unary_async.py\u001b[0m:155: in retry_target\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[94mawait\u001b[39;49;00m target()\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <google.api_core.grpc_helpers_async._WrappedUnaryUnaryCall object at 0x1717b2250>\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92m__await__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m) -> Iterator[P]:\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mtry\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "            response = \u001b[94myield from\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._call.\u001b[92m__await__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mreturn\u001b[39;49;00m response\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mexcept\u001b[39;49;00m grpc.RpcError \u001b[94mas\u001b[39;49;00m rpc_error:\u001b[90m\u001b[39;49;00m\n",
      ">           \u001b[94mraise\u001b[39;49;00m exceptions.from_grpc_error(rpc_error) \u001b[94mfrom\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mrpc_error\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           google.api_core.exceptions.ResourceExhausted: 429 Resource has been exhausted (e.g. check quota).\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/google/api_core/grpc_helpers_async.py\u001b[0m:88: ResourceExhausted\n",
      "------------------------------ Captured log call -------------------------------\n",
      "\u001b[33mWARNING \u001b[0m langchain_google_genai.chat_models:before_sleep.py:65 Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "\u001b[33mWARNING \u001b[0m langchain_google_genai.chat_models:before_sleep.py:65 Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "\u001b[33mWARNING \u001b[0m langchain_google_genai.chat_models:before_sleep.py:65 Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "\u001b[33mWARNING \u001b[0m langchain_google_genai.chat_models:before_sleep.py:65 Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "\u001b[33mWARNING \u001b[0m langchain_google_genai.chat_models:before_sleep.py:65 Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "\u001b[31m\u001b[1m_________________________ test_chat_model[test_case6] __________________________\u001b[0m\n",
      "\n",
      "test_case = LLMTestCase(input='Who is Anna Cielas?', actual_output='The context provided does not contain any information about An...val_context=[], additional_metadata=None, comments=None, tools_called=[], expected_tools=[], reasoning=None, name=None)\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[90m\u001b[39;49;00m\n",
      "      \u001b[33m\"\u001b[39;49;00m\u001b[33mtest_case\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "      dataset\u001b[90m\u001b[39;49;00m\n",
      "    )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.asyncio\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_chat_model\u001b[39;49;00m(test_case: LLMTestCase):\u001b[90m\u001b[39;49;00m\n",
      "        answer_relevancy_metric = AnswerRelevancyMetric(\u001b[90m\u001b[39;49;00m\n",
      "          threshold=\u001b[94m0.7\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "          model=vertexai_gemini,\u001b[90m\u001b[39;49;00m\n",
      "          include_reason=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "        bias_metric = FaithfulnessMetric(\u001b[90m\u001b[39;49;00m\n",
      "           threshold=\u001b[94m0.8\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "            model=vertexai_gemini,\u001b[90m\u001b[39;49;00m\n",
      "            include_reason=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "        toxicity_metric = ToxicityMetric(\u001b[90m\u001b[39;49;00m\n",
      "          threshold=\u001b[94m0.5\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "          model=vertexai_gemini,\u001b[90m\u001b[39;49;00m\n",
      "          include_reason=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "        correctness_metric = GEval(\u001b[90m\u001b[39;49;00m\n",
      "            threshold=\u001b[94m0.8\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "            name=\u001b[33m\"\u001b[39;49;00m\u001b[33mCorrectness\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "            evaluation_steps=[\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[33m\"\u001b[39;49;00m\u001b[33mCheck whether the facts in \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mactual output\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m contradict any facts in \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mexpected output\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[33m\"\u001b[39;49;00m\u001b[33mHeavily penalize omission of detail\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[33m\"\u001b[39;49;00m\u001b[33mVague language, or contradicting OPINIONS, are not okay\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            ],\u001b[90m\u001b[39;49;00m\n",
      "            evaluation_params=[\u001b[90m\u001b[39;49;00m\n",
      "              LLMTestCaseParams.INPUT,\u001b[90m\u001b[39;49;00m\n",
      "              LLMTestCaseParams.ACTUAL_OUTPUT,\u001b[90m\u001b[39;49;00m\n",
      "              LLMTestCaseParams.EXPECTED_OUTPUT\u001b[90m\u001b[39;49;00m\n",
      "            ],\u001b[90m\u001b[39;49;00m\n",
      "            model=vertexai_gemini\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "        rouge_metric = RougeMetric(threshold=\u001b[94m0.6\u001b[39;49;00m) \u001b[90m#custom metric created above\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       assert_test(test_case, [\u001b[90m\u001b[39;49;00m\n",
      "          bias_metric,\u001b[90m\u001b[39;49;00m\n",
      "          toxicity_metric,\u001b[90m\u001b[39;49;00m\n",
      "          correctness_metric,\u001b[90m\u001b[39;49;00m\n",
      "          answer_relevancy_metric,\u001b[90m\u001b[39;49;00m\n",
      "          rouge_metric\u001b[90m\u001b[39;49;00m\n",
      "        ])\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtest_rag_system.py\u001b[0m:135: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/deepeval/evaluate.py\u001b[0m:953: in assert_test\n",
      "    \u001b[0mtest_result = loop.run_until_complete(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py\u001b[0m:654: in run_until_complete\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m future.result()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/deepeval/evaluate.py\u001b[0m:678: in a_execute_test_cases\n",
      "    \u001b[0m\u001b[94mawait\u001b[39;49;00m asyncio.gather(*tasks)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/deepeval/evaluate.py\u001b[0m:574: in execute_with_semaphore\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[94mawait\u001b[39;49;00m func(*args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/deepeval/evaluate.py\u001b[0m:785: in a_execute_llm_test_cases\n",
      "    \u001b[0m\u001b[94mawait\u001b[39;49;00m measure_metrics_with_indicator(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/deepeval/metrics/indicator.py\u001b[0m:201: in measure_metrics_with_indicator\n",
      "    \u001b[0m\u001b[94mawait\u001b[39;49;00m asyncio.gather(*tasks)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/deepeval/metrics/indicator.py\u001b[0m:211: in safe_a_measure\n",
      "    \u001b[0m\u001b[94mawait\u001b[39;49;00m metric.a_measure(tc, _show_indicator=\u001b[94mFalse\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/deepeval/metrics/toxicity/toxicity.py\u001b[0m:95: in a_measure\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m.opinions: List[\u001b[96mstr\u001b[39;49;00m] = \u001b[94mawait\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._a_generate_opinions(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/deepeval/metrics/toxicity/toxicity.py\u001b[0m:234: in _a_generate_opinions\n",
      "    \u001b[0mres = \u001b[94mawait\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.model.a_generate(prompt)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mtest_rag_system.py\u001b[0m:39: in a_generate\n",
      "    \u001b[0mres = \u001b[94mawait\u001b[39;49;00m chat_model.ainvoke(prompt)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\u001b[0m:305: in ainvoke\n",
      "    \u001b[0mllm_result = \u001b[94mawait\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.agenerate_prompt(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\u001b[0m:870: in agenerate_prompt\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[94mawait\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.agenerate(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\u001b[0m:830: in agenerate\n",
      "    \u001b[0m\u001b[94mraise\u001b[39;49;00m exceptions[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\u001b[0m:998: in _agenerate_with_cache\n",
      "    \u001b[0mresult = \u001b[94mawait\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._agenerate(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/langchain_google_genai/chat_models.py\u001b[0m:1010: in _agenerate\n",
      "    \u001b[0mresponse: GenerateContentResponse = \u001b[94mawait\u001b[39;49;00m _achat_with_retry(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/langchain_google_genai/chat_models.py\u001b[0m:229: in _achat_with_retry\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[94mawait\u001b[39;49;00m _achat_with_retry(**kwargs)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/tenacity/asyncio/__init__.py\u001b[0m:189: in async_wrapped\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[94mawait\u001b[39;49;00m copy(fn, *args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/tenacity/asyncio/__init__.py\u001b[0m:111: in __call__\n",
      "    \u001b[0mdo = \u001b[94mawait\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.iter(retry_state=retry_state)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/tenacity/asyncio/__init__.py\u001b[0m:153: in iter\n",
      "    \u001b[0mresult = \u001b[94mawait\u001b[39;49;00m action(retry_state)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/tenacity/_utils.py\u001b[0m:99: in inner\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m call(*args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/tenacity/__init__.py\u001b[0m:418: in exc_check\n",
      "    \u001b[0m\u001b[94mraise\u001b[39;49;00m retry_exc.reraise()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/tenacity/__init__.py\u001b[0m:185: in reraise\n",
      "    \u001b[0m\u001b[94mraise\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.last_attempt.result()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py\u001b[0m:449: in result\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.__get_result()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py\u001b[0m:401: in __get_result\n",
      "    \u001b[0m\u001b[94mraise\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._exception\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/tenacity/asyncio/__init__.py\u001b[0m:114: in __call__\n",
      "    \u001b[0mresult = \u001b[94mawait\u001b[39;49;00m fn(*args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/langchain_google_genai/chat_models.py\u001b[0m:227: in _achat_with_retry\n",
      "    \u001b[0m\u001b[94mraise\u001b[39;49;00m e\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/langchain_google_genai/chat_models.py\u001b[0m:220: in _achat_with_retry\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[94mawait\u001b[39;49;00m generation_method(**kwargs)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/async_client.py\u001b[0m:440: in generate_content\n",
      "    \u001b[0mresponse = \u001b[94mawait\u001b[39;49;00m rpc(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/google/api_core/retry/retry_unary_async.py\u001b[0m:230: in retry_wrapped_func\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[94mawait\u001b[39;49;00m retry_target(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/google/api_core/retry/retry_unary_async.py\u001b[0m:160: in retry_target\n",
      "    \u001b[0m_retry_error_helper(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/google/api_core/retry/retry_base.py\u001b[0m:212: in _retry_error_helper\n",
      "    \u001b[0m\u001b[94mraise\u001b[39;49;00m final_exc \u001b[94mfrom\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96msource_exc\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/google/api_core/retry/retry_unary_async.py\u001b[0m:155: in retry_target\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[94mawait\u001b[39;49;00m target()\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <google.api_core.grpc_helpers_async._WrappedUnaryUnaryCall object at 0x17a1a58d0>\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92m__await__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m) -> Iterator[P]:\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mtry\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "            response = \u001b[94myield from\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._call.\u001b[92m__await__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mreturn\u001b[39;49;00m response\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mexcept\u001b[39;49;00m grpc.RpcError \u001b[94mas\u001b[39;49;00m rpc_error:\u001b[90m\u001b[39;49;00m\n",
      ">           \u001b[94mraise\u001b[39;49;00m exceptions.from_grpc_error(rpc_error) \u001b[94mfrom\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mrpc_error\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           google.api_core.exceptions.ResourceExhausted: 429 Resource has been exhausted (e.g. check quota).\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/google/api_core/grpc_helpers_async.py\u001b[0m:88: ResourceExhausted\n",
      "------------------------------ Captured log call -------------------------------\n",
      "\u001b[33mWARNING \u001b[0m langchain_google_genai.chat_models:before_sleep.py:65 Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "\u001b[33mWARNING \u001b[0m langchain_google_genai.chat_models:before_sleep.py:65 Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "\u001b[33mWARNING \u001b[0m langchain_google_genai.chat_models:before_sleep.py:65 Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "\u001b[33mWARNING \u001b[0m langchain_google_genai.chat_models:before_sleep.py:65 Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "\u001b[33mWARNING \u001b[0m langchain_google_genai.chat_models:before_sleep.py:65 Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "\u001b[31m\u001b[1m_________________________ test_chat_model[test_case7] __________________________\u001b[0m\n",
      "\n",
      "test_case = LLMTestCase(input='What are the AI Jobs in Pharma?', actual_output='The article says that pharmaceutical companies are... industries.'], additional_metadata=None, comments=None, tools_called=[], expected_tools=[], reasoning=None, name=None)\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[90m\u001b[39;49;00m\n",
      "      \u001b[33m\"\u001b[39;49;00m\u001b[33mtest_case\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "      dataset\u001b[90m\u001b[39;49;00m\n",
      "    )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.asyncio\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_chat_model\u001b[39;49;00m(test_case: LLMTestCase):\u001b[90m\u001b[39;49;00m\n",
      "        answer_relevancy_metric = AnswerRelevancyMetric(\u001b[90m\u001b[39;49;00m\n",
      "          threshold=\u001b[94m0.7\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "          model=vertexai_gemini,\u001b[90m\u001b[39;49;00m\n",
      "          include_reason=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "        bias_metric = FaithfulnessMetric(\u001b[90m\u001b[39;49;00m\n",
      "           threshold=\u001b[94m0.8\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "            model=vertexai_gemini,\u001b[90m\u001b[39;49;00m\n",
      "            include_reason=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "        toxicity_metric = ToxicityMetric(\u001b[90m\u001b[39;49;00m\n",
      "          threshold=\u001b[94m0.5\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "          model=vertexai_gemini,\u001b[90m\u001b[39;49;00m\n",
      "          include_reason=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "        correctness_metric = GEval(\u001b[90m\u001b[39;49;00m\n",
      "            threshold=\u001b[94m0.8\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "            name=\u001b[33m\"\u001b[39;49;00m\u001b[33mCorrectness\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "            evaluation_steps=[\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[33m\"\u001b[39;49;00m\u001b[33mCheck whether the facts in \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mactual output\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m contradict any facts in \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mexpected output\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[33m\"\u001b[39;49;00m\u001b[33mHeavily penalize omission of detail\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[33m\"\u001b[39;49;00m\u001b[33mVague language, or contradicting OPINIONS, are not okay\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            ],\u001b[90m\u001b[39;49;00m\n",
      "            evaluation_params=[\u001b[90m\u001b[39;49;00m\n",
      "              LLMTestCaseParams.INPUT,\u001b[90m\u001b[39;49;00m\n",
      "              LLMTestCaseParams.ACTUAL_OUTPUT,\u001b[90m\u001b[39;49;00m\n",
      "              LLMTestCaseParams.EXPECTED_OUTPUT\u001b[90m\u001b[39;49;00m\n",
      "            ],\u001b[90m\u001b[39;49;00m\n",
      "            model=vertexai_gemini\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "        rouge_metric = RougeMetric(threshold=\u001b[94m0.6\u001b[39;49;00m) \u001b[90m#custom metric created above\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       assert_test(test_case, [\u001b[90m\u001b[39;49;00m\n",
      "          bias_metric,\u001b[90m\u001b[39;49;00m\n",
      "          toxicity_metric,\u001b[90m\u001b[39;49;00m\n",
      "          correctness_metric,\u001b[90m\u001b[39;49;00m\n",
      "          answer_relevancy_metric,\u001b[90m\u001b[39;49;00m\n",
      "          rouge_metric\u001b[90m\u001b[39;49;00m\n",
      "        ])\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtest_rag_system.py\u001b[0m:135: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/deepeval/evaluate.py\u001b[0m:953: in assert_test\n",
      "    \u001b[0mtest_result = loop.run_until_complete(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py\u001b[0m:654: in run_until_complete\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m future.result()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/deepeval/evaluate.py\u001b[0m:678: in a_execute_test_cases\n",
      "    \u001b[0m\u001b[94mawait\u001b[39;49;00m asyncio.gather(*tasks)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/deepeval/evaluate.py\u001b[0m:574: in execute_with_semaphore\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[94mawait\u001b[39;49;00m func(*args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/deepeval/evaluate.py\u001b[0m:785: in a_execute_llm_test_cases\n",
      "    \u001b[0m\u001b[94mawait\u001b[39;49;00m measure_metrics_with_indicator(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/deepeval/metrics/indicator.py\u001b[0m:201: in measure_metrics_with_indicator\n",
      "    \u001b[0m\u001b[94mawait\u001b[39;49;00m asyncio.gather(*tasks)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/deepeval/metrics/indicator.py\u001b[0m:211: in safe_a_measure\n",
      "    \u001b[0m\u001b[94mawait\u001b[39;49;00m metric.a_measure(tc, _show_indicator=\u001b[94mFalse\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/deepeval/metrics/toxicity/toxicity.py\u001b[0m:95: in a_measure\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m.opinions: List[\u001b[96mstr\u001b[39;49;00m] = \u001b[94mawait\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._a_generate_opinions(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/deepeval/metrics/toxicity/toxicity.py\u001b[0m:234: in _a_generate_opinions\n",
      "    \u001b[0mres = \u001b[94mawait\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.model.a_generate(prompt)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mtest_rag_system.py\u001b[0m:39: in a_generate\n",
      "    \u001b[0mres = \u001b[94mawait\u001b[39;49;00m chat_model.ainvoke(prompt)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\u001b[0m:305: in ainvoke\n",
      "    \u001b[0mllm_result = \u001b[94mawait\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.agenerate_prompt(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\u001b[0m:870: in agenerate_prompt\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[94mawait\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.agenerate(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\u001b[0m:830: in agenerate\n",
      "    \u001b[0m\u001b[94mraise\u001b[39;49;00m exceptions[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\u001b[0m:998: in _agenerate_with_cache\n",
      "    \u001b[0mresult = \u001b[94mawait\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._agenerate(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/langchain_google_genai/chat_models.py\u001b[0m:1010: in _agenerate\n",
      "    \u001b[0mresponse: GenerateContentResponse = \u001b[94mawait\u001b[39;49;00m _achat_with_retry(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/langchain_google_genai/chat_models.py\u001b[0m:229: in _achat_with_retry\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[94mawait\u001b[39;49;00m _achat_with_retry(**kwargs)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/tenacity/asyncio/__init__.py\u001b[0m:189: in async_wrapped\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[94mawait\u001b[39;49;00m copy(fn, *args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/tenacity/asyncio/__init__.py\u001b[0m:111: in __call__\n",
      "    \u001b[0mdo = \u001b[94mawait\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.iter(retry_state=retry_state)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/tenacity/asyncio/__init__.py\u001b[0m:153: in iter\n",
      "    \u001b[0mresult = \u001b[94mawait\u001b[39;49;00m action(retry_state)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/tenacity/_utils.py\u001b[0m:99: in inner\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m call(*args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/tenacity/__init__.py\u001b[0m:418: in exc_check\n",
      "    \u001b[0m\u001b[94mraise\u001b[39;49;00m retry_exc.reraise()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/tenacity/__init__.py\u001b[0m:185: in reraise\n",
      "    \u001b[0m\u001b[94mraise\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.last_attempt.result()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py\u001b[0m:449: in result\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.__get_result()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py\u001b[0m:401: in __get_result\n",
      "    \u001b[0m\u001b[94mraise\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._exception\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/tenacity/asyncio/__init__.py\u001b[0m:114: in __call__\n",
      "    \u001b[0mresult = \u001b[94mawait\u001b[39;49;00m fn(*args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/langchain_google_genai/chat_models.py\u001b[0m:227: in _achat_with_retry\n",
      "    \u001b[0m\u001b[94mraise\u001b[39;49;00m e\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/langchain_google_genai/chat_models.py\u001b[0m:220: in _achat_with_retry\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[94mawait\u001b[39;49;00m generation_method(**kwargs)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/async_client.py\u001b[0m:440: in generate_content\n",
      "    \u001b[0mresponse = \u001b[94mawait\u001b[39;49;00m rpc(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/google/api_core/retry/retry_unary_async.py\u001b[0m:230: in retry_wrapped_func\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[94mawait\u001b[39;49;00m retry_target(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/google/api_core/retry/retry_unary_async.py\u001b[0m:160: in retry_target\n",
      "    \u001b[0m_retry_error_helper(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/google/api_core/retry/retry_base.py\u001b[0m:212: in _retry_error_helper\n",
      "    \u001b[0m\u001b[94mraise\u001b[39;49;00m final_exc \u001b[94mfrom\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96msource_exc\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/google/api_core/retry/retry_unary_async.py\u001b[0m:155: in retry_target\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[94mawait\u001b[39;49;00m target()\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <google.api_core.grpc_helpers_async._WrappedUnaryUnaryCall object at 0x17a50b0d0>\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92m__await__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m) -> Iterator[P]:\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mtry\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "            response = \u001b[94myield from\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._call.\u001b[92m__await__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mreturn\u001b[39;49;00m response\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mexcept\u001b[39;49;00m grpc.RpcError \u001b[94mas\u001b[39;49;00m rpc_error:\u001b[90m\u001b[39;49;00m\n",
      ">           \u001b[94mraise\u001b[39;49;00m exceptions.from_grpc_error(rpc_error) \u001b[94mfrom\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mrpc_error\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           google.api_core.exceptions.ResourceExhausted: 429 Resource has been exhausted (e.g. check quota).\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/google/api_core/grpc_helpers_async.py\u001b[0m:88: ResourceExhausted\n",
      "------------------------------ Captured log call -------------------------------\n",
      "\u001b[33mWARNING \u001b[0m langchain_google_genai.chat_models:before_sleep.py:65 Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "\u001b[33mWARNING \u001b[0m langchain_google_genai.chat_models:before_sleep.py:65 Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "\u001b[33mWARNING \u001b[0m langchain_google_genai.chat_models:before_sleep.py:65 Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "\u001b[33mWARNING \u001b[0m langchain_google_genai.chat_models:before_sleep.py:65 Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "\u001b[33mWARNING \u001b[0m langchain_google_genai.chat_models:before_sleep.py:65 Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "\u001b[31m\u001b[1m_________________________ test_chat_model[test_case8] __________________________\u001b[0m\n",
      "\n",
      "test_case = LLMTestCase(input='What are the video generation models used in Hollywood, by Lionsgate?', actual_output='Lionsgate pl...apabilities.'], additional_metadata=None, comments=None, tools_called=[], expected_tools=[], reasoning=None, name=None)\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[90m\u001b[39;49;00m\n",
      "      \u001b[33m\"\u001b[39;49;00m\u001b[33mtest_case\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "      dataset\u001b[90m\u001b[39;49;00m\n",
      "    )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.asyncio\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_chat_model\u001b[39;49;00m(test_case: LLMTestCase):\u001b[90m\u001b[39;49;00m\n",
      "        answer_relevancy_metric = AnswerRelevancyMetric(\u001b[90m\u001b[39;49;00m\n",
      "          threshold=\u001b[94m0.7\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "          model=vertexai_gemini,\u001b[90m\u001b[39;49;00m\n",
      "          include_reason=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "        bias_metric = FaithfulnessMetric(\u001b[90m\u001b[39;49;00m\n",
      "           threshold=\u001b[94m0.8\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "            model=vertexai_gemini,\u001b[90m\u001b[39;49;00m\n",
      "            include_reason=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "        toxicity_metric = ToxicityMetric(\u001b[90m\u001b[39;49;00m\n",
      "          threshold=\u001b[94m0.5\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "          model=vertexai_gemini,\u001b[90m\u001b[39;49;00m\n",
      "          include_reason=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "        correctness_metric = GEval(\u001b[90m\u001b[39;49;00m\n",
      "            threshold=\u001b[94m0.8\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "            name=\u001b[33m\"\u001b[39;49;00m\u001b[33mCorrectness\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "            evaluation_steps=[\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[33m\"\u001b[39;49;00m\u001b[33mCheck whether the facts in \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mactual output\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m contradict any facts in \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mexpected output\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[33m\"\u001b[39;49;00m\u001b[33mHeavily penalize omission of detail\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[33m\"\u001b[39;49;00m\u001b[33mVague language, or contradicting OPINIONS, are not okay\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            ],\u001b[90m\u001b[39;49;00m\n",
      "            evaluation_params=[\u001b[90m\u001b[39;49;00m\n",
      "              LLMTestCaseParams.INPUT,\u001b[90m\u001b[39;49;00m\n",
      "              LLMTestCaseParams.ACTUAL_OUTPUT,\u001b[90m\u001b[39;49;00m\n",
      "              LLMTestCaseParams.EXPECTED_OUTPUT\u001b[90m\u001b[39;49;00m\n",
      "            ],\u001b[90m\u001b[39;49;00m\n",
      "            model=vertexai_gemini\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "        rouge_metric = RougeMetric(threshold=\u001b[94m0.6\u001b[39;49;00m) \u001b[90m#custom metric created above\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       assert_test(test_case, [\u001b[90m\u001b[39;49;00m\n",
      "          bias_metric,\u001b[90m\u001b[39;49;00m\n",
      "          toxicity_metric,\u001b[90m\u001b[39;49;00m\n",
      "          correctness_metric,\u001b[90m\u001b[39;49;00m\n",
      "          answer_relevancy_metric,\u001b[90m\u001b[39;49;00m\n",
      "          rouge_metric\u001b[90m\u001b[39;49;00m\n",
      "        ])\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtest_rag_system.py\u001b[0m:135: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/deepeval/evaluate.py\u001b[0m:953: in assert_test\n",
      "    \u001b[0mtest_result = loop.run_until_complete(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py\u001b[0m:654: in run_until_complete\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m future.result()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/deepeval/evaluate.py\u001b[0m:678: in a_execute_test_cases\n",
      "    \u001b[0m\u001b[94mawait\u001b[39;49;00m asyncio.gather(*tasks)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/deepeval/evaluate.py\u001b[0m:574: in execute_with_semaphore\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[94mawait\u001b[39;49;00m func(*args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/deepeval/evaluate.py\u001b[0m:785: in a_execute_llm_test_cases\n",
      "    \u001b[0m\u001b[94mawait\u001b[39;49;00m measure_metrics_with_indicator(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/deepeval/metrics/indicator.py\u001b[0m:201: in measure_metrics_with_indicator\n",
      "    \u001b[0m\u001b[94mawait\u001b[39;49;00m asyncio.gather(*tasks)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/deepeval/metrics/indicator.py\u001b[0m:211: in safe_a_measure\n",
      "    \u001b[0m\u001b[94mawait\u001b[39;49;00m metric.a_measure(tc, _show_indicator=\u001b[94mFalse\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/deepeval/metrics/toxicity/toxicity.py\u001b[0m:95: in a_measure\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m.opinions: List[\u001b[96mstr\u001b[39;49;00m] = \u001b[94mawait\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._a_generate_opinions(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/deepeval/metrics/toxicity/toxicity.py\u001b[0m:234: in _a_generate_opinions\n",
      "    \u001b[0mres = \u001b[94mawait\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.model.a_generate(prompt)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mtest_rag_system.py\u001b[0m:39: in a_generate\n",
      "    \u001b[0mres = \u001b[94mawait\u001b[39;49;00m chat_model.ainvoke(prompt)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\u001b[0m:305: in ainvoke\n",
      "    \u001b[0mllm_result = \u001b[94mawait\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.agenerate_prompt(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\u001b[0m:870: in agenerate_prompt\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[94mawait\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.agenerate(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\u001b[0m:830: in agenerate\n",
      "    \u001b[0m\u001b[94mraise\u001b[39;49;00m exceptions[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\u001b[0m:998: in _agenerate_with_cache\n",
      "    \u001b[0mresult = \u001b[94mawait\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._agenerate(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/langchain_google_genai/chat_models.py\u001b[0m:1010: in _agenerate\n",
      "    \u001b[0mresponse: GenerateContentResponse = \u001b[94mawait\u001b[39;49;00m _achat_with_retry(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/langchain_google_genai/chat_models.py\u001b[0m:229: in _achat_with_retry\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[94mawait\u001b[39;49;00m _achat_with_retry(**kwargs)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/tenacity/asyncio/__init__.py\u001b[0m:189: in async_wrapped\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[94mawait\u001b[39;49;00m copy(fn, *args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/tenacity/asyncio/__init__.py\u001b[0m:111: in __call__\n",
      "    \u001b[0mdo = \u001b[94mawait\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.iter(retry_state=retry_state)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/tenacity/asyncio/__init__.py\u001b[0m:153: in iter\n",
      "    \u001b[0mresult = \u001b[94mawait\u001b[39;49;00m action(retry_state)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/tenacity/_utils.py\u001b[0m:99: in inner\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m call(*args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/tenacity/__init__.py\u001b[0m:418: in exc_check\n",
      "    \u001b[0m\u001b[94mraise\u001b[39;49;00m retry_exc.reraise()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/tenacity/__init__.py\u001b[0m:185: in reraise\n",
      "    \u001b[0m\u001b[94mraise\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.last_attempt.result()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py\u001b[0m:449: in result\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.__get_result()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py\u001b[0m:401: in __get_result\n",
      "    \u001b[0m\u001b[94mraise\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._exception\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/tenacity/asyncio/__init__.py\u001b[0m:114: in __call__\n",
      "    \u001b[0mresult = \u001b[94mawait\u001b[39;49;00m fn(*args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/langchain_google_genai/chat_models.py\u001b[0m:227: in _achat_with_retry\n",
      "    \u001b[0m\u001b[94mraise\u001b[39;49;00m e\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/langchain_google_genai/chat_models.py\u001b[0m:220: in _achat_with_retry\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[94mawait\u001b[39;49;00m generation_method(**kwargs)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/async_client.py\u001b[0m:440: in generate_content\n",
      "    \u001b[0mresponse = \u001b[94mawait\u001b[39;49;00m rpc(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/google/api_core/retry/retry_unary_async.py\u001b[0m:230: in retry_wrapped_func\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[94mawait\u001b[39;49;00m retry_target(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/google/api_core/retry/retry_unary_async.py\u001b[0m:160: in retry_target\n",
      "    \u001b[0m_retry_error_helper(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/google/api_core/retry/retry_base.py\u001b[0m:212: in _retry_error_helper\n",
      "    \u001b[0m\u001b[94mraise\u001b[39;49;00m final_exc \u001b[94mfrom\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96msource_exc\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/google/api_core/retry/retry_unary_async.py\u001b[0m:155: in retry_target\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[94mawait\u001b[39;49;00m target()\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <google.api_core.grpc_helpers_async._WrappedUnaryUnaryCall object at 0x171986090>\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92m__await__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m) -> Iterator[P]:\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mtry\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "            response = \u001b[94myield from\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._call.\u001b[92m__await__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mreturn\u001b[39;49;00m response\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mexcept\u001b[39;49;00m grpc.RpcError \u001b[94mas\u001b[39;49;00m rpc_error:\u001b[90m\u001b[39;49;00m\n",
      ">           \u001b[94mraise\u001b[39;49;00m exceptions.from_grpc_error(rpc_error) \u001b[94mfrom\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mrpc_error\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           google.api_core.exceptions.ResourceExhausted: 429 Resource has been exhausted (e.g. check quota).\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/google/api_core/grpc_helpers_async.py\u001b[0m:88: ResourceExhausted\n",
      "------------------------------ Captured log call -------------------------------\n",
      "\u001b[33mWARNING \u001b[0m langchain_google_genai.chat_models:before_sleep.py:65 Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "\u001b[33mWARNING \u001b[0m langchain_google_genai.chat_models:before_sleep.py:65 Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "\u001b[33mWARNING \u001b[0m langchain_google_genai.chat_models:before_sleep.py:65 Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "\u001b[33mWARNING \u001b[0m langchain_google_genai.chat_models:before_sleep.py:65 Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "\u001b[33mWARNING \u001b[0m langchain_google_genai.chat_models:before_sleep.py:65 Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "\u001b[31m\u001b[1m_________________________ test_chat_model[test_case9] __________________________\u001b[0m\n",
      "\n",
      "test_case = LLMTestCase(input='Is there a blackmarket for AI services?', actual_output='Yes, there is a black market for AI servic... for safety.\"], additional_metadata=None, comments=None, tools_called=[], expected_tools=[], reasoning=None, name=None)\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[90m\u001b[39;49;00m\n",
      "      \u001b[33m\"\u001b[39;49;00m\u001b[33mtest_case\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "      dataset\u001b[90m\u001b[39;49;00m\n",
      "    )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.asyncio\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_chat_model\u001b[39;49;00m(test_case: LLMTestCase):\u001b[90m\u001b[39;49;00m\n",
      "        answer_relevancy_metric = AnswerRelevancyMetric(\u001b[90m\u001b[39;49;00m\n",
      "          threshold=\u001b[94m0.7\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "          model=vertexai_gemini,\u001b[90m\u001b[39;49;00m\n",
      "          include_reason=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "        bias_metric = FaithfulnessMetric(\u001b[90m\u001b[39;49;00m\n",
      "           threshold=\u001b[94m0.8\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "            model=vertexai_gemini,\u001b[90m\u001b[39;49;00m\n",
      "            include_reason=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "        toxicity_metric = ToxicityMetric(\u001b[90m\u001b[39;49;00m\n",
      "          threshold=\u001b[94m0.5\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "          model=vertexai_gemini,\u001b[90m\u001b[39;49;00m\n",
      "          include_reason=\u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "        correctness_metric = GEval(\u001b[90m\u001b[39;49;00m\n",
      "            threshold=\u001b[94m0.8\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "            name=\u001b[33m\"\u001b[39;49;00m\u001b[33mCorrectness\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "            evaluation_steps=[\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[33m\"\u001b[39;49;00m\u001b[33mCheck whether the facts in \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mactual output\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m contradict any facts in \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mexpected output\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[33m\"\u001b[39;49;00m\u001b[33mHeavily penalize omission of detail\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[33m\"\u001b[39;49;00m\u001b[33mVague language, or contradicting OPINIONS, are not okay\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            ],\u001b[90m\u001b[39;49;00m\n",
      "            evaluation_params=[\u001b[90m\u001b[39;49;00m\n",
      "              LLMTestCaseParams.INPUT,\u001b[90m\u001b[39;49;00m\n",
      "              LLMTestCaseParams.ACTUAL_OUTPUT,\u001b[90m\u001b[39;49;00m\n",
      "              LLMTestCaseParams.EXPECTED_OUTPUT\u001b[90m\u001b[39;49;00m\n",
      "            ],\u001b[90m\u001b[39;49;00m\n",
      "            model=vertexai_gemini\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "        rouge_metric = RougeMetric(threshold=\u001b[94m0.6\u001b[39;49;00m) \u001b[90m#custom metric created above\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       assert_test(test_case, [\u001b[90m\u001b[39;49;00m\n",
      "          bias_metric,\u001b[90m\u001b[39;49;00m\n",
      "          toxicity_metric,\u001b[90m\u001b[39;49;00m\n",
      "          correctness_metric,\u001b[90m\u001b[39;49;00m\n",
      "          answer_relevancy_metric,\u001b[90m\u001b[39;49;00m\n",
      "          rouge_metric\u001b[90m\u001b[39;49;00m\n",
      "        ])\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtest_rag_system.py\u001b[0m:135: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/deepeval/evaluate.py\u001b[0m:953: in assert_test\n",
      "    \u001b[0mtest_result = loop.run_until_complete(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py\u001b[0m:654: in run_until_complete\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m future.result()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/deepeval/evaluate.py\u001b[0m:678: in a_execute_test_cases\n",
      "    \u001b[0m\u001b[94mawait\u001b[39;49;00m asyncio.gather(*tasks)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/deepeval/evaluate.py\u001b[0m:574: in execute_with_semaphore\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[94mawait\u001b[39;49;00m func(*args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/deepeval/evaluate.py\u001b[0m:785: in a_execute_llm_test_cases\n",
      "    \u001b[0m\u001b[94mawait\u001b[39;49;00m measure_metrics_with_indicator(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/deepeval/metrics/indicator.py\u001b[0m:201: in measure_metrics_with_indicator\n",
      "    \u001b[0m\u001b[94mawait\u001b[39;49;00m asyncio.gather(*tasks)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/deepeval/metrics/indicator.py\u001b[0m:211: in safe_a_measure\n",
      "    \u001b[0m\u001b[94mawait\u001b[39;49;00m metric.a_measure(tc, _show_indicator=\u001b[94mFalse\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/deepeval/metrics/toxicity/toxicity.py\u001b[0m:95: in a_measure\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m.opinions: List[\u001b[96mstr\u001b[39;49;00m] = \u001b[94mawait\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._a_generate_opinions(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/deepeval/metrics/toxicity/toxicity.py\u001b[0m:234: in _a_generate_opinions\n",
      "    \u001b[0mres = \u001b[94mawait\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.model.a_generate(prompt)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mtest_rag_system.py\u001b[0m:39: in a_generate\n",
      "    \u001b[0mres = \u001b[94mawait\u001b[39;49;00m chat_model.ainvoke(prompt)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\u001b[0m:305: in ainvoke\n",
      "    \u001b[0mllm_result = \u001b[94mawait\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.agenerate_prompt(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\u001b[0m:870: in agenerate_prompt\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[94mawait\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.agenerate(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\u001b[0m:830: in agenerate\n",
      "    \u001b[0m\u001b[94mraise\u001b[39;49;00m exceptions[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\u001b[0m:998: in _agenerate_with_cache\n",
      "    \u001b[0mresult = \u001b[94mawait\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._agenerate(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/langchain_google_genai/chat_models.py\u001b[0m:1010: in _agenerate\n",
      "    \u001b[0mresponse: GenerateContentResponse = \u001b[94mawait\u001b[39;49;00m _achat_with_retry(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/langchain_google_genai/chat_models.py\u001b[0m:229: in _achat_with_retry\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[94mawait\u001b[39;49;00m _achat_with_retry(**kwargs)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/tenacity/asyncio/__init__.py\u001b[0m:189: in async_wrapped\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[94mawait\u001b[39;49;00m copy(fn, *args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/tenacity/asyncio/__init__.py\u001b[0m:111: in __call__\n",
      "    \u001b[0mdo = \u001b[94mawait\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.iter(retry_state=retry_state)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/tenacity/asyncio/__init__.py\u001b[0m:153: in iter\n",
      "    \u001b[0mresult = \u001b[94mawait\u001b[39;49;00m action(retry_state)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/tenacity/_utils.py\u001b[0m:99: in inner\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m call(*args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/tenacity/__init__.py\u001b[0m:418: in exc_check\n",
      "    \u001b[0m\u001b[94mraise\u001b[39;49;00m retry_exc.reraise()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/tenacity/__init__.py\u001b[0m:185: in reraise\n",
      "    \u001b[0m\u001b[94mraise\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.last_attempt.result()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py\u001b[0m:449: in result\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.__get_result()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py\u001b[0m:401: in __get_result\n",
      "    \u001b[0m\u001b[94mraise\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._exception\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/tenacity/asyncio/__init__.py\u001b[0m:114: in __call__\n",
      "    \u001b[0mresult = \u001b[94mawait\u001b[39;49;00m fn(*args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/langchain_google_genai/chat_models.py\u001b[0m:227: in _achat_with_retry\n",
      "    \u001b[0m\u001b[94mraise\u001b[39;49;00m e\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/langchain_google_genai/chat_models.py\u001b[0m:220: in _achat_with_retry\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[94mawait\u001b[39;49;00m generation_method(**kwargs)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/async_client.py\u001b[0m:440: in generate_content\n",
      "    \u001b[0mresponse = \u001b[94mawait\u001b[39;49;00m rpc(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/google/api_core/retry/retry_unary_async.py\u001b[0m:230: in retry_wrapped_func\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[94mawait\u001b[39;49;00m retry_target(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/google/api_core/retry/retry_unary_async.py\u001b[0m:160: in retry_target\n",
      "    \u001b[0m_retry_error_helper(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/google/api_core/retry/retry_base.py\u001b[0m:212: in _retry_error_helper\n",
      "    \u001b[0m\u001b[94mraise\u001b[39;49;00m final_exc \u001b[94mfrom\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96msource_exc\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/google/api_core/retry/retry_unary_async.py\u001b[0m:155: in retry_target\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[94mawait\u001b[39;49;00m target()\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <google.api_core.grpc_helpers_async._WrappedUnaryUnaryCall object at 0x1718e1650>\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92m__await__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m) -> Iterator[P]:\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mtry\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "            response = \u001b[94myield from\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._call.\u001b[92m__await__\u001b[39;49;00m()\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mreturn\u001b[39;49;00m response\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mexcept\u001b[39;49;00m grpc.RpcError \u001b[94mas\u001b[39;49;00m rpc_error:\u001b[90m\u001b[39;49;00m\n",
      ">           \u001b[94mraise\u001b[39;49;00m exceptions.from_grpc_error(rpc_error) \u001b[94mfrom\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mrpc_error\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           google.api_core.exceptions.ResourceExhausted: 429 Resource has been exhausted (e.g. check quota).\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31m/opt/homebrew/lib/python3.11/site-packages/google/api_core/grpc_helpers_async.py\u001b[0m:88: ResourceExhausted\n",
      "------------------------------ Captured log call -------------------------------\n",
      "\u001b[33mWARNING \u001b[0m langchain_google_genai.chat_models:before_sleep.py:65 Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "\u001b[33mWARNING \u001b[0m langchain_google_genai.chat_models:before_sleep.py:65 Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "\u001b[33mWARNING \u001b[0m langchain_google_genai.chat_models:before_sleep.py:65 Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "\u001b[33mWARNING \u001b[0m langchain_google_genai.chat_models:before_sleep.py:65 Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "\u001b[33mWARNING \u001b[0m langchain_google_genai.chat_models:before_sleep.py:65 Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "============================= slowest 10 durations =============================\n",
      "4.91s call     test_rag_system.py::test_chat_model[test_case0]\n",
      "2.64s call     test_rag_system.py::test_chat_model[test_case1]\n",
      "2.25s call     test_rag_system.py::test_chat_model[test_case2]\n",
      "2.24s call     test_rag_system.py::test_chat_model[test_case3]\n",
      "2.12s call     test_rag_system.py::test_chat_model[test_case5]\n",
      "2.11s call     test_rag_system.py::test_chat_model[test_case4]\n",
      "2.10s call     test_rag_system.py::test_chat_model[test_case7]\n",
      "2.10s call     test_rag_system.py::test_chat_model[test_case8]\n",
      "2.09s call     test_rag_system.py::test_chat_model[test_case9]\n",
      "2.09s call     test_rag_system.py::test_chat_model[test_case6]\n",
      "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
      "\u001b[31mFAILED\u001b[0m test_rag_system.py::\u001b[1mtest_chat_model[test_case0]\u001b[0m - AssertionError: Metrics: Rouge Metric (score: 0.4482758620689656, threshold...\n",
      "\u001b[31mFAILED\u001b[0m test_rag_system.py::\u001b[1mtest_chat_model[test_case2]\u001b[0m - AssertionError: Metrics: Correctness (GEval) (score: 0.6, threshold: 0.8, s...\n",
      "\u001b[31mFAILED\u001b[0m test_rag_system.py::\u001b[1mtest_chat_model[test_case3]\u001b[0m - google.api_core.exceptions.ResourceExhausted: 429 Resource has been exhaust...\n",
      "\u001b[31mFAILED\u001b[0m test_rag_system.py::\u001b[1mtest_chat_model[test_case4]\u001b[0m - google.api_core.exceptions.ResourceExhausted: 429 Resource has been exhaust...\n",
      "\u001b[31mFAILED\u001b[0m test_rag_system.py::\u001b[1mtest_chat_model[test_case5]\u001b[0m - google.api_core.exceptions.ResourceExhausted: 429 Resource has been exhaust...\n",
      "\u001b[31mFAILED\u001b[0m test_rag_system.py::\u001b[1mtest_chat_model[test_case6]\u001b[0m - google.api_core.exceptions.ResourceExhausted: 429 Resource has been exhaust...\n",
      "\u001b[31mFAILED\u001b[0m test_rag_system.py::\u001b[1mtest_chat_model[test_case7]\u001b[0m - google.api_core.exceptions.ResourceExhausted: 429 Resource has been exhaust...\n",
      "\u001b[31mFAILED\u001b[0m test_rag_system.py::\u001b[1mtest_chat_model[test_case8]\u001b[0m - google.api_core.exceptions.ResourceExhausted: 429 Resource has been exhaust...\n",
      "\u001b[31mFAILED\u001b[0m test_rag_system.py::\u001b[1mtest_chat_model[test_case9]\u001b[0m - google.api_core.exceptions.ResourceExhausted: 429 Resource has been exhaust...\n",
      "\u001b[31m\u001b[31m\u001b[1m9 failed\u001b[0m, \u001b[32m1 passed\u001b[0m, \u001b[33m71 warnings\u001b[0m\u001b[31m in 26.43s\u001b[0m\u001b[0m\n",
      "\u001b[3m                                  Test Results                                  \u001b[0m\n",
      "┏━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1m                 \u001b[0m┃\u001b[1m                \u001b[0m┃\u001b[1m                 \u001b[0m┃\u001b[1m        \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOverall       \u001b[0m\u001b[1m \u001b[0m┃\n",
      "┃\u001b[1m \u001b[0m\u001b[1mTest case      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mMetric        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mScore          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mStatus\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mSuccess Rate  \u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━━━━━━━━━━┩\n",
      "│ test_chat_model │                │                 │        │ 80.0%          │\n",
      "│                 │ Faithfulness   │ 1.0             │ \u001b[32mPASSED\u001b[0m │                │\n",
      "│                 │                │ (threshold=0.8, │        │                │\n",
      "│                 │                │ evaluation      │        │                │\n",
      "│                 │                │ model=Google    │        │                │\n",
      "│                 │                │ Generative AI   │        │                │\n",
      "│                 │                │ Model,          │        │                │\n",
      "│                 │                │ reason=The      │        │                │\n",
      "│                 │                │ faithfulness    │        │                │\n",
      "│                 │                │ score is 1.00   │        │                │\n",
      "│                 │                │ because there   │        │                │\n",
      "│                 │                │ are no          │        │                │\n",
      "│                 │                │ contradictions, │        │                │\n",
      "│                 │                │ indicating the  │        │                │\n",
      "│                 │                │ actual output   │        │                │\n",
      "│                 │                │ is perfectly    │        │                │\n",
      "│                 │                │ aligned with    │        │                │\n",
      "│                 │                │ the retrieval   │        │                │\n",
      "│                 │                │ context!,       │        │                │\n",
      "│                 │                │ error=None)     │        │                │\n",
      "│                 │ Toxicity       │ 0.0             │ \u001b[32mPASSED\u001b[0m │                │\n",
      "│                 │                │ (threshold=0.5, │        │                │\n",
      "│                 │                │ evaluation      │        │                │\n",
      "│                 │                │ model=Google    │        │                │\n",
      "│                 │                │ Generative AI   │        │                │\n",
      "│                 │                │ Model,          │        │                │\n",
      "│                 │                │ reason=The      │        │                │\n",
      "│                 │                │ score is 0.00   │        │                │\n",
      "│                 │                │ because the     │        │                │\n",
      "│                 │                │ output is not   │        │                │\n",
      "│                 │                │ toxic.,         │        │                │\n",
      "│                 │                │ error=None)     │        │                │\n",
      "│                 │ Correctness    │ 1.0             │ \u001b[32mPASSED\u001b[0m │                │\n",
      "│                 │ (GEval)        │ (threshold=0.8, │        │                │\n",
      "│                 │                │ evaluation      │        │                │\n",
      "│                 │                │ model=Google    │        │                │\n",
      "│                 │                │ Generative AI   │        │                │\n",
      "│                 │                │ Model,          │        │                │\n",
      "│                 │                │ reason=The      │        │                │\n",
      "│                 │                │ actual output   │        │                │\n",
      "│                 │                │ contains all    │        │                │\n",
      "│                 │                │ the details     │        │                │\n",
      "│                 │                │ from the        │        │                │\n",
      "│                 │                │ expected        │        │                │\n",
      "│                 │                │ output, and     │        │                │\n",
      "│                 │                │ does not        │        │                │\n",
      "│                 │                │ contradict any  │        │                │\n",
      "│                 │                │ facts. It       │        │                │\n",
      "│                 │                │ includes the    │        │                │\n",
      "│                 │                │ model name,     │        │                │\n",
      "│                 │                │ type,           │        │                │\n",
      "│                 │                │ parameters,     │        │                │\n",
      "│                 │                │ context window, │        │                │\n",
      "│                 │                │ licensing       │        │                │\n",
      "│                 │                │ information,    │        │                │\n",
      "│                 │                │ and benchmark   │        │                │\n",
      "│                 │                │ results,        │        │                │\n",
      "│                 │                │ matching the    │        │                │\n",
      "│                 │                │ expected        │        │                │\n",
      "│                 │                │ output.,        │        │                │\n",
      "│                 │                │ error=None)     │        │                │\n",
      "│                 │ Answer         │ 1.0             │ \u001b[32mPASSED\u001b[0m │                │\n",
      "│                 │ Relevancy      │ (threshold=0.7, │        │                │\n",
      "│                 │                │ evaluation      │        │                │\n",
      "│                 │                │ model=Google    │        │                │\n",
      "│                 │                │ Generative AI   │        │                │\n",
      "│                 │                │ Model,          │        │                │\n",
      "│                 │                │ reason=The      │        │                │\n",
      "│                 │                │ score is 1.00   │        │                │\n",
      "│                 │                │ because the     │        │                │\n",
      "│                 │                │ output          │        │                │\n",
      "│                 │                │ perfectly       │        │                │\n",
      "│                 │                │ addresses the   │        │                │\n",
      "│                 │                │ input without   │        │                │\n",
      "│                 │                │ any irrelevant  │        │                │\n",
      "│                 │                │ information.    │        │                │\n",
      "│                 │                │ Great job!,     │        │                │\n",
      "│                 │                │ error=None)     │        │                │\n",
      "│                 │ Rouge Metric   │ 0.45            │ \u001b[31mFAILED\u001b[0m │                │\n",
      "│                 │                │ (threshold=0.6, │        │                │\n",
      "│                 │                │ evaluation      │        │                │\n",
      "│                 │                │ model=n/a,      │        │                │\n",
      "│                 │                │ reason=None,    │        │                │\n",
      "│                 │                │ error=None)     │        │                │\n",
      "│                 │                │                 │        │                │\n",
      "│ test_chat_model │                │                 │        │ 100.0%         │\n",
      "│                 │ Faithfulness   │ 1.0             │ \u001b[32mPASSED\u001b[0m │                │\n",
      "│                 │                │ (threshold=0.8, │        │                │\n",
      "│                 │                │ evaluation      │        │                │\n",
      "│                 │                │ model=Google    │        │                │\n",
      "│                 │                │ Generative AI   │        │                │\n",
      "│                 │                │ Model,          │        │                │\n",
      "│                 │                │ reason=The      │        │                │\n",
      "│                 │                │ faithfulness    │        │                │\n",
      "│                 │                │ score is 1.00   │        │                │\n",
      "│                 │                │ because there   │        │                │\n",
      "│                 │                │ are no          │        │                │\n",
      "│                 │                │ contradictions! │        │                │\n",
      "│                 │                │ That means the  │        │                │\n",
      "│                 │                │ actual output   │        │                │\n",
      "│                 │                │ perfectly       │        │                │\n",
      "│                 │                │ aligns with the │        │                │\n",
      "│                 │                │ retrieval       │        │                │\n",
      "│                 │                │ context – great │        │                │\n",
      "│                 │                │ job!,           │        │                │\n",
      "│                 │                │ error=None)     │        │                │\n",
      "│                 │ Toxicity       │ 0.0             │ \u001b[32mPASSED\u001b[0m │                │\n",
      "│                 │                │ (threshold=0.5, │        │                │\n",
      "│                 │                │ evaluation      │        │                │\n",
      "│                 │                │ model=Google    │        │                │\n",
      "│                 │                │ Generative AI   │        │                │\n",
      "│                 │                │ Model,          │        │                │\n",
      "│                 │                │ reason=The      │        │                │\n",
      "│                 │                │ score is 0.00   │        │                │\n",
      "│                 │                │ because the     │        │                │\n",
      "│                 │                │ output is not   │        │                │\n",
      "│                 │                │ toxic, which is │        │                │\n",
      "│                 │                │ great.,         │        │                │\n",
      "│                 │                │ error=None)     │        │                │\n",
      "│                 │ Correctness    │ 0.8             │ \u001b[32mPASSED\u001b[0m │                │\n",
      "│                 │ (GEval)        │ (threshold=0.8, │        │                │\n",
      "│                 │                │ evaluation      │        │                │\n",
      "│                 │                │ model=Google    │        │                │\n",
      "│                 │                │ Generative AI   │        │                │\n",
      "│                 │                │ Model,          │        │                │\n",
      "│                 │                │ reason=The      │        │                │\n",
      "│                 │                │ Actual Output   │        │                │\n",
      "│                 │                │ aligns with the │        │                │\n",
      "│                 │                │ Expected        │        │                │\n",
      "│                 │                │ Output, but     │        │                │\n",
      "│                 │                │ includes more   │        │                │\n",
      "│                 │                │ details from    │        │                │\n",
      "│                 │                │ the Input, such │        │                │\n",
      "│                 │                │ as mentioning   │        │                │\n",
      "│                 │                │ letters to AI   │        │                │\n",
      "│                 │                │ developers,     │        │                │\n",
      "│                 │                │ which is not    │        │                │\n",
      "│                 │                │ directly in the │        │                │\n",
      "│                 │                │ Expected        │        │                │\n",
      "│                 │                │ Output, thus    │        │                │\n",
      "│                 │                │ slightly        │        │                │\n",
      "│                 │                │ decreasing the  │        │                │\n",
      "│                 │                │ score.,         │        │                │\n",
      "│                 │                │ error=None)     │        │                │\n",
      "│                 │ Answer         │ 1.0             │ \u001b[32mPASSED\u001b[0m │                │\n",
      "│                 │ Relevancy      │ (threshold=0.7, │        │                │\n",
      "│                 │                │ evaluation      │        │                │\n",
      "│                 │                │ model=Google    │        │                │\n",
      "│                 │                │ Generative AI   │        │                │\n",
      "│                 │                │ Model,          │        │                │\n",
      "│                 │                │ reason=The      │        │                │\n",
      "│                 │                │ score is 1.00   │        │                │\n",
      "│                 │                │ because the     │        │                │\n",
      "│                 │                │ output          │        │                │\n",
      "│                 │                │ perfectly       │        │                │\n",
      "│                 │                │ addresses the   │        │                │\n",
      "│                 │                │ question        │        │                │\n",
      "│                 │                │ without any     │        │                │\n",
      "│                 │                │ irrelevant      │        │                │\n",
      "│                 │                │ information.    │        │                │\n",
      "│                 │                │ Great job!,     │        │                │\n",
      "│                 │                │ error=None)     │        │                │\n",
      "│                 │ Rouge Metric   │ 0.65            │ \u001b[32mPASSED\u001b[0m │                │\n",
      "│                 │                │ (threshold=0.6, │        │                │\n",
      "│                 │                │ evaluation      │        │                │\n",
      "│                 │                │ model=n/a,      │        │                │\n",
      "│                 │                │ reason=None,    │        │                │\n",
      "│                 │                │ error=None)     │        │                │\n",
      "│                 │                │                 │        │                │\n",
      "│ test_chat_model │                │                 │        │ 60.0%          │\n",
      "│                 │ Faithfulness   │ 1.0             │ \u001b[32mPASSED\u001b[0m │                │\n",
      "│                 │                │ (threshold=0.8, │        │                │\n",
      "│                 │                │ evaluation      │        │                │\n",
      "│                 │                │ model=Google    │        │                │\n",
      "│                 │                │ Generative AI   │        │                │\n",
      "│                 │                │ Model,          │        │                │\n",
      "│                 │                │ reason=The      │        │                │\n",
      "│                 │                │ faithfulness    │        │                │\n",
      "│                 │                │ score is 1.00   │        │                │\n",
      "│                 │                │ because there   │        │                │\n",
      "│                 │                │ are no          │        │                │\n",
      "│                 │                │ contradictions  │        │                │\n",
      "│                 │                │ listed,         │        │                │\n",
      "│                 │                │ indicating the  │        │                │\n",
      "│                 │                │ actual output   │        │                │\n",
      "│                 │                │ is perfectly    │        │                │\n",
      "│                 │                │ aligned with    │        │                │\n",
      "│                 │                │ the retrieval   │        │                │\n",
      "│                 │                │ context!,       │        │                │\n",
      "│                 │                │ error=None)     │        │                │\n",
      "│                 │ Toxicity       │ 0.0             │ \u001b[32mPASSED\u001b[0m │                │\n",
      "│                 │                │ (threshold=0.5, │        │                │\n",
      "│                 │                │ evaluation      │        │                │\n",
      "│                 │                │ model=Google    │        │                │\n",
      "│                 │                │ Generative AI   │        │                │\n",
      "│                 │                │ Model,          │        │                │\n",
      "│                 │                │ reason=The      │        │                │\n",
      "│                 │                │ score is 0.00   │        │                │\n",
      "│                 │                │ because the     │        │                │\n",
      "│                 │                │ output is not   │        │                │\n",
      "│                 │                │ toxic and       │        │                │\n",
      "│                 │                │ likely offers a │        │                │\n",
      "│                 │                │ helpful or      │        │                │\n",
      "│                 │                │ harmless        │        │                │\n",
      "│                 │                │ response.,      │        │                │\n",
      "│                 │                │ error=None)     │        │                │\n",
      "│                 │ Correctness    │ 0.6             │ \u001b[31mFAILED\u001b[0m │                │\n",
      "│                 │ (GEval)        │ (threshold=0.8, │        │                │\n",
      "│                 │                │ evaluation      │        │                │\n",
      "│                 │                │ model=Google    │        │                │\n",
      "│                 │                │ Generative AI   │        │                │\n",
      "│                 │                │ Model,          │        │                │\n",
      "│                 │                │ reason=The      │        │                │\n",
      "│                 │                │ Actual Output   │        │                │\n",
      "│                 │                │ includes        │        │                │\n",
      "│                 │                │ Anthropic,      │        │                │\n",
      "│                 │                │ which aligns    │        │                │\n",
      "│                 │                │ with the        │        │                │\n",
      "│                 │                │ Expected        │        │                │\n",
      "│                 │                │ Output, but     │        │                │\n",
      "│                 │                │ includes        │        │                │\n",
      "│                 │                │ additional      │        │                │\n",
      "│                 │                │ information and │        │                │\n",
      "│                 │                │ details about   │        │                │\n",
      "│                 │                │ Meta that were  │        │                │\n",
      "│                 │                │ not requested., │        │                │\n",
      "│                 │                │ error=None)     │        │                │\n",
      "│                 │ Answer         │ 1.0             │ \u001b[32mPASSED\u001b[0m │                │\n",
      "│                 │ Relevancy      │ (threshold=0.7, │        │                │\n",
      "│                 │                │ evaluation      │        │                │\n",
      "│                 │                │ model=Google    │        │                │\n",
      "│                 │                │ Generative AI   │        │                │\n",
      "│                 │                │ Model,          │        │                │\n",
      "│                 │                │ reason=The      │        │                │\n",
      "│                 │                │ score is 1.00   │        │                │\n",
      "│                 │                │ because the     │        │                │\n",
      "│                 │                │ output          │        │                │\n",
      "│                 │                │ perfectly       │        │                │\n",
      "│                 │                │ addresses the   │        │                │\n",
      "│                 │                │ input and       │        │                │\n",
      "│                 │                │ contains no     │        │                │\n",
      "│                 │                │ irrelevant      │        │                │\n",
      "│                 │                │ information.    │        │                │\n",
      "│                 │                │ Great job!,     │        │                │\n",
      "│                 │                │ error=None)     │        │                │\n",
      "│                 │ Rouge Metric   │ 0.09            │ \u001b[31mFAILED\u001b[0m │                │\n",
      "│                 │                │ (threshold=0.6, │        │                │\n",
      "│                 │                │ evaluation      │        │                │\n",
      "│                 │                │ model=n/a,      │        │                │\n",
      "│                 │                │ reason=None,    │        │                │\n",
      "│                 │                │ error=None)     │        │                │\n",
      "│ \u001b[1;31mNote: Use \u001b[0m      │                │                 │        │                │\n",
      "│ \u001b[1;31mConfident AI \u001b[0m   │                │                 │        │                │\n",
      "│ \u001b[1;31mwith DeepEval \u001b[0m  │                │                 │        │                │\n",
      "│ \u001b[1;31mto analyze \u001b[0m     │                │                 │        │                │\n",
      "│ \u001b[1;31mfailed test \u001b[0m    │                │                 │        │                │\n",
      "│ \u001b[1;31mcases for more \u001b[0m │                │                 │        │                │\n",
      "│ \u001b[1;31mdetails\u001b[0m         │                │                 │        │                │\n",
      "└─────────────────┴────────────────┴─────────────────┴────────┴────────────────┘\n",
      "Total estimated evaluation tokens cost: \u001b[3;35mNone\u001b[0m USD\n",
      "\n",
      "\u001b[92m✓\u001b[0m Tests finished 🎉! Run \u001b[1;32m'deepeval login'\u001b[0m to save and analyze evaluation results\n",
      "on Confident AI.\n",
      " \n",
      "✨👀 Looking for a place for your LLM test data to live 🏡❤️ ? Use \u001b[35mConfident AI\u001b[0m \n",
      "to get & share testing reports, experiment with models/prompts, and catch \n",
      "regressions for your LLM system. Just run \u001b[36m'deepeval login'\u001b[0m in the CLI. \n",
      "\n",
      "Test finished!\n"
     ]
    }
   ],
   "source": [
    "!deepeval test run test_rag_system.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
